flags Namespace(checkpoint_path=None, exp_config='flowagent', num_cpus=1, num_steps=10, rl_trainer='rllib', rollout_size=1000)
== Status ==
Memory usage on this node: 10.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+-------+
| Trial name                      | status   | loc   |
|---------------------------------+----------+-------|
| PPO_FleetControlEnv-v0_b1f448d0 | RUNNING  |       |
+---------------------------------+----------+-------+


[2m[36m(pid=233099)[0m 2025-04-08 20:00:52,081	INFO trainer.py:371 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution
[2m[36m(pid=233099)[0m 2025-04-08 20:00:52,356	INFO trainer.py:512 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=233099)[0m 2025-04-08 20:00:57,228	WARNING util.py:45 -- Install gputil for GPU system monitoring.
Result for PPO_FleetControlEnv-v0_b1f448d0:
  custom_metrics: {}
  date: 2025-04-08_20-01-00
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 401.9784076755606
  episode_reward_mean: 401.9784076755606
  episode_reward_min: 401.9784076755606
  episodes_this_iter: 1
  episodes_total: 1
  experiment_id: ec3e00c155114660a032530698b069a1
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 345.869
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 21.297422409057617
        entropy_coeff: 0.0
        kl: 0.0009788447059690952
        policy_loss: -0.03316137567162514
        total_loss: 27904.236328125
        vf_explained_var: 1.0728836059570312e-05
        vf_loss: 27904.267578125
    load_time_ms: 74.017
    num_steps_sampled: 45
    num_steps_trained: 45
    sample_time_ms: 1337.486
    update_time_ms: 972.855
  iterations_since_restore: 1
  node_ip: 192.168.0.24
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.18
    ram_util_percent: 74.72
  pid: 233099
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.921151409978452
    mean_inference_ms: 1.5549296918122664
    mean_processing_ms: 0.489794689676036
  time_since_restore: 2.795382499694824
  time_this_iter_s: 2.795382499694824
  time_total_s: 2.795382499694824
  timestamp: 1744156860
  timesteps_since_restore: 45
  timesteps_this_iter: 45
  timesteps_total: 45
  training_iteration: 1
  trial_id: b1f448d0
  
== Status ==
Memory usage on this node: 11.5/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+---------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                 |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+---------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_b1f448d0 | RUNNING  | 192.168.0.24:233099 |      1 |          2.79538 |          45 |  401.978 |
+---------------------------------+----------+---------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_b1f448d0:
  custom_metrics: {}
  date: 2025-04-08_20-01-03
  done: true
  episode_len_mean: 45.0
  episode_reward_max: 401.9784076755606
  episode_reward_mean: 105.74442390914051
  episode_reward_min: 27.179704096645708
  episodes_this_iter: 1
  episodes_total: 10
  experiment_id: ec3e00c155114660a032530698b069a1
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 51.296
    learner:
      default_policy:
        cur_kl_coeff: 0.0003906250058207661
        cur_lr: 4.999999873689376e-05
        entropy: 21.24187660217285
        entropy_coeff: 0.0
        kl: 0.0003649817663244903
        policy_loss: -0.024345260113477707
        total_loss: 160.08888244628906
        vf_explained_var: 0.0003827810287475586
        vf_loss: 160.1132354736328
    load_time_ms: 8.2
    num_steps_sampled: 450
    num_steps_trained: 450
    sample_time_ms: 435.965
    update_time_ms: 100.519
  iterations_since_restore: 10
  node_ip: 192.168.0.24
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf: {}
  pid: 233099
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.302024577619739
    mean_inference_ms: 0.9687245001001299
    mean_processing_ms: 0.5018701300321834
  time_since_restore: 6.047955751419067
  time_this_iter_s: 0.3509366512298584
  time_total_s: 6.047955751419067
  timestamp: 1744156863
  timesteps_since_restore: 450
  timesteps_this_iter: 45
  timesteps_total: 450
  training_iteration: 10
  trial_id: b1f448d0
  
== Status ==
Memory usage on this node: 11.6/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 TERMINATED)
+---------------------------------+------------+-------+--------+------------------+-------------+----------+
| Trial name                      | status     | loc   |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+------------+-------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_b1f448d0 | TERMINATED |       |     10 |          6.04796 |         450 |  105.744 |
+---------------------------------+------------+-------+--------+------------------+-------------+----------+


[2m[36m(pid=233098)[0m ./emissions_output/fleet_control_20250408-2000571744156857.049077-0_emission.csv ./emissions_output
