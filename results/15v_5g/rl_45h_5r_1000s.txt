flags Namespace(checkpoint_path=None, exp_config='flowagent', num_cpus=1, num_steps=1000, rl_trainer='rllib', rollout_size=1000)
== Status ==
Memory usage on this node: 11.2/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+-------+
| Trial name                      | status   | loc   |
|---------------------------------+----------+-------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  |       |
+---------------------------------+----------+-------+


[2m[36m(pid=263755)[0m 2025-04-09 09:43:36,866	INFO trainer.py:371 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution
[2m[36m(pid=263755)[0m 2025-04-09 09:43:37,094	INFO trainer.py:512 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=263755)[0m 2025-04-09 09:43:41,759	WARNING util.py:45 -- Install gputil for GPU system monitoring.
Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-43-45
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 372.05180181986856
  episode_reward_mean: 162.42823097980153
  episode_reward_min: 51.098844921712605
  episodes_this_iter: 5
  episodes_total: 5
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 393.533
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 21.216899871826172
        entropy_coeff: 0.0
        kl: 0.006391279399394989
        policy_loss: -0.05159463733434677
        total_loss: 7127.7099609375
        vf_explained_var: 4.177093433099799e-05
        vf_loss: 7127.7607421875
    load_time_ms: 69.526
    num_steps_sampled: 225
    num_steps_trained: 225
    sample_time_ms: 2358.721
    update_time_ms: 970.896
  iterations_since_restore: 1
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.349999999999998
    ram_util_percent: 76.81666666666666
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.181985618793859
    mean_inference_ms: 0.7307445053505687
    mean_processing_ms: 0.4439934165076872
  time_since_restore: 3.8570079803466797
  time_this_iter_s: 3.8570079803466797
  time_total_s: 3.8570079803466797
  timestamp: 1744206225
  timesteps_since_restore: 225
  timesteps_this_iter: 225
  timesteps_total: 225
  training_iteration: 1
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |      1 |          3.85701 |         225 |  162.428 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-43-52
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 372.05180181986856
  episode_reward_mean: 49.15334839735806
  episode_reward_min: 9.212001264802549
  episodes_this_iter: 5
  episodes_total: 25
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 162.018
    learner:
      default_policy:
        cur_kl_coeff: 0.012500000186264515
        cur_lr: 4.999999873689376e-05
        entropy: 21.250167846679688
        entropy_coeff: 0.0
        kl: 0.007067055441439152
        policy_loss: -0.048973243683576584
        total_loss: 25.321422576904297
        vf_explained_var: 0.00456269970163703
        vf_loss: 25.37030792236328
    load_time_ms: 14.562
    num_steps_sampled: 1125
    num_steps_trained: 1125
    sample_time_ms: 1628.392
    update_time_ms: 197.473
  iterations_since_restore: 5
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.75
    ram_util_percent: 77.0
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.127629680082567
    mean_inference_ms: 0.6667052199912777
    mean_processing_ms: 0.44407865932255014
  time_since_restore: 10.088935852050781
  time_this_iter_s: 1.7398602962493896
  time_total_s: 10.088935852050781
  timestamp: 1744206232
  timesteps_since_restore: 1125
  timesteps_this_iter: 225
  timesteps_total: 1125
  training_iteration: 5
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |      5 |          10.0889 |        1125 |  49.1533 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-43-57
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 372.05180181986856
  episode_reward_mean: 33.90010195692996
  episode_reward_min: 5.429280519059216
  episodes_this_iter: 5
  episodes_total: 40
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 133.339
    learner:
      default_policy:
        cur_kl_coeff: 0.0015625000232830644
        cur_lr: 4.999999873689376e-05
        entropy: 21.246152877807617
        entropy_coeff: 0.0
        kl: 0.005905921570956707
        policy_loss: -0.0371367372572422
        total_loss: 9.946725845336914
        vf_explained_var: 0.006314909551292658
        vf_loss: 9.983853340148926
    load_time_ms: 9.405
    num_steps_sampled: 1800
    num_steps_trained: 1800
    sample_time_ms: 1630.68
    update_time_ms: 124.988
  iterations_since_restore: 8
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.066666666666666
    ram_util_percent: 76.96666666666667
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.237403532557404
    mean_inference_ms: 0.6733503097855917
    mean_processing_ms: 0.4572810806255932
  time_since_restore: 15.273337125778198
  time_this_iter_s: 1.8204302787780762
  time_total_s: 15.273337125778198
  timestamp: 1744206237
  timesteps_since_restore: 1800
  timesteps_this_iter: 225
  timesteps_total: 1800
  training_iteration: 8
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |      8 |          15.2733 |        1800 |  33.9001 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-44-02
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 372.05180181986856
  episode_reward_mean: 26.31228378904148
  episode_reward_min: 4.344604793470894
  episodes_this_iter: 5
  episodes_total: 55
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 96.079
    learner:
      default_policy:
        cur_kl_coeff: 0.00019531250291038305
        cur_lr: 4.999999873689376e-05
        entropy: 21.166202545166016
        entropy_coeff: 0.0
        kl: 0.00653229933232069
        policy_loss: -0.03620787709951401
        total_loss: 4.7634758949279785
        vf_explained_var: 0.006254339125007391
        vf_loss: 4.7996826171875
    load_time_ms: 0.902
    num_steps_sampled: 2475
    num_steps_trained: 2475
    sample_time_ms: 1583.312
    update_time_ms: 4.283
  iterations_since_restore: 11
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.85
    ram_util_percent: 77.0
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.357228549685736
    mean_inference_ms: 0.683439679840889
    mean_processing_ms: 0.4696858324241006
  time_since_restore: 20.736016988754272
  time_this_iter_s: 1.6283299922943115
  time_total_s: 20.736016988754272
  timestamp: 1744206242
  timesteps_since_restore: 2475
  timesteps_this_iter: 225
  timesteps_total: 2475
  training_iteration: 11
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     11 |           20.736 |        2475 |  26.3123 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-44-08
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 372.05180181986856
  episode_reward_mean: 21.66207374777923
  episode_reward_min: 3.435492245738385
  episodes_this_iter: 5
  episodes_total: 70
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 96.472
    learner:
      default_policy:
        cur_kl_coeff: 4.882812572759576e-05
        cur_lr: 4.999999873689376e-05
        entropy: 20.994768142700195
        entropy_coeff: 0.0
        kl: 0.012939788401126862
        policy_loss: -0.05649294704198837
        total_loss: 4.303118705749512
        vf_explained_var: 0.029015302658081055
        vf_loss: 4.359610557556152
    load_time_ms: 0.966
    num_steps_sampled: 3150
    num_steps_trained: 3150
    sample_time_ms: 1677.167
    update_time_ms: 4.395
  iterations_since_restore: 14
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.7
    ram_util_percent: 77.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.4604997478667725
    mean_inference_ms: 0.6940215719401804
    mean_processing_ms: 0.47936727651548566
  time_since_restore: 26.1738224029541
  time_this_iter_s: 1.473893642425537
  time_total_s: 26.1738224029541
  timestamp: 1744206248
  timesteps_since_restore: 3150
  timesteps_this_iter: 225
  timesteps_total: 3150
  training_iteration: 14
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     14 |          26.1738 |        3150 |  21.6621 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-44-14
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 372.05180181986856
  episode_reward_mean: 18.53742232839785
  episode_reward_min: 2.7357523570254423
  episodes_this_iter: 5
  episodes_total: 85
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 99.06
    learner:
      default_policy:
        cur_kl_coeff: 1.220703143189894e-05
        cur_lr: 4.999999873689376e-05
        entropy: 20.94144630432129
        entropy_coeff: 0.0
        kl: 0.010401922278106213
        policy_loss: -0.055023085325956345
        total_loss: 2.2695679664611816
        vf_explained_var: 0.018193388357758522
        vf_loss: 2.3245906829833984
    load_time_ms: 0.979
    num_steps_sampled: 3825
    num_steps_trained: 3825
    sample_time_ms: 1748.341
    update_time_ms: 4.352
  iterations_since_restore: 17
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.633333333333336
    ram_util_percent: 77.10000000000001
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.543542130735826
    mean_inference_ms: 0.7028964568740844
    mean_processing_ms: 0.4862064895246848
  time_since_restore: 32.01508593559265
  time_this_iter_s: 1.9724938869476318
  time_total_s: 32.01508593559265
  timestamp: 1744206254
  timesteps_since_restore: 3825
  timesteps_this_iter: 225
  timesteps_total: 3825
  training_iteration: 17
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     17 |          32.0151 |        3825 |  18.5374 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-44-19
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 372.05180181986856
  episode_reward_mean: 16.271045893821604
  episode_reward_min: 2.6672693615734473
  episodes_this_iter: 5
  episodes_total: 100
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 101.483
    learner:
      default_policy:
        cur_kl_coeff: 1.220703143189894e-05
        cur_lr: 4.999999873689376e-05
        entropy: 20.801523208618164
        entropy_coeff: 0.0
        kl: 0.008976020850241184
        policy_loss: -0.05109461396932602
        total_loss: 2.039442539215088
        vf_explained_var: 0.023670971393585205
        vf_loss: 2.0905370712280273
    load_time_ms: 1.051
    num_steps_sampled: 4500
    num_steps_trained: 4500
    sample_time_ms: 1737.305
    update_time_ms: 4.324
  iterations_since_restore: 20
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.4
    ram_util_percent: 76.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.617484485774246
    mean_inference_ms: 0.7113301561520534
    mean_processing_ms: 0.4930162078470236
  time_since_restore: 37.58422589302063
  time_this_iter_s: 1.862077236175537
  time_total_s: 37.58422589302063
  timestamp: 1744206259
  timesteps_since_restore: 4500
  timesteps_this_iter: 225
  timesteps_total: 4500
  training_iteration: 20
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     20 |          37.5842 |        4500 |   16.271 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-44-24
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 16.027570532034034
  episode_reward_mean: 5.660679114411629
  episode_reward_min: 2.5616570129486163
  episodes_this_iter: 5
  episodes_total: 115
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 95.739
    learner:
      default_policy:
        cur_kl_coeff: 3.051757857974735e-06
        cur_lr: 4.999999873689376e-05
        entropy: 20.78731918334961
        entropy_coeff: 0.0
        kl: 0.0073584988713264465
        policy_loss: -0.04320262745022774
        total_loss: 1.2490547895431519
        vf_explained_var: 0.05738229677081108
        vf_loss: 1.29225754737854
    load_time_ms: 1.063
    num_steps_sampled: 5175
    num_steps_trained: 5175
    sample_time_ms: 1683.304
    update_time_ms: 4.126
  iterations_since_restore: 23
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.26666666666667
    ram_util_percent: 76.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.757083454018726
    mean_inference_ms: 0.7232809725464846
    mean_processing_ms: 0.5073405750071105
  time_since_restore: 42.57747936248779
  time_this_iter_s: 1.623396635055542
  time_total_s: 42.57747936248779
  timestamp: 1744206264
  timesteps_since_restore: 5175
  timesteps_this_iter: 225
  timesteps_total: 5175
  training_iteration: 23
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     23 |          42.5775 |        5175 |  5.66068 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-44-29
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 9.325661491159218
  episode_reward_mean: 4.305781982340706
  episode_reward_min: 2.104279281993554
  episodes_this_iter: 5
  episodes_total: 130
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 93.401
    learner:
      default_policy:
        cur_kl_coeff: 7.629394644936838e-07
        cur_lr: 4.999999873689376e-05
        entropy: 20.70420265197754
        entropy_coeff: 0.0
        kl: 0.010523970238864422
        policy_loss: -0.04443035647273064
        total_loss: 0.7988327741622925
        vf_explained_var: 0.050297509878873825
        vf_loss: 0.8432631492614746
    load_time_ms: 1.018
    num_steps_sampled: 5850
    num_steps_trained: 5850
    sample_time_ms: 1668.32
    update_time_ms: 4.249
  iterations_since_restore: 26
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.3
    ram_util_percent: 77.0
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.8770836009846645
    mean_inference_ms: 0.7366507628503886
    mean_processing_ms: 0.5173039845000013
  time_since_restore: 47.74832510948181
  time_this_iter_s: 1.6948225498199463
  time_total_s: 47.74832510948181
  timestamp: 1744206269
  timesteps_since_restore: 5850
  timesteps_this_iter: 225
  timesteps_total: 5850
  training_iteration: 26
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     26 |          47.7483 |        5850 |  4.30578 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-44-36
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 5.41063215528683
  episode_reward_mean: 3.3569495139232663
  episode_reward_min: 1.8392892922168185
  episodes_this_iter: 5
  episodes_total: 150
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 88.845
    learner:
      default_policy:
        cur_kl_coeff: 3.814697322468419e-07
        cur_lr: 4.999999873689376e-05
        entropy: 21.026073455810547
        entropy_coeff: 0.0
        kl: 0.009052375331521034
        policy_loss: -0.04307667165994644
        total_loss: 0.7456321120262146
        vf_explained_var: 0.09652093797922134
        vf_loss: 0.7887088060379028
    load_time_ms: 0.945
    num_steps_sampled: 6750
    num_steps_trained: 6750
    sample_time_ms: 1543.6
    update_time_ms: 3.922
  iterations_since_restore: 30
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.6
    ram_util_percent: 76.85
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.954642525500537
    mean_inference_ms: 0.7438764469779617
    mean_processing_ms: 0.5234437049701789
  time_since_restore: 53.990764141082764
  time_this_iter_s: 1.5100955963134766
  time_total_s: 53.990764141082764
  timestamp: 1744206276
  timesteps_since_restore: 6750
  timesteps_this_iter: 225
  timesteps_total: 6750
  training_iteration: 30
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     30 |          53.9908 |        6750 |  3.35695 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-44-41
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 5.331348495896566
  episode_reward_mean: 3.006736347825594
  episode_reward_min: 1.8392892922168185
  episodes_this_iter: 5
  episodes_total: 165
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 93.153
    learner:
      default_policy:
        cur_kl_coeff: 9.536743306171047e-08
        cur_lr: 4.999999873689376e-05
        entropy: 21.2603702545166
        entropy_coeff: 0.0
        kl: 0.009230097755789757
        policy_loss: -0.04051157087087631
        total_loss: 0.5528358817100525
        vf_explained_var: 0.04800073057413101
        vf_loss: 0.593347430229187
    load_time_ms: 0.889
    num_steps_sampled: 7425
    num_steps_trained: 7425
    sample_time_ms: 1574.084
    update_time_ms: 3.573
  iterations_since_restore: 33
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.833333333333332
    ram_util_percent: 77.0
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.973676180228827
    mean_inference_ms: 0.744649410211054
    mean_processing_ms: 0.5246515028263632
  time_since_restore: 59.32738780975342
  time_this_iter_s: 1.868856430053711
  time_total_s: 59.32738780975342
  timestamp: 1744206281
  timesteps_since_restore: 7425
  timesteps_this_iter: 225
  timesteps_total: 7425
  training_iteration: 33
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     33 |          59.3274 |        7425 |  3.00674 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-44-46
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 4.536382787468695
  episode_reward_mean: 2.6537675007832244
  episode_reward_min: 1.5794332799800848
  episodes_this_iter: 5
  episodes_total: 180
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 97.133
    learner:
      default_policy:
        cur_kl_coeff: 4.7683716530855236e-08
        cur_lr: 4.999999873689376e-05
        entropy: 21.462900161743164
        entropy_coeff: 0.0
        kl: 0.012159367091953754
        policy_loss: -0.05842847377061844
        total_loss: 0.3346562385559082
        vf_explained_var: 0.0218567606061697
        vf_loss: 0.39308470487594604
    load_time_ms: 0.983
    num_steps_sampled: 8100
    num_steps_trained: 8100
    sample_time_ms: 1561.106
    update_time_ms: 3.494
  iterations_since_restore: 36
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.0
    ram_util_percent: 77.43333333333332
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.9797086983116605
    mean_inference_ms: 0.7441271123920251
    mean_processing_ms: 0.5253667898782035
  time_since_restore: 64.4074969291687
  time_this_iter_s: 1.9107933044433594
  time_total_s: 64.4074969291687
  timestamp: 1744206286
  timesteps_since_restore: 8100
  timesteps_this_iter: 225
  timesteps_total: 8100
  training_iteration: 36
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     36 |          64.4075 |        8100 |  2.65377 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-44-51
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 4.325050809967867
  episode_reward_mean: 2.5015788813426747
  episode_reward_min: 1.5794332799800848
  episodes_this_iter: 5
  episodes_total: 190
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 101.803
    learner:
      default_policy:
        cur_kl_coeff: 4.7683716530855236e-08
        cur_lr: 4.999999873689376e-05
        entropy: 21.303974151611328
        entropy_coeff: 0.0
        kl: 0.011233360506594181
        policy_loss: -0.04824686795473099
        total_loss: 0.30627763271331787
        vf_explained_var: 0.04425613954663277
        vf_loss: 0.35452455282211304
    load_time_ms: 1.024
    num_steps_sampled: 8550
    num_steps_trained: 8550
    sample_time_ms: 1772.437
    update_time_ms: 3.637
  iterations_since_restore: 38
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 46.525
    ram_util_percent: 77.42500000000001
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.980870379864989
    mean_inference_ms: 0.7432946736475995
    mean_processing_ms: 0.5266258482208045
  time_since_restore: 69.59027314186096
  time_this_iter_s: 2.820263147354126
  time_total_s: 69.59027314186096
  timestamp: 1744206291
  timesteps_since_restore: 8550
  timesteps_this_iter: 225
  timesteps_total: 8550
  training_iteration: 38
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     38 |          69.5903 |        8550 |  2.50158 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-44-56
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 3.3382450213905153
  episode_reward_mean: 2.3506338903914004
  episode_reward_min: 1.5295315157549172
  episodes_this_iter: 5
  episodes_total: 200
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 112.444
    learner:
      default_policy:
        cur_kl_coeff: 4.7683716530855236e-08
        cur_lr: 4.999999873689376e-05
        entropy: 21.26810646057129
        entropy_coeff: 0.0
        kl: 0.014707420952618122
        policy_loss: -0.05929816886782646
        total_loss: 0.2588983178138733
        vf_explained_var: 0.032912254333496094
        vf_loss: 0.31819647550582886
    load_time_ms: 1.131
    num_steps_sampled: 9000
    num_steps_trained: 9000
    sample_time_ms: 1946.742
    update_time_ms: 3.908
  iterations_since_restore: 40
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 45.099999999999994
    ram_util_percent: 78.60000000000001
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.9950620396249
    mean_inference_ms: 0.744553889018796
    mean_processing_ms: 0.5291747134913048
  time_since_restore: 74.6675956249237
  time_this_iter_s: 2.292698860168457
  time_total_s: 74.6675956249237
  timestamp: 1744206296
  timesteps_since_restore: 9000
  timesteps_this_iter: 225
  timesteps_total: 9000
  training_iteration: 40
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     40 |          74.6676 |        9000 |  2.35063 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-45-03
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 3.2478920508102624
  episode_reward_mean: 2.188568436188605
  episode_reward_min: 1.4721365960934223
  episodes_this_iter: 5
  episodes_total: 215
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 112.254
    learner:
      default_policy:
        cur_kl_coeff: 4.7683716530855236e-08
        cur_lr: 4.999999873689376e-05
        entropy: 21.055206298828125
        entropy_coeff: 0.0
        kl: 0.00919350702315569
        policy_loss: -0.039086028933525085
        total_loss: 0.1925078183412552
        vf_explained_var: 0.07114292681217194
        vf_loss: 0.23159381747245789
    load_time_ms: 1.336
    num_steps_sampled: 9675
    num_steps_trained: 9675
    sample_time_ms: 2063.604
    update_time_ms: 4.455
  iterations_since_restore: 43
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 44.53333333333333
    ram_util_percent: 79.26666666666667
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.029381899115622
    mean_inference_ms: 0.7485778203785389
    mean_processing_ms: 0.5355194406874719
  time_since_restore: 81.17856621742249
  time_this_iter_s: 2.1186602115631104
  time_total_s: 81.17856621742249
  timestamp: 1744206303
  timesteps_since_restore: 9675
  timesteps_this_iter: 225
  timesteps_total: 9675
  training_iteration: 43
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.2/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     43 |          81.1786 |        9675 |  2.18857 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-45-09
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 2.9226350359172613
  episode_reward_mean: 1.979757834237374
  episode_reward_min: 1.0105924998001243
  episodes_this_iter: 5
  episodes_total: 235
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 107.358
    learner:
      default_policy:
        cur_kl_coeff: 2.3841858265427618e-08
        cur_lr: 4.999999873689376e-05
        entropy: 20.878021240234375
        entropy_coeff: 0.0
        kl: 0.014415192417800426
        policy_loss: -0.05980967357754707
        total_loss: 0.10828480869531631
        vf_explained_var: 0.045691441744565964
        vf_loss: 0.1680944859981537
    load_time_ms: 1.23
    num_steps_sampled: 10575
    num_steps_trained: 10575
    sample_time_ms: 1977.552
    update_time_ms: 4.462
  iterations_since_restore: 47
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.75
    ram_util_percent: 79.0
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.072601482183338
    mean_inference_ms: 0.7552013025190593
    mean_processing_ms: 0.545228779290533
  time_since_restore: 87.71034550666809
  time_this_iter_s: 1.9264147281646729
  time_total_s: 87.71034550666809
  timestamp: 1744206309
  timesteps_since_restore: 10575
  timesteps_this_iter: 225
  timesteps_total: 10575
  training_iteration: 47
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.2/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     47 |          87.7103 |       10575 |  1.97976 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-45-16
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 2.3920521354134276
  episode_reward_mean: 1.807411508870188
  episode_reward_min: 1.0105924998001243
  episodes_this_iter: 5
  episodes_total: 255
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 96.501
    learner:
      default_policy:
        cur_kl_coeff: 2.3841858265427618e-08
        cur_lr: 4.999999873689376e-05
        entropy: 20.875619888305664
        entropy_coeff: 0.0
        kl: 0.008371276780962944
        policy_loss: -0.04269414022564888
        total_loss: 0.13007581233978271
        vf_explained_var: 0.1195555105805397
        vf_loss: 0.1727699488401413
    load_time_ms: 1.113
    num_steps_sampled: 11475
    num_steps_trained: 11475
    sample_time_ms: 1595.17
    update_time_ms: 3.698
  iterations_since_restore: 51
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.35
    ram_util_percent: 78.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.1194821741641645
    mean_inference_ms: 0.7632622268417382
    mean_processing_ms: 0.5549636188192767
  time_since_restore: 93.89442682266235
  time_this_iter_s: 1.5688807964324951
  time_total_s: 93.89442682266235
  timestamp: 1744206316
  timesteps_since_restore: 11475
  timesteps_this_iter: 225
  timesteps_total: 11475
  training_iteration: 51
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     51 |          93.8944 |       11475 |  1.80741 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-45-21
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 2.355210563501575
  episode_reward_mean: 1.7104153868240743
  episode_reward_min: 1.0105924998001243
  episodes_this_iter: 5
  episodes_total: 270
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 92.968
    learner:
      default_policy:
        cur_kl_coeff: 5.9604645663569045e-09
        cur_lr: 4.999999873689376e-05
        entropy: 21.087478637695312
        entropy_coeff: 0.0
        kl: 0.0067933835089206696
        policy_loss: -0.03434479981660843
        total_loss: 0.11118285357952118
        vf_explained_var: 0.09663312137126923
        vf_loss: 0.1455276757478714
    load_time_ms: 0.886
    num_steps_sampled: 12150
    num_steps_trained: 12150
    sample_time_ms: 1521.119
    update_time_ms: 3.457
  iterations_since_restore: 54
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.6
    ram_util_percent: 77.85
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.150183056894853
    mean_inference_ms: 0.7687894837685859
    mean_processing_ms: 0.5616197427651131
  time_since_restore: 98.89627742767334
  time_this_iter_s: 1.5937120914459229
  time_total_s: 98.89627742767334
  timestamp: 1744206321
  timesteps_since_restore: 12150
  timesteps_this_iter: 225
  timesteps_total: 12150
  training_iteration: 54
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     54 |          98.8963 |       12150 |  1.71042 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-45-27
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 2.2102991360711326
  episode_reward_mean: 1.5943897291904385
  episode_reward_min: 1.0105924998001243
  episodes_this_iter: 5
  episodes_total: 290
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.985
    learner:
      default_policy:
        cur_kl_coeff: 2.9802322831784522e-09
        cur_lr: 4.999999873689376e-05
        entropy: 21.136478424072266
        entropy_coeff: 0.0
        kl: 0.01089894026517868
        policy_loss: -0.055204689502716064
        total_loss: 0.06553126871585846
        vf_explained_var: 0.17861616611480713
        vf_loss: 0.12073595821857452
    load_time_ms: 0.821
    num_steps_sampled: 13050
    num_steps_trained: 13050
    sample_time_ms: 1460.499
    update_time_ms: 3.462
  iterations_since_restore: 58
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.95
    ram_util_percent: 77.7
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.171901583134784
    mean_inference_ms: 0.773365068461888
    mean_processing_ms: 0.5676562059584882
  time_since_restore: 104.9478816986084
  time_this_iter_s: 1.4950132369995117
  time_total_s: 104.9478816986084
  timestamp: 1744206327
  timesteps_since_restore: 13050
  timesteps_this_iter: 225
  timesteps_total: 13050
  training_iteration: 58
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     58 |          104.948 |       13050 |  1.59439 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-45-33
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 2.0875641017601603
  episode_reward_mean: 1.4911902212778374
  episode_reward_min: 1.0105924998001243
  episodes_this_iter: 5
  episodes_total: 310
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.562
    learner:
      default_policy:
        cur_kl_coeff: 2.9802322831784522e-09
        cur_lr: 4.999999873689376e-05
        entropy: 21.323993682861328
        entropy_coeff: 0.0
        kl: 0.009890458546578884
        policy_loss: -0.0429052896797657
        total_loss: 0.04951994866132736
        vf_explained_var: 0.3652589023113251
        vf_loss: 0.09242523461580276
    load_time_ms: 0.879
    num_steps_sampled: 13950
    num_steps_trained: 13950
    sample_time_ms: 1423.893
    update_time_ms: 3.702
  iterations_since_restore: 62
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.5
    ram_util_percent: 77.4
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.132475060818324
    mean_inference_ms: 0.7696443898048654
    mean_processing_ms: 0.5654221809889145
  time_since_restore: 110.97867155075073
  time_this_iter_s: 1.4757976531982422
  time_total_s: 110.97867155075073
  timestamp: 1744206333
  timesteps_since_restore: 13950
  timesteps_this_iter: 225
  timesteps_total: 13950
  training_iteration: 62
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     62 |          110.979 |       13950 |  1.49119 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-45-39
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.8629604803143553
  episode_reward_mean: 1.4259789090412973
  episode_reward_min: 0.9493177619358646
  episodes_this_iter: 5
  episodes_total: 330
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.83
    learner:
      default_policy:
        cur_kl_coeff: 1.4901161415892261e-09
        cur_lr: 4.999999873689376e-05
        entropy: 21.29642677307129
        entropy_coeff: 0.0
        kl: 0.011075749062001705
        policy_loss: -0.04803011938929558
        total_loss: 0.019435003399848938
        vf_explained_var: 0.4525422155857086
        vf_loss: 0.06746512651443481
    load_time_ms: 0.894
    num_steps_sampled: 14850
    num_steps_trained: 14850
    sample_time_ms: 1417.743
    update_time_ms: 3.767
  iterations_since_restore: 66
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.950000000000003
    ram_util_percent: 77.35
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.076348811524599
    mean_inference_ms: 0.7636802580752247
    mean_processing_ms: 0.5588462593698595
  time_since_restore: 117.09026503562927
  time_this_iter_s: 1.5407042503356934
  time_total_s: 117.09026503562927
  timestamp: 1744206339
  timesteps_since_restore: 14850
  timesteps_this_iter: 225
  timesteps_total: 14850
  training_iteration: 66
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     66 |           117.09 |       14850 |  1.42598 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-45-45
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.740192128763188
  episode_reward_mean: 1.3694092636706432
  episode_reward_min: 0.9493177619358646
  episodes_this_iter: 5
  episodes_total: 350
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.968
    learner:
      default_policy:
        cur_kl_coeff: 7.450580707946131e-10
        cur_lr: 4.999999873689376e-05
        entropy: 21.467182159423828
        entropy_coeff: 0.0
        kl: 0.01155545748770237
        policy_loss: -0.055610693991184235
        total_loss: -0.01278185099363327
        vf_explained_var: 0.6595407724380493
        vf_loss: 0.04282885044813156
    load_time_ms: 0.91
    num_steps_sampled: 15750
    num_steps_trained: 15750
    sample_time_ms: 1420.045
    update_time_ms: 3.741
  iterations_since_restore: 70
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.950000000000003
    ram_util_percent: 77.4
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.022872543266353
    mean_inference_ms: 0.7582886893036309
    mean_processing_ms: 0.5527249879145788
  time_since_restore: 123.21946167945862
  time_this_iter_s: 1.4389009475708008
  time_total_s: 123.21946167945862
  timestamp: 1744206345
  timesteps_since_restore: 15750
  timesteps_this_iter: 225
  timesteps_total: 15750
  training_iteration: 70
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     70 |          123.219 |       15750 |  1.36941 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-45-51
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.5708084510397498
  episode_reward_mean: 1.305002499474137
  episode_reward_min: 0.9493177619358646
  episodes_this_iter: 5
  episodes_total: 370
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.8
    learner:
      default_policy:
        cur_kl_coeff: 7.450580707946131e-10
        cur_lr: 4.999999873689376e-05
        entropy: 21.6612606048584
        entropy_coeff: 0.0
        kl: 0.007971016690135002
        policy_loss: -0.043978575617074966
        total_loss: -0.015804473310709
        vf_explained_var: 0.7495439648628235
        vf_loss: 0.028174102306365967
    load_time_ms: 0.858
    num_steps_sampled: 16650
    num_steps_trained: 16650
    sample_time_ms: 1410.062
    update_time_ms: 3.841
  iterations_since_restore: 74
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.65
    ram_util_percent: 77.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.9700879558352655
    mean_inference_ms: 0.752921734450452
    mean_processing_ms: 0.5469199566119665
  time_since_restore: 129.1415810585022
  time_this_iter_s: 1.4618291854858398
  time_total_s: 129.1415810585022
  timestamp: 1744206351
  timesteps_since_restore: 16650
  timesteps_this_iter: 225
  timesteps_total: 16650
  training_iteration: 74
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     74 |          129.142 |       16650 |    1.305 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-45-57
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.5543857527973501
  episode_reward_mean: 1.262261388038587
  episode_reward_min: 0.9493177619358646
  episodes_this_iter: 5
  episodes_total: 390
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.94
    learner:
      default_policy:
        cur_kl_coeff: 9.313225884932663e-11
        cur_lr: 4.999999873689376e-05
        entropy: 21.714143753051758
        entropy_coeff: 0.0
        kl: 0.014725561253726482
        policy_loss: -0.07102430611848831
        total_loss: -0.042551226913928986
        vf_explained_var: 0.770153820514679
        vf_loss: 0.028473079204559326
    load_time_ms: 0.864
    num_steps_sampled: 17550
    num_steps_trained: 17550
    sample_time_ms: 1380.16
    update_time_ms: 3.834
  iterations_since_restore: 78
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.5
    ram_util_percent: 77.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.920322979576715
    mean_inference_ms: 0.7477196831808876
    mean_processing_ms: 0.541475248918842
  time_since_restore: 135.11260151863098
  time_this_iter_s: 1.5440630912780762
  time_total_s: 135.11260151863098
  timestamp: 1744206357
  timesteps_since_restore: 17550
  timesteps_this_iter: 225
  timesteps_total: 17550
  training_iteration: 78
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     78 |          135.113 |       17550 |  1.26226 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-46-02
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.531503656179055
  episode_reward_mean: 1.2083619733690931
  episode_reward_min: 0.896605905628804
  episodes_this_iter: 5
  episodes_total: 405
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 88.906
    learner:
      default_policy:
        cur_kl_coeff: 4.6566129424663316e-11
        cur_lr: 4.999999873689376e-05
        entropy: 21.689855575561523
        entropy_coeff: 0.0
        kl: 0.008476579561829567
        policy_loss: -0.04547964781522751
        total_loss: -0.026151467114686966
        vf_explained_var: 0.7676825523376465
        vf_loss: 0.019328173249959946
    load_time_ms: 0.866
    num_steps_sampled: 18225
    num_steps_trained: 18225
    sample_time_ms: 1446.931
    update_time_ms: 3.929
  iterations_since_restore: 81
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.95
    ram_util_percent: 77.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.8892980114082745
    mean_inference_ms: 0.7445199245768793
    mean_processing_ms: 0.5381549101280144
  time_since_restore: 140.130366563797
  time_this_iter_s: 1.5733716487884521
  time_total_s: 140.130366563797
  timestamp: 1744206362
  timesteps_since_restore: 18225
  timesteps_this_iter: 225
  timesteps_total: 18225
  training_iteration: 81
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     81 |           140.13 |       18225 |  1.20836 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-46-08
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.531503656179055
  episode_reward_mean: 1.1541085083712854
  episode_reward_min: 0.8461753024582164
  episodes_this_iter: 5
  episodes_total: 425
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 88.227
    learner:
      default_policy:
        cur_kl_coeff: 2.3283064712331658e-11
        cur_lr: 4.999999873689376e-05
        entropy: 21.668609619140625
        entropy_coeff: 0.0
        kl: 0.013109113089740276
        policy_loss: -0.05929804593324661
        total_loss: -0.047613225877285004
        vf_explained_var: 0.8750632405281067
        vf_loss: 0.011684835888445377
    load_time_ms: 0.877
    num_steps_sampled: 19125
    num_steps_trained: 19125
    sample_time_ms: 1490.498
    update_time_ms: 3.717
  iterations_since_restore: 85
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.96666666666667
    ram_util_percent: 77.53333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.854096492993453
    mean_inference_ms: 0.7406826239455515
    mean_processing_ms: 0.5342703943981068
  time_since_restore: 146.4805347919464
  time_this_iter_s: 1.7839219570159912
  time_total_s: 146.4805347919464
  timestamp: 1744206368
  timesteps_since_restore: 19125
  timesteps_this_iter: 225
  timesteps_total: 19125
  training_iteration: 85
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     85 |          146.481 |       19125 |  1.15411 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-46-15
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.4562992825065637
  episode_reward_mean: 1.099044698552413
  episode_reward_min: 0.8121673023264087
  episodes_this_iter: 5
  episodes_total: 445
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.846
    learner:
      default_policy:
        cur_kl_coeff: 2.9103830890414573e-12
        cur_lr: 4.999999873689376e-05
        entropy: 21.520465850830078
        entropy_coeff: 0.0
        kl: 0.010755237191915512
        policy_loss: -0.05205037444829941
        total_loss: -0.0391891673207283
        vf_explained_var: 0.8386964797973633
        vf_loss: 0.012861205264925957
    load_time_ms: 0.829
    num_steps_sampled: 20025
    num_steps_trained: 20025
    sample_time_ms: 1471.733
    update_time_ms: 3.661
  iterations_since_restore: 89
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.2
    ram_util_percent: 77.6
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.823624540840963
    mean_inference_ms: 0.7370816934315734
    mean_processing_ms: 0.5309277332412701
  time_since_restore: 152.70005750656128
  time_this_iter_s: 1.5052709579467773
  time_total_s: 152.70005750656128
  timestamp: 1744206375
  timesteps_since_restore: 20025
  timesteps_this_iter: 225
  timesteps_total: 20025
  training_iteration: 89
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     89 |            152.7 |       20025 |  1.09904 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-46-21
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.3717662984441508
  episode_reward_mean: 1.0479609813761392
  episode_reward_min: 0.8121673023264087
  episodes_this_iter: 5
  episodes_total: 465
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.84
    learner:
      default_policy:
        cur_kl_coeff: 3.6379788613018216e-13
        cur_lr: 4.999999873689376e-05
        entropy: 21.324169158935547
        entropy_coeff: 0.0
        kl: 0.00878141075372696
        policy_loss: -0.03613366559147835
        total_loss: -0.028185110539197922
        vf_explained_var: 0.8989049792289734
        vf_loss: 0.007948548533022404
    load_time_ms: 0.858
    num_steps_sampled: 20925
    num_steps_trained: 20925
    sample_time_ms: 1496.401
    update_time_ms: 4.241
  iterations_since_restore: 93
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.166666666666664
    ram_util_percent: 77.8
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.800346022022552
    mean_inference_ms: 0.7341003363957852
    mean_processing_ms: 0.5283038972359848
  time_since_restore: 159.10350823402405
  time_this_iter_s: 1.5355398654937744
  time_total_s: 159.10350823402405
  timestamp: 1744206381
  timesteps_since_restore: 20925
  timesteps_this_iter: 225
  timesteps_total: 20925
  training_iteration: 93
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     93 |          159.104 |       20925 |  1.04796 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-46-28
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.261821150397929
  episode_reward_mean: 1.0011861096874477
  episode_reward_min: 0.7627282007751635
  episodes_this_iter: 5
  episodes_total: 485
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.543
    learner:
      default_policy:
        cur_kl_coeff: 9.094947153254554e-14
        cur_lr: 4.999999873689376e-05
        entropy: 21.352128982543945
        entropy_coeff: 0.0
        kl: 0.011493096128106117
        policy_loss: -0.05080519989132881
        total_loss: -0.03730466961860657
        vf_explained_var: 0.8272503018379211
        vf_loss: 0.01350052934139967
    load_time_ms: 0.914
    num_steps_sampled: 21825
    num_steps_trained: 21825
    sample_time_ms: 1493.439
    update_time_ms: 4.206
  iterations_since_restore: 97
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.5
    ram_util_percent: 77.8
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.784340396489527
    mean_inference_ms: 0.7320056874825451
    mean_processing_ms: 0.5261471319559681
  time_since_restore: 165.6038327217102
  time_this_iter_s: 1.7193748950958252
  time_total_s: 165.6038327217102
  timestamp: 1744206388
  timesteps_since_restore: 21825
  timesteps_this_iter: 225
  timesteps_total: 21825
  training_iteration: 97
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |     97 |          165.604 |       21825 |  1.00119 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-46-34
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.2321173060900583
  episode_reward_mean: 0.972420962284273
  episode_reward_min: 0.6877175001740081
  episodes_this_iter: 5
  episodes_total: 505
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.841
    learner:
      default_policy:
        cur_kl_coeff: 4.547473576627277e-14
        cur_lr: 4.999999873689376e-05
        entropy: 21.26338768005371
        entropy_coeff: 0.0
        kl: 0.01628178358078003
        policy_loss: -0.07149940729141235
        total_loss: -0.06392202526330948
        vf_explained_var: 0.8929244875907898
        vf_loss: 0.007577377371490002
    load_time_ms: 0.894
    num_steps_sampled: 22725
    num_steps_trained: 22725
    sample_time_ms: 1473.064
    update_time_ms: 4.328
  iterations_since_restore: 101
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.0
    ram_util_percent: 77.7
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.769625741198481
    mean_inference_ms: 0.7298157609689454
    mean_processing_ms: 0.5238710516700275
  time_since_restore: 171.79246044158936
  time_this_iter_s: 1.6030383110046387
  time_total_s: 171.79246044158936
  timestamp: 1744206394
  timesteps_since_restore: 22725
  timesteps_this_iter: 225
  timesteps_total: 22725
  training_iteration: 101
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    101 |          171.792 |       22725 | 0.972421 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-46-40
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.1358640403427258
  episode_reward_mean: 0.9392751634432435
  episode_reward_min: 0.6877175001740081
  episodes_this_iter: 5
  episodes_total: 525
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.636
    learner:
      default_policy:
        cur_kl_coeff: 4.547473576627277e-14
        cur_lr: 4.999999873689376e-05
        entropy: 20.955629348754883
        entropy_coeff: 0.0
        kl: 0.013049088418483734
        policy_loss: -0.058806411921978
        total_loss: -0.05110190436244011
        vf_explained_var: 0.8732666969299316
        vf_loss: 0.007704496383666992
    load_time_ms: 0.837
    num_steps_sampled: 23625
    num_steps_trained: 23625
    sample_time_ms: 1433.762
    update_time_ms: 3.89
  iterations_since_restore: 105
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.25
    ram_util_percent: 77.35
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.75447915908963
    mean_inference_ms: 0.7275783383558272
    mean_processing_ms: 0.5216644308473123
  time_since_restore: 177.7484974861145
  time_this_iter_s: 1.4443597793579102
  time_total_s: 177.7484974861145
  timestamp: 1744206400
  timesteps_since_restore: 23625
  timesteps_this_iter: 225
  timesteps_total: 23625
  training_iteration: 105
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    105 |          177.748 |       23625 | 0.939275 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-46-46
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.1358640403427258
  episode_reward_mean: 0.9133436122180113
  episode_reward_min: 0.6877175001740081
  episodes_this_iter: 5
  episodes_total: 545
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 92.275
    learner:
      default_policy:
        cur_kl_coeff: 2.2737367883136385e-14
        cur_lr: 4.999999873689376e-05
        entropy: 20.589134216308594
        entropy_coeff: 0.0
        kl: 0.012190624140202999
        policy_loss: -0.05700336769223213
        total_loss: -0.049939725548028946
        vf_explained_var: 0.8757264018058777
        vf_loss: 0.007063648663461208
    load_time_ms: 0.829
    num_steps_sampled: 24525
    num_steps_trained: 24525
    sample_time_ms: 1438.562
    update_time_ms: 3.919
  iterations_since_restore: 109
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.4
    ram_util_percent: 77.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.739789393002148
    mean_inference_ms: 0.7255276214478757
    mean_processing_ms: 0.5196890103394409
  time_since_restore: 184.1008791923523
  time_this_iter_s: 1.4697976112365723
  time_total_s: 184.1008791923523
  timestamp: 1744206406
  timesteps_since_restore: 24525
  timesteps_this_iter: 225
  timesteps_total: 24525
  training_iteration: 109
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    109 |          184.101 |       24525 | 0.913344 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-46-53
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.1358640403427258
  episode_reward_mean: 0.8894066290192224
  episode_reward_min: 0.6877175001740081
  episodes_this_iter: 5
  episodes_total: 565
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.295
    learner:
      default_policy:
        cur_kl_coeff: 2.2737367883136385e-14
        cur_lr: 4.999999873689376e-05
        entropy: 20.290348052978516
        entropy_coeff: 0.0
        kl: 0.015300622209906578
        policy_loss: -0.05354391410946846
        total_loss: -0.044599153101444244
        vf_explained_var: 0.8372928500175476
        vf_loss: 0.008944762870669365
    load_time_ms: 0.859
    num_steps_sampled: 25425
    num_steps_trained: 25425
    sample_time_ms: 1461.974
    update_time_ms: 3.844
  iterations_since_restore: 113
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.2
    ram_util_percent: 77.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.724219341827052
    mean_inference_ms: 0.7234226846305956
    mean_processing_ms: 0.5175803455060662
  time_since_restore: 190.42782044410706
  time_this_iter_s: 1.8477380275726318
  time_total_s: 190.42782044410706
  timestamp: 1744206413
  timesteps_since_restore: 25425
  timesteps_this_iter: 225
  timesteps_total: 25425
  training_iteration: 113
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    113 |          190.428 |       25425 | 0.889407 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-46-59
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.1145546733885496
  episode_reward_mean: 0.8704116972234579
  episode_reward_min: 0.6877175001740081
  episodes_this_iter: 5
  episodes_total: 585
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.709
    learner:
      default_policy:
        cur_kl_coeff: 1.1368683941568192e-14
        cur_lr: 4.999999873689376e-05
        entropy: 20.138748168945312
        entropy_coeff: 0.0
        kl: 0.013633357360959053
        policy_loss: -0.05936341732740402
        total_loss: -0.05055379122495651
        vf_explained_var: 0.8475200533866882
        vf_loss: 0.008809617720544338
    load_time_ms: 0.9
    num_steps_sampled: 26325
    num_steps_trained: 26325
    sample_time_ms: 1421.127
    update_time_ms: 3.871
  iterations_since_restore: 117
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.8
    ram_util_percent: 77.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.707915544958102
    mean_inference_ms: 0.7211314174659837
    mean_processing_ms: 0.5154683858729483
  time_since_restore: 196.3230118751526
  time_this_iter_s: 1.4308829307556152
  time_total_s: 196.3230118751526
  timestamp: 1744206419
  timesteps_since_restore: 26325
  timesteps_this_iter: 225
  timesteps_total: 26325
  training_iteration: 117
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    117 |          196.323 |       26325 | 0.870412 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-47-05
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.9937271826942773
  episode_reward_mean: 0.8400824464907507
  episode_reward_min: 0.6627899848857237
  episodes_this_iter: 5
  episodes_total: 605
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.085
    learner:
      default_policy:
        cur_kl_coeff: 1.1368683941568192e-14
        cur_lr: 4.999999873689376e-05
        entropy: 20.197582244873047
        entropy_coeff: 0.0
        kl: 0.015578019432723522
        policy_loss: -0.06234877184033394
        total_loss: -0.058085061609745026
        vf_explained_var: 0.9155291318893433
        vf_loss: 0.0042637065052986145
    load_time_ms: 0.948
    num_steps_sampled: 27225
    num_steps_trained: 27225
    sample_time_ms: 1467.666
    update_time_ms: 3.84
  iterations_since_restore: 121
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.25
    ram_util_percent: 77.1
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.692779486628797
    mean_inference_ms: 0.7190712612539762
    mean_processing_ms: 0.5136831053730504
  time_since_restore: 202.802264213562
  time_this_iter_s: 1.558149814605713
  time_total_s: 202.802264213562
  timestamp: 1744206425
  timesteps_since_restore: 27225
  timesteps_this_iter: 225
  timesteps_total: 27225
  training_iteration: 121
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    121 |          202.802 |       27225 | 0.840082 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-47-12
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.9937271826942773
  episode_reward_mean: 0.8226066860539808
  episode_reward_min: 0.6627899848857237
  episodes_this_iter: 5
  episodes_total: 625
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.715
    learner:
      default_policy:
        cur_kl_coeff: 1.1368683941568192e-14
        cur_lr: 4.999999873689376e-05
        entropy: 19.968547821044922
        entropy_coeff: 0.0
        kl: 0.017221415415406227
        policy_loss: -0.07017772644758224
        total_loss: -0.06463095545768738
        vf_explained_var: 0.8938226699829102
        vf_loss: 0.005546778440475464
    load_time_ms: 0.901
    num_steps_sampled: 28125
    num_steps_trained: 28125
    sample_time_ms: 1483.228
    update_time_ms: 3.733
  iterations_since_restore: 125
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.15
    ram_util_percent: 77.4
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.681688813579613
    mean_inference_ms: 0.7176431256667978
    mean_processing_ms: 0.5123438104751902
  time_since_restore: 209.2050998210907
  time_this_iter_s: 1.4196724891662598
  time_total_s: 209.2050998210907
  timestamp: 1744206432
  timesteps_since_restore: 28125
  timesteps_this_iter: 225
  timesteps_total: 28125
  training_iteration: 125
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    125 |          209.205 |       28125 | 0.822607 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-47-17
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.9937271826942773
  episode_reward_mean: 0.8099429374086242
  episode_reward_min: 0.6627899848857237
  episodes_this_iter: 5
  episodes_total: 645
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.3
    learner:
      default_policy:
        cur_kl_coeff: 5.684341970784096e-15
        cur_lr: 4.999999873689376e-05
        entropy: 19.792356491088867
        entropy_coeff: 0.0
        kl: 0.012475088238716125
        policy_loss: -0.05194317176938057
        total_loss: -0.0458528995513916
        vf_explained_var: 0.8824154138565063
        vf_loss: 0.006090268492698669
    load_time_ms: 0.912
    num_steps_sampled: 29025
    num_steps_trained: 29025
    sample_time_ms: 1443.801
    update_time_ms: 3.615
  iterations_since_restore: 129
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.75
    ram_util_percent: 77.4
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.668522084241016
    mean_inference_ms: 0.7160380847195171
    mean_processing_ms: 0.5108885997169171
  time_since_restore: 215.091002702713
  time_this_iter_s: 1.5047295093536377
  time_total_s: 215.091002702713
  timestamp: 1744206437
  timesteps_since_restore: 29025
  timesteps_this_iter: 225
  timesteps_total: 29025
  training_iteration: 129
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    129 |          215.091 |       29025 | 0.809943 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-47-24
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.9937271826942773
  episode_reward_mean: 0.793778806899784
  episode_reward_min: 0.6627899848857237
  episodes_this_iter: 5
  episodes_total: 665
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 92.805
    learner:
      default_policy:
        cur_kl_coeff: 5.684341970784096e-15
        cur_lr: 4.999999873689376e-05
        entropy: 19.400531768798828
        entropy_coeff: 0.0
        kl: 0.020574847236275673
        policy_loss: -0.06482050567865372
        total_loss: -0.059963613748550415
        vf_explained_var: 0.8984403610229492
        vf_loss: 0.0048568896017968655
    load_time_ms: 0.992
    num_steps_sampled: 29925
    num_steps_trained: 29925
    sample_time_ms: 1388.62
    update_time_ms: 3.748
  iterations_since_restore: 133
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.133333333333333
    ram_util_percent: 77.4
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.655508878510818
    mean_inference_ms: 0.7146170287248657
    mean_processing_ms: 0.5096492336765905
  time_since_restore: 221.1624937057495
  time_this_iter_s: 1.5902693271636963
  time_total_s: 221.1624937057495
  timestamp: 1744206444
  timesteps_since_restore: 29925
  timesteps_this_iter: 225
  timesteps_total: 29925
  training_iteration: 133
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    133 |          221.162 |       29925 | 0.793779 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-47-30
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.8835862906544373
  episode_reward_mean: 0.7781950899947462
  episode_reward_min: 0.6627899848857237
  episodes_this_iter: 5
  episodes_total: 685
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.375
    learner:
      default_policy:
        cur_kl_coeff: 5.684341970784096e-15
        cur_lr: 4.999999873689376e-05
        entropy: 19.28045654296875
        entropy_coeff: 0.0
        kl: 0.018487107008695602
        policy_loss: -0.07701019197702408
        total_loss: -0.0731644406914711
        vf_explained_var: 0.9191314578056335
        vf_loss: 0.0038457668852061033
    load_time_ms: 0.964
    num_steps_sampled: 30825
    num_steps_trained: 30825
    sample_time_ms: 1419.423
    update_time_ms: 3.654
  iterations_since_restore: 137
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.299999999999997
    ram_util_percent: 77.4
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.6437572677011305
    mean_inference_ms: 0.713501403553243
    mean_processing_ms: 0.5087505675955518
  time_since_restore: 227.35264468193054
  time_this_iter_s: 1.4576246738433838
  time_total_s: 227.35264468193054
  timestamp: 1744206450
  timesteps_since_restore: 30825
  timesteps_this_iter: 225
  timesteps_total: 30825
  training_iteration: 137
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    137 |          227.353 |       30825 | 0.778195 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-47-36
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.879387189622593
  episode_reward_mean: 0.7794305471646623
  episode_reward_min: 0.6725471021077558
  episodes_this_iter: 5
  episodes_total: 705
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 88.608
    learner:
      default_policy:
        cur_kl_coeff: 5.684341970784096e-15
        cur_lr: 4.999999873689376e-05
        entropy: 19.46868896484375
        entropy_coeff: 0.0
        kl: 0.017814218997955322
        policy_loss: -0.06002919748425484
        total_loss: -0.05428818613290787
        vf_explained_var: 0.8768124580383301
        vf_loss: 0.005740999709814787
    load_time_ms: 0.886
    num_steps_sampled: 31725
    num_steps_trained: 31725
    sample_time_ms: 1407.454
    update_time_ms: 3.719
  iterations_since_restore: 141
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.2
    ram_util_percent: 77.4
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.6297494795109655
    mean_inference_ms: 0.712326405043656
    mean_processing_ms: 0.5077249220858027
  time_since_restore: 233.1707980632782
  time_this_iter_s: 1.4236986637115479
  time_total_s: 233.1707980632782
  timestamp: 1744206456
  timesteps_since_restore: 31725
  timesteps_this_iter: 225
  timesteps_total: 31725
  training_iteration: 141
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    141 |          233.171 |       31725 | 0.779431 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-47-42
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.8744936608712233
  episode_reward_mean: 0.771551202442204
  episode_reward_min: 0.6697383336549807
  episodes_this_iter: 5
  episodes_total: 725
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.628
    learner:
      default_policy:
        cur_kl_coeff: 5.684341970784096e-15
        cur_lr: 4.999999873689376e-05
        entropy: 19.304664611816406
        entropy_coeff: 0.0
        kl: 0.010473504662513733
        policy_loss: -0.04167905077338219
        total_loss: -0.036341164261102676
        vf_explained_var: 0.8888656497001648
        vf_loss: 0.005337889306247234
    load_time_ms: 0.804
    num_steps_sampled: 32625
    num_steps_trained: 32625
    sample_time_ms: 1370.076
    update_time_ms: 3.664
  iterations_since_restore: 145
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.1
    ram_util_percent: 77.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.6126051402630965
    mean_inference_ms: 0.7107852216290333
    mean_processing_ms: 0.5065177827104559
  time_since_restore: 239.14278435707092
  time_this_iter_s: 1.578747272491455
  time_total_s: 239.14278435707092
  timestamp: 1744206462
  timesteps_since_restore: 32625
  timesteps_this_iter: 225
  timesteps_total: 32625
  training_iteration: 145
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    145 |          239.143 |       32625 | 0.771551 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-47-47
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.8744936608712233
  episode_reward_mean: 0.7606970193628889
  episode_reward_min: 0.6072936002124733
  episodes_this_iter: 5
  episodes_total: 745
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.164
    learner:
      default_policy:
        cur_kl_coeff: 5.684341970784096e-15
        cur_lr: 4.999999873689376e-05
        entropy: 19.304309844970703
        entropy_coeff: 0.0
        kl: 0.015166307799518108
        policy_loss: -0.044796768575906754
        total_loss: -0.042265456169843674
        vf_explained_var: 0.9436233639717102
        vf_loss: 0.0025313093792647123
    load_time_ms: 0.855
    num_steps_sampled: 33525
    num_steps_trained: 33525
    sample_time_ms: 1365.436
    update_time_ms: 3.601
  iterations_since_restore: 149
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.4
    ram_util_percent: 77.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.596406374881692
    mean_inference_ms: 0.7093946898481928
    mean_processing_ms: 0.5054683625481199
  time_since_restore: 244.870037317276
  time_this_iter_s: 1.388995885848999
  time_total_s: 244.870037317276
  timestamp: 1744206467
  timesteps_since_restore: 33525
  timesteps_this_iter: 225
  timesteps_total: 33525
  training_iteration: 149
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    149 |           244.87 |       33525 | 0.760697 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-47-54
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.8744936608712233
  episode_reward_mean: 0.7449463790395794
  episode_reward_min: 0.6072936002124733
  episodes_this_iter: 5
  episodes_total: 765
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.567
    learner:
      default_policy:
        cur_kl_coeff: 5.684341970784096e-15
        cur_lr: 4.999999873689376e-05
        entropy: 19.342655181884766
        entropy_coeff: 0.0
        kl: 0.011243118904531002
        policy_loss: -0.04516887664794922
        total_loss: -0.04170466214418411
        vf_explained_var: 0.912955105304718
        vf_loss: 0.003464206587523222
    load_time_ms: 0.917
    num_steps_sampled: 34425
    num_steps_trained: 34425
    sample_time_ms: 1425.341
    update_time_ms: 3.741
  iterations_since_restore: 153
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.03333333333333
    ram_util_percent: 77.13333333333334
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.58255330239664
    mean_inference_ms: 0.7082542196169929
    mean_processing_ms: 0.5045886241330302
  time_since_restore: 251.31844782829285
  time_this_iter_s: 1.6113646030426025
  time_total_s: 251.31844782829285
  timestamp: 1744206474
  timesteps_since_restore: 34425
  timesteps_this_iter: 225
  timesteps_total: 34425
  training_iteration: 153
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    153 |          251.318 |       34425 | 0.744946 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-48-00
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.8744936608712233
  episode_reward_mean: 0.7305688599361776
  episode_reward_min: 0.5944388224343679
  episodes_this_iter: 5
  episodes_total: 785
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 92.453
    learner:
      default_policy:
        cur_kl_coeff: 5.684341970784096e-15
        cur_lr: 4.999999873689376e-05
        entropy: 19.389162063598633
        entropy_coeff: 0.0
        kl: 0.02171461470425129
        policy_loss: -0.07759996503591537
        total_loss: -0.07395215332508087
        vf_explained_var: 0.9099399447441101
        vf_loss: 0.0036478047259151936
    load_time_ms: 0.908
    num_steps_sampled: 35325
    num_steps_trained: 35325
    sample_time_ms: 1414.6
    update_time_ms: 3.897
  iterations_since_restore: 157
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.95
    ram_util_percent: 77.1
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.567918769555175
    mean_inference_ms: 0.7069617233516712
    mean_processing_ms: 0.5034964036242738
  time_since_restore: 257.2247803211212
  time_this_iter_s: 1.44038724899292
  time_total_s: 257.2247803211212
  timestamp: 1744206480
  timesteps_since_restore: 35325
  timesteps_this_iter: 225
  timesteps_total: 35325
  training_iteration: 157
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    157 |          257.225 |       35325 | 0.730569 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-48-06
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.8254866665025019
  episode_reward_mean: 0.7121669306383873
  episode_reward_min: 0.5944388224343679
  episodes_this_iter: 5
  episodes_total: 805
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 92.314
    learner:
      default_policy:
        cur_kl_coeff: 5.684341970784096e-15
        cur_lr: 4.999999873689376e-05
        entropy: 19.151531219482422
        entropy_coeff: 0.0
        kl: 0.02379770018160343
        policy_loss: -0.0770852342247963
        total_loss: -0.07400880753993988
        vf_explained_var: 0.9174893498420715
        vf_loss: 0.003076420398429036
    load_time_ms: 0.881
    num_steps_sampled: 36225
    num_steps_trained: 36225
    sample_time_ms: 1375.514
    update_time_ms: 3.867
  iterations_since_restore: 161
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.3
    ram_util_percent: 77.1
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.554047348213567
    mean_inference_ms: 0.7057507896513322
    mean_processing_ms: 0.5024167852455247
  time_since_restore: 263.01112055778503
  time_this_iter_s: 1.484675407409668
  time_total_s: 263.01112055778503
  timestamp: 1744206486
  timesteps_since_restore: 36225
  timesteps_this_iter: 225
  timesteps_total: 36225
  training_iteration: 161
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    161 |          263.011 |       36225 | 0.712167 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-48-12
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.7869933151288677
  episode_reward_mean: 0.6916717627921283
  episode_reward_min: 0.5944388224343679
  episodes_this_iter: 5
  episodes_total: 825
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.986
    learner:
      default_policy:
        cur_kl_coeff: 5.684341970784096e-15
        cur_lr: 4.999999873689376e-05
        entropy: 19.130474090576172
        entropy_coeff: 0.0
        kl: 0.021620137616991997
        policy_loss: -0.08100748807191849
        total_loss: -0.07909273356199265
        vf_explained_var: 0.9448615908622742
        vf_loss: 0.001914745895192027
    load_time_ms: 0.869
    num_steps_sampled: 37125
    num_steps_trained: 37125
    sample_time_ms: 1395.157
    update_time_ms: 3.716
  iterations_since_restore: 165
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.1
    ram_util_percent: 77.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.542640108660709
    mean_inference_ms: 0.7049009811884271
    mean_processing_ms: 0.501466479739876
  time_since_restore: 269.2208297252655
  time_this_iter_s: 1.4403188228607178
  time_total_s: 269.2208297252655
  timestamp: 1744206492
  timesteps_since_restore: 37125
  timesteps_this_iter: 225
  timesteps_total: 37125
  training_iteration: 165
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    165 |          269.221 |       37125 | 0.691672 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-48-18
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.777655728370085
  episode_reward_mean: 0.6751628154040462
  episode_reward_min: 0.5944388224343679
  episodes_this_iter: 5
  episodes_total: 845
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.594
    learner:
      default_policy:
        cur_kl_coeff: 5.684341970784096e-15
        cur_lr: 4.999999873689376e-05
        entropy: 19.195756912231445
        entropy_coeff: 0.0
        kl: 0.011227590031921864
        policy_loss: -0.04663190245628357
        total_loss: -0.04454705864191055
        vf_explained_var: 0.940170168876648
        vf_loss: 0.002084848005324602
    load_time_ms: 0.816
    num_steps_sampled: 38025
    num_steps_trained: 38025
    sample_time_ms: 1408.0
    update_time_ms: 3.719
  iterations_since_restore: 169
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.5
    ram_util_percent: 77.7
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.531847790574491
    mean_inference_ms: 0.7041209454993183
    mean_processing_ms: 0.5003619354628417
  time_since_restore: 275.1772813796997
  time_this_iter_s: 1.5034613609313965
  time_total_s: 275.1772813796997
  timestamp: 1744206498
  timesteps_since_restore: 38025
  timesteps_this_iter: 225
  timesteps_total: 38025
  training_iteration: 169
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    169 |          275.177 |       38025 | 0.675163 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-48-24
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.777655728370085
  episode_reward_mean: 0.6597253507961729
  episode_reward_min: 0.524006190688734
  episodes_this_iter: 5
  episodes_total: 865
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.775
    learner:
      default_policy:
        cur_kl_coeff: 5.684341970784096e-15
        cur_lr: 4.999999873689376e-05
        entropy: 19.30527114868164
        entropy_coeff: 0.0
        kl: 0.014010434038937092
        policy_loss: -0.06098243594169617
        total_loss: -0.05872257426381111
        vf_explained_var: 0.9356498718261719
        vf_loss: 0.002259868895635009
    load_time_ms: 0.897
    num_steps_sampled: 38925
    num_steps_trained: 38925
    sample_time_ms: 1375.905
    update_time_ms: 3.685
  iterations_since_restore: 173
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.566666666666666
    ram_util_percent: 77.7
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.520297798532979
    mean_inference_ms: 0.7032042508257859
    mean_processing_ms: 0.4990782110331604
  time_since_restore: 281.14290499687195
  time_this_iter_s: 1.5775768756866455
  time_total_s: 281.14290499687195
  timestamp: 1744206504
  timesteps_since_restore: 38925
  timesteps_this_iter: 225
  timesteps_total: 38925
  training_iteration: 173
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    173 |          281.143 |       38925 | 0.659725 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-48-30
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.764219335133853
  episode_reward_mean: 0.6444430988502852
  episode_reward_min: 0.524006190688734
  episodes_this_iter: 5
  episodes_total: 880
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 96.683
    learner:
      default_policy:
        cur_kl_coeff: 5.684341970784096e-15
        cur_lr: 4.999999873689376e-05
        entropy: 19.285152435302734
        entropy_coeff: 0.0
        kl: 0.01756196841597557
        policy_loss: -0.07510076463222504
        total_loss: -0.07309368997812271
        vf_explained_var: 0.9330424070358276
        vf_loss: 0.0020070639438927174
    load_time_ms: 0.904
    num_steps_sampled: 39600
    num_steps_trained: 39600
    sample_time_ms: 1598.872
    update_time_ms: 3.804
  iterations_since_restore: 176
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.96666666666667
    ram_util_percent: 78.03333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.516372459887273
    mean_inference_ms: 0.7032836210207049
    mean_processing_ms: 0.49869899848971444
  time_since_restore: 287.710410118103
  time_this_iter_s: 1.9109413623809814
  time_total_s: 287.710410118103
  timestamp: 1744206510
  timesteps_since_restore: 39600
  timesteps_this_iter: 225
  timesteps_total: 39600
  training_iteration: 176
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    176 |           287.71 |       39600 | 0.644443 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-48-36
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.7297125128105981
  episode_reward_mean: 0.6295032560957262
  episode_reward_min: 0.524006190688734
  episodes_this_iter: 5
  episodes_total: 895
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 97.091
    learner:
      default_policy:
        cur_kl_coeff: 5.684341970784096e-15
        cur_lr: 4.999999873689376e-05
        entropy: 19.394779205322266
        entropy_coeff: 0.0
        kl: 0.014253859408199787
        policy_loss: -0.05886251851916313
        total_loss: -0.05709173157811165
        vf_explained_var: 0.9365580677986145
        vf_loss: 0.0017707934603095055
    load_time_ms: 0.942
    num_steps_sampled: 40275
    num_steps_trained: 40275
    sample_time_ms: 1669.661
    update_time_ms: 3.686
  iterations_since_restore: 179
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.450000000000003
    ram_util_percent: 78.0
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.516127344928894
    mean_inference_ms: 0.7039589672732248
    mean_processing_ms: 0.4987883217922418
  time_since_restore: 292.9255442619324
  time_this_iter_s: 1.7035026550292969
  time_total_s: 292.9255442619324
  timestamp: 1744206516
  timesteps_since_restore: 40275
  timesteps_this_iter: 225
  timesteps_total: 40275
  training_iteration: 179
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    179 |          292.926 |       40275 | 0.629503 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-48-41
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.6938886149542042
  episode_reward_mean: 0.6176286764007337
  episode_reward_min: 0.524006190688734
  episodes_this_iter: 5
  episodes_total: 910
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 98.072
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: 19.307979583740234
        entropy_coeff: 0.0
        kl: 0.016297582536935806
        policy_loss: -0.05767879635095596
        total_loss: -0.05599202588200569
        vf_explained_var: 0.939754843711853
        vf_loss: 0.0016867760568857193
    load_time_ms: 0.927
    num_steps_sampled: 40950
    num_steps_trained: 40950
    sample_time_ms: 1727.582
    update_time_ms: 3.752
  iterations_since_restore: 182
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.333333333333332
    ram_util_percent: 77.1
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.518052800771487
    mean_inference_ms: 0.7049670043442723
    mean_processing_ms: 0.4991238015042833
  time_since_restore: 297.9028811454773
  time_this_iter_s: 1.4395415782928467
  time_total_s: 297.9028811454773
  timestamp: 1744206521
  timesteps_since_restore: 40950
  timesteps_this_iter: 225
  timesteps_total: 40950
  training_iteration: 182
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    182 |          297.903 |       40950 | 0.617629 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-48-46
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.6927173677336513
  episode_reward_mean: 0.6005142172418465
  episode_reward_min: 0.5009396589088593
  episodes_this_iter: 5
  episodes_total: 930
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 93.17
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: 19.191686630249023
        entropy_coeff: 0.0
        kl: 0.02101029083132744
        policy_loss: -0.06410800665616989
        total_loss: -0.06245610862970352
        vf_explained_var: 0.9345016479492188
        vf_loss: 0.001651905127801001
    load_time_ms: 0.869
    num_steps_sampled: 41850
    num_steps_trained: 41850
    sample_time_ms: 1495.208
    update_time_ms: 3.683
  iterations_since_restore: 186
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.799999999999997
    ram_util_percent: 76.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.5193324615743675
    mean_inference_ms: 0.70609777388303
    mean_processing_ms: 0.49949728054646797
  time_since_restore: 303.6728484630585
  time_this_iter_s: 1.446277141571045
  time_total_s: 303.6728484630585
  timestamp: 1744206526
  timesteps_since_restore: 41850
  timesteps_this_iter: 225
  timesteps_total: 41850
  training_iteration: 186
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    186 |          303.673 |       41850 | 0.600514 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-48-52
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.6856424777592951
  episode_reward_mean: 0.5842301246969586
  episode_reward_min: 0.5009396589088593
  episodes_this_iter: 5
  episodes_total: 950
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.82
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: 18.877872467041016
        entropy_coeff: 0.0
        kl: 0.011389178223907948
        policy_loss: -0.055011212825775146
        total_loss: -0.053896017372608185
        vf_explained_var: 0.9563946723937988
        vf_loss: 0.0011152013903483748
    load_time_ms: 0.832
    num_steps_sampled: 42750
    num_steps_trained: 42750
    sample_time_ms: 1371.04
    update_time_ms: 3.921
  iterations_since_restore: 190
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.65
    ram_util_percent: 77.0
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.5209068941143915
    mean_inference_ms: 0.7071436418076551
    mean_processing_ms: 0.5000791761372212
  time_since_restore: 309.6334595680237
  time_this_iter_s: 1.4056580066680908
  time_total_s: 309.6334595680237
  timestamp: 1744206532
  timesteps_since_restore: 42750
  timesteps_this_iter: 225
  timesteps_total: 42750
  training_iteration: 190
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    190 |          309.633 |       42750 |  0.58423 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-48-58
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.6673318001685288
  episode_reward_mean: 0.5656497397277319
  episode_reward_min: 0.4534082326801813
  episodes_this_iter: 5
  episodes_total: 970
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 92.876
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: 18.680908203125
        entropy_coeff: 0.0
        kl: 0.03230936825275421
        policy_loss: -0.08674353361129761
        total_loss: -0.08586117625236511
        vf_explained_var: 0.9617019891738892
        vf_loss: 0.0008823491516523063
    load_time_ms: 0.863
    num_steps_sampled: 43650
    num_steps_trained: 43650
    sample_time_ms: 1365.423
    update_time_ms: 3.874
  iterations_since_restore: 194
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.75
    ram_util_percent: 76.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.521111396642763
    mean_inference_ms: 0.708029638892691
    mean_processing_ms: 0.5006382197304423
  time_since_restore: 315.3949031829834
  time_this_iter_s: 1.4263865947723389
  time_total_s: 315.3949031829834
  timestamp: 1744206538
  timesteps_since_restore: 43650
  timesteps_this_iter: 225
  timesteps_total: 43650
  training_iteration: 194
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    194 |          315.395 |       43650 |  0.56565 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-49-04
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.6365011880884517
  episode_reward_mean: 0.5501584903308541
  episode_reward_min: 0.4534082326801813
  episodes_this_iter: 5
  episodes_total: 990
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.366
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: 18.391613006591797
        entropy_coeff: 0.0
        kl: 0.015574258752167225
        policy_loss: -0.06071857735514641
        total_loss: -0.05982900410890579
        vf_explained_var: 0.9598008990287781
        vf_loss: 0.0008895721985027194
    load_time_ms: 0.911
    num_steps_sampled: 44550
    num_steps_trained: 44550
    sample_time_ms: 1365.454
    update_time_ms: 3.833
  iterations_since_restore: 198
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.5
    ram_util_percent: 76.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.513452390654943
    mean_inference_ms: 0.7075601343081314
    mean_processing_ms: 0.5002926124147639
  time_since_restore: 321.31522583961487
  time_this_iter_s: 1.5141170024871826
  time_total_s: 321.31522583961487
  timestamp: 1744206544
  timesteps_since_restore: 44550
  timesteps_this_iter: 225
  timesteps_total: 44550
  training_iteration: 198
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    198 |          321.315 |       44550 | 0.550158 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-49-10
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.6365011880884517
  episode_reward_mean: 0.533034799423981
  episode_reward_min: 0.4534082326801813
  episodes_this_iter: 5
  episodes_total: 1010
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.957
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: 18.367895126342773
        entropy_coeff: 0.0
        kl: 0.016538074240088463
        policy_loss: -0.054433126002550125
        total_loss: -0.05290579795837402
        vf_explained_var: 0.9265727996826172
        vf_loss: 0.001527338637970388
    load_time_ms: 0.882
    num_steps_sampled: 45450
    num_steps_trained: 45450
    sample_time_ms: 1369.949
    update_time_ms: 3.72
  iterations_since_restore: 202
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.8
    ram_util_percent: 77.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.502092228813547
    mean_inference_ms: 0.7064702462482608
    mean_processing_ms: 0.4995136597104829
  time_since_restore: 327.2530708312988
  time_this_iter_s: 1.4634201526641846
  time_total_s: 327.2530708312988
  timestamp: 1744206550
  timesteps_since_restore: 45450
  timesteps_this_iter: 225
  timesteps_total: 45450
  training_iteration: 202
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    202 |          327.253 |       45450 | 0.533035 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-49-16
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.5896536485680748
  episode_reward_mean: 0.5209374602326889
  episode_reward_min: 0.4534082326801813
  episodes_this_iter: 5
  episodes_total: 1030
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 87.822
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: 17.876262664794922
        entropy_coeff: 0.0
        kl: 0.01888379454612732
        policy_loss: -0.057864706963300705
        total_loss: -0.05673154443502426
        vf_explained_var: 0.9475275874137878
        vf_loss: 0.0011331748683005571
    load_time_ms: 0.894
    num_steps_sampled: 46350
    num_steps_trained: 46350
    sample_time_ms: 1382.214
    update_time_ms: 3.683
  iterations_since_restore: 206
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.75
    ram_util_percent: 77.1
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.491360905908233
    mean_inference_ms: 0.7054033084823277
    mean_processing_ms: 0.49870573255210543
  time_since_restore: 333.1754832267761
  time_this_iter_s: 1.532149314880371
  time_total_s: 333.1754832267761
  timestamp: 1744206556
  timesteps_since_restore: 46350
  timesteps_this_iter: 225
  timesteps_total: 46350
  training_iteration: 206
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    206 |          333.175 |       46350 | 0.520937 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-49-22
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.5734918589748916
  episode_reward_mean: 0.5090450636491288
  episode_reward_min: 0.4407610353093102
  episodes_this_iter: 5
  episodes_total: 1050
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.966
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: 17.914573669433594
        entropy_coeff: 0.0
        kl: 0.022249383851885796
        policy_loss: -0.06534136831760406
        total_loss: -0.06394652277231216
        vf_explained_var: 0.9325616955757141
        vf_loss: 0.0013948417035862803
    load_time_ms: 0.888
    num_steps_sampled: 47250
    num_steps_trained: 47250
    sample_time_ms: 1371.813
    update_time_ms: 3.765
  iterations_since_restore: 210
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.9
    ram_util_percent: 77.1
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.4806762557811
    mean_inference_ms: 0.7043504267794914
    mean_processing_ms: 0.49779038283526345
  time_since_restore: 338.93095231056213
  time_this_iter_s: 1.4542124271392822
  time_total_s: 338.93095231056213
  timestamp: 1744206562
  timesteps_since_restore: 47250
  timesteps_this_iter: 225
  timesteps_total: 47250
  training_iteration: 210
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    210 |          338.931 |       47250 | 0.509045 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-49-28
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.5677133263816164
  episode_reward_mean: 0.5055053342466824
  episode_reward_min: 0.4407610353093102
  episodes_this_iter: 5
  episodes_total: 1070
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.11
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: 17.931705474853516
        entropy_coeff: 0.0
        kl: 0.022299891337752342
        policy_loss: -0.06285407394170761
        total_loss: -0.061922986060380936
        vf_explained_var: 0.9580373764038086
        vf_loss: 0.0009310871246270835
    load_time_ms: 0.885
    num_steps_sampled: 48150
    num_steps_trained: 48150
    sample_time_ms: 1361.88
    update_time_ms: 3.712
  iterations_since_restore: 214
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.35
    ram_util_percent: 77.05
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.4706135441327115
    mean_inference_ms: 0.7033260870659487
    mean_processing_ms: 0.49688924642474425
  time_since_restore: 344.86183190345764
  time_this_iter_s: 1.5280909538269043
  time_total_s: 344.86183190345764
  timestamp: 1744206568
  timesteps_since_restore: 48150
  timesteps_this_iter: 225
  timesteps_total: 48150
  training_iteration: 214
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    214 |          344.862 |       48150 | 0.505505 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-49-34
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.5677133263816164
  episode_reward_mean: 0.49971216658724166
  episode_reward_min: 0.43986833126527075
  episodes_this_iter: 5
  episodes_total: 1090
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 92.379
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: 17.82956314086914
        entropy_coeff: 0.0
        kl: 0.021983325481414795
        policy_loss: -0.0591132715344429
        total_loss: -0.057940781116485596
        vf_explained_var: 0.9423822164535522
        vf_loss: 0.001172484247945249
    load_time_ms: 0.868
    num_steps_sampled: 49050
    num_steps_trained: 49050
    sample_time_ms: 1392.88
    update_time_ms: 3.713
  iterations_since_restore: 218
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.900000000000002
    ram_util_percent: 77.0
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.461482625917941
    mean_inference_ms: 0.7024027819180156
    mean_processing_ms: 0.4959819342752265
  time_since_restore: 350.9952554702759
  time_this_iter_s: 1.6488621234893799
  time_total_s: 350.9952554702759
  timestamp: 1744206574
  timesteps_since_restore: 49050
  timesteps_this_iter: 225
  timesteps_total: 49050
  training_iteration: 218
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    218 |          350.995 |       49050 | 0.499712 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-49-40
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.5677133263816164
  episode_reward_mean: 0.4932256526892516
  episode_reward_min: 0.4320214937497128
  episodes_this_iter: 5
  episodes_total: 1110
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 92.526
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: 17.921611785888672
        entropy_coeff: 0.0
        kl: 0.019305994734168053
        policy_loss: -0.06352653354406357
        total_loss: -0.06305204331874847
        vf_explained_var: 0.9740891456604004
        vf_loss: 0.0004744931939058006
    load_time_ms: 0.878
    num_steps_sampled: 49950
    num_steps_trained: 49950
    sample_time_ms: 1405.89
    update_time_ms: 3.583
  iterations_since_restore: 222
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.8
    ram_util_percent: 76.8
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.4531702236580735
    mean_inference_ms: 0.7015044863227553
    mean_processing_ms: 0.49510182988473983
  time_since_restore: 356.9411976337433
  time_this_iter_s: 1.5057194232940674
  time_total_s: 356.9411976337433
  timestamp: 1744206580
  timesteps_since_restore: 49950
  timesteps_this_iter: 225
  timesteps_total: 49950
  training_iteration: 222
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    222 |          356.941 |       49950 | 0.493226 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-49-46
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.5677133263816164
  episode_reward_mean: 0.48585745863968993
  episode_reward_min: 0.4276708857927879
  episodes_this_iter: 5
  episodes_total: 1130
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.39
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: 18.012737274169922
        entropy_coeff: 0.0
        kl: 0.021684661507606506
        policy_loss: -0.0657758042216301
        total_loss: -0.06474202871322632
        vf_explained_var: 0.943557620048523
        vf_loss: 0.0010337803978472948
    load_time_ms: 0.832
    num_steps_sampled: 50850
    num_steps_trained: 50850
    sample_time_ms: 1423.901
    update_time_ms: 3.546
  iterations_since_restore: 226
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.75
    ram_util_percent: 76.8
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.445560742315892
    mean_inference_ms: 0.7006097855917204
    mean_processing_ms: 0.49436730034204296
  time_since_restore: 363.0589134693146
  time_this_iter_s: 1.4472129344940186
  time_total_s: 363.0589134693146
  timestamp: 1744206586
  timesteps_since_restore: 50850
  timesteps_this_iter: 225
  timesteps_total: 50850
  training_iteration: 226
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    226 |          363.059 |       50850 | 0.485857 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-49-52
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.5677133263816164
  episode_reward_mean: 0.4788494045587795
  episode_reward_min: 0.4276708857927879
  episodes_this_iter: 5
  episodes_total: 1150
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.493
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: 18.149023056030273
        entropy_coeff: 0.0
        kl: 0.020744528621435165
        policy_loss: -0.06792382895946503
        total_loss: -0.06675770878791809
        vf_explained_var: 0.9363466501235962
        vf_loss: 0.0011661237804219127
    load_time_ms: 0.826
    num_steps_sampled: 51750
    num_steps_trained: 51750
    sample_time_ms: 1425.15
    update_time_ms: 3.683
  iterations_since_restore: 230
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.26666666666667
    ram_util_percent: 76.53333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.439261622654035
    mean_inference_ms: 0.6998244323839862
    mean_processing_ms: 0.4938371578197436
  time_since_restore: 369.0872583389282
  time_this_iter_s: 1.5216970443725586
  time_total_s: 369.0872583389282
  timestamp: 1744206592
  timesteps_since_restore: 51750
  timesteps_this_iter: 225
  timesteps_total: 51750
  training_iteration: 230
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    230 |          369.087 |       51750 | 0.478849 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-49-58
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.524900404007924
  episode_reward_mean: 0.4684761519210204
  episode_reward_min: 0.4080210362474672
  episodes_this_iter: 5
  episodes_total: 1170
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 88.582
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: 18.226194381713867
        entropy_coeff: 0.0
        kl: 0.013788153417408466
        policy_loss: -0.06450080871582031
        total_loss: -0.0636853575706482
        vf_explained_var: 0.9531146883964539
        vf_loss: 0.0008154468378052115
    load_time_ms: 0.855
    num_steps_sampled: 52650
    num_steps_trained: 52650
    sample_time_ms: 1425.231
    update_time_ms: 3.893
  iterations_since_restore: 234
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.4
    ram_util_percent: 76.5
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.433732036789254
    mean_inference_ms: 0.6991659578480838
    mean_processing_ms: 0.4933967103575374
  time_since_restore: 375.0806884765625
  time_this_iter_s: 1.4257872104644775
  time_total_s: 375.0806884765625
  timestamp: 1744206598
  timesteps_since_restore: 52650
  timesteps_this_iter: 225
  timesteps_total: 52650
  training_iteration: 234
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    234 |          375.081 |       52650 | 0.468476 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-50-04
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.5206105908741477
  episode_reward_mean: 0.4611876712911891
  episode_reward_min: 0.3729384935392455
  episodes_this_iter: 5
  episodes_total: 1190
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 94.605
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: 18.2432804107666
        entropy_coeff: 0.0
        kl: 0.014574432745575905
        policy_loss: -0.053878653794527054
        total_loss: -0.05300745368003845
        vf_explained_var: 0.9475672841072083
        vf_loss: 0.000871197204105556
    load_time_ms: 0.887
    num_steps_sampled: 53550
    num_steps_trained: 53550
    sample_time_ms: 1390.901
    update_time_ms: 3.85
  iterations_since_restore: 238
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.6
    ram_util_percent: 76.5
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.427980381280358
    mean_inference_ms: 0.6985230649848537
    mean_processing_ms: 0.49299778933007393
  time_since_restore: 381.0171070098877
  time_this_iter_s: 1.42043137550354
  time_total_s: 381.0171070098877
  timestamp: 1744206604
  timesteps_since_restore: 53550
  timesteps_this_iter: 225
  timesteps_total: 53550
  training_iteration: 238
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    238 |          381.017 |       53550 | 0.461188 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-50-10
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.5123436822313749
  episode_reward_mean: 0.457356112678938
  episode_reward_min: 0.3729384935392455
  episodes_this_iter: 5
  episodes_total: 1210
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 93.073
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: 18.238794326782227
        entropy_coeff: 0.0
        kl: 0.015534582547843456
        policy_loss: -0.055031467229127884
        total_loss: -0.054451774805784225
        vf_explained_var: 0.964614987373352
        vf_loss: 0.00057968869805336
    load_time_ms: 0.909
    num_steps_sampled: 54450
    num_steps_trained: 54450
    sample_time_ms: 1379.812
    update_time_ms: 3.615
  iterations_since_restore: 242
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.75
    ram_util_percent: 76.8
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.422138788362895
    mean_inference_ms: 0.6979533023282656
    mean_processing_ms: 0.49261122192217754
  time_since_restore: 386.961966753006
  time_this_iter_s: 1.4271955490112305
  time_total_s: 386.961966753006
  timestamp: 1744206610
  timesteps_since_restore: 54450
  timesteps_this_iter: 225
  timesteps_total: 54450
  training_iteration: 242
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    242 |          386.962 |       54450 | 0.457356 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-50-16
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.5123436822313749
  episode_reward_mean: 0.45355834575810255
  episode_reward_min: 0.3729384935392455
  episodes_this_iter: 5
  episodes_total: 1230
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.905
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: 18.167287826538086
        entropy_coeff: 0.0
        kl: 0.0290067158639431
        policy_loss: -0.08307087421417236
        total_loss: -0.08248212188482285
        vf_explained_var: 0.9659835696220398
        vf_loss: 0.0005887470906600356
    load_time_ms: 0.894
    num_steps_sampled: 55350
    num_steps_trained: 55350
    sample_time_ms: 1384.749
    update_time_ms: 3.576
  iterations_since_restore: 246
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.7
    ram_util_percent: 76.5
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.41600744284523
    mean_inference_ms: 0.6974440537914391
    mean_processing_ms: 0.49219359425246284
  time_since_restore: 392.87706685066223
  time_this_iter_s: 1.4638104438781738
  time_total_s: 392.87706685066223
  timestamp: 1744206616
  timesteps_since_restore: 55350
  timesteps_this_iter: 225
  timesteps_total: 55350
  training_iteration: 246
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    246 |          392.877 |       55350 | 0.453558 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-50-22
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.5062984548853707
  episode_reward_mean: 0.448092065997371
  episode_reward_min: 0.3729384935392455
  episodes_this_iter: 5
  episodes_total: 1250
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 88.846
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: 18.25001335144043
        entropy_coeff: 0.0
        kl: 0.015052849426865578
        policy_loss: -0.062301766127347946
        total_loss: -0.06146872043609619
        vf_explained_var: 0.9467803835868835
        vf_loss: 0.0008330546552315354
    load_time_ms: 0.846
    num_steps_sampled: 56250
    num_steps_trained: 56250
    sample_time_ms: 1386.573
    update_time_ms: 3.571
  iterations_since_restore: 250
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.5
    ram_util_percent: 76.4
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.409456992927767
    mean_inference_ms: 0.6969632730088793
    mean_processing_ms: 0.4917319582146938
  time_since_restore: 398.8243820667267
  time_this_iter_s: 1.421222448348999
  time_total_s: 398.8243820667267
  timestamp: 1744206622
  timesteps_since_restore: 56250
  timesteps_this_iter: 225
  timesteps_total: 56250
  training_iteration: 250
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    250 |          398.824 |       56250 | 0.448092 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-50-28
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.4982219516548444
  episode_reward_mean: 0.44347290584685245
  episode_reward_min: 0.3729384935392455
  episodes_this_iter: 5
  episodes_total: 1270
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.056
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: 18.108854293823242
        entropy_coeff: 0.0
        kl: 0.014870723709464073
        policy_loss: -0.05615496635437012
        total_loss: -0.05538659170269966
        vf_explained_var: 0.9507774114608765
        vf_loss: 0.0007683649891987443
    load_time_ms: 0.849
    num_steps_sampled: 57150
    num_steps_trained: 57150
    sample_time_ms: 1411.894
    update_time_ms: 3.691
  iterations_since_restore: 254
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.65
    ram_util_percent: 76.35
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.402885844096576
    mean_inference_ms: 0.6964878994890341
    mean_processing_ms: 0.49127306090713646
  time_since_restore: 405.05506563186646
  time_this_iter_s: 1.7451751232147217
  time_total_s: 405.05506563186646
  timestamp: 1744206628
  timesteps_since_restore: 57150
  timesteps_this_iter: 225
  timesteps_total: 57150
  training_iteration: 254
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.7/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    254 |          405.055 |       57150 | 0.443473 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-50-34
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.4982219516548444
  episode_reward_mean: 0.4355070807264581
  episode_reward_min: 0.35069827154044353
  episodes_this_iter: 5
  episodes_total: 1290
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.454
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: 18.09690284729004
        entropy_coeff: 0.0
        kl: 0.01946423389017582
        policy_loss: -0.06852773576974869
        total_loss: -0.06800398230552673
        vf_explained_var: 0.9612706303596497
        vf_loss: 0.0005237652803771198
    load_time_ms: 0.845
    num_steps_sampled: 58050
    num_steps_trained: 58050
    sample_time_ms: 1420.057
    update_time_ms: 3.727
  iterations_since_restore: 258
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.05
    ram_util_percent: 76.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.397617567795017
    mean_inference_ms: 0.6961351419547687
    mean_processing_ms: 0.49089317642155167
  time_since_restore: 411.0640125274658
  time_this_iter_s: 1.4906947612762451
  time_total_s: 411.0640125274658
  timestamp: 1744206634
  timesteps_since_restore: 58050
  timesteps_this_iter: 225
  timesteps_total: 58050
  training_iteration: 258
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.7/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    258 |          411.064 |       58050 | 0.435507 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-50-40
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.481834036580152
  episode_reward_mean: 0.42552592274150713
  episode_reward_min: 0.35069827154044353
  episodes_this_iter: 5
  episodes_total: 1310
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.815
    learner:
      default_policy:
        cur_kl_coeff: 1.421085492696024e-15
        cur_lr: 4.999999873689376e-05
        entropy: 18.02729034423828
        entropy_coeff: 0.0
        kl: 0.012602833099663258
        policy_loss: -0.05611192062497139
        total_loss: -0.05528327822685242
        vf_explained_var: 0.9391288757324219
        vf_loss: 0.0008286368101835251
    load_time_ms: 0.861
    num_steps_sampled: 58950
    num_steps_trained: 58950
    sample_time_ms: 1431.426
    update_time_ms: 3.839
  iterations_since_restore: 262
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.6
    ram_util_percent: 76.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.392487514252455
    mean_inference_ms: 0.6958101722562146
    mean_processing_ms: 0.49064219440158735
  time_since_restore: 416.9972333908081
  time_this_iter_s: 1.4375500679016113
  time_total_s: 416.9972333908081
  timestamp: 1744206640
  timesteps_since_restore: 58950
  timesteps_this_iter: 225
  timesteps_total: 58950
  training_iteration: 262
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.7/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    262 |          416.997 |       58950 | 0.425526 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-50-46
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.46574817047577566
  episode_reward_mean: 0.4113342314421697
  episode_reward_min: 0.3488587584233955
  episodes_this_iter: 5
  episodes_total: 1330
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 88.792
    learner:
      default_policy:
        cur_kl_coeff: 1.421085492696024e-15
        cur_lr: 4.999999873689376e-05
        entropy: 18.262271881103516
        entropy_coeff: 0.0
        kl: 0.016198184341192245
        policy_loss: -0.06870806217193604
        total_loss: -0.06821130216121674
        vf_explained_var: 0.9594478607177734
        vf_loss: 0.0004967466229572892
    load_time_ms: 0.909
    num_steps_sampled: 59850
    num_steps_trained: 59850
    sample_time_ms: 1393.912
    update_time_ms: 3.737
  iterations_since_restore: 266
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.45
    ram_util_percent: 76.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.387757389370938
    mean_inference_ms: 0.6955121854710805
    mean_processing_ms: 0.49042712082489304
  time_since_restore: 423.0260179042816
  time_this_iter_s: 1.4688444137573242
  time_total_s: 423.0260179042816
  timestamp: 1744206646
  timesteps_since_restore: 59850
  timesteps_this_iter: 225
  timesteps_total: 59850
  training_iteration: 266
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.7/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    266 |          423.026 |       59850 | 0.411334 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-50-52
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.46574817047577566
  episode_reward_mean: 0.399677465737317
  episode_reward_min: 0.3271523805569977
  episodes_this_iter: 5
  episodes_total: 1350
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.013
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 18.519636154174805
        entropy_coeff: 0.0
        kl: 0.01724332943558693
        policy_loss: -0.06686937808990479
        total_loss: -0.06649846583604813
        vf_explained_var: 0.9694463610649109
        vf_loss: 0.0003709060256369412
    load_time_ms: 0.919
    num_steps_sampled: 60750
    num_steps_trained: 60750
    sample_time_ms: 1406.178
    update_time_ms: 3.783
  iterations_since_restore: 270
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.766666666666666
    ram_util_percent: 76.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.383403998938357
    mean_inference_ms: 0.695223660577298
    mean_processing_ms: 0.49017019543350654
  time_since_restore: 429.12276792526245
  time_this_iter_s: 1.5596563816070557
  time_total_s: 429.12276792526245
  timestamp: 1744206652
  timesteps_since_restore: 60750
  timesteps_this_iter: 225
  timesteps_total: 60750
  training_iteration: 270
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.7/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    270 |          429.123 |       60750 | 0.399677 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-50-59
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.45230517550792504
  episode_reward_mean: 0.38868523269325306
  episode_reward_min: 0.3271523805569977
  episodes_this_iter: 5
  episodes_total: 1370
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.226
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 18.551387786865234
        entropy_coeff: 0.0
        kl: 0.02302015945315361
        policy_loss: -0.07513553649187088
        total_loss: -0.07457838952541351
        vf_explained_var: 0.9536724090576172
        vf_loss: 0.0005571306683123112
    load_time_ms: 0.89
    num_steps_sampled: 61650
    num_steps_trained: 61650
    sample_time_ms: 1446.145
    update_time_ms: 3.576
  iterations_since_restore: 274
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.35
    ram_util_percent: 76.0
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.380302470705476
    mean_inference_ms: 0.6950324961938966
    mean_processing_ms: 0.489968813191932
  time_since_restore: 435.5249435901642
  time_this_iter_s: 1.6021718978881836
  time_total_s: 435.5249435901642
  timestamp: 1744206659
  timesteps_since_restore: 61650
  timesteps_this_iter: 225
  timesteps_total: 61650
  training_iteration: 274
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.7/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    274 |          435.525 |       61650 | 0.388685 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-51-05
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.45230517550792504
  episode_reward_mean: 0.38024091128790954
  episode_reward_min: 0.3210548079896955
  episodes_this_iter: 5
  episodes_total: 1390
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 87.026
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 18.546939849853516
        entropy_coeff: 0.0
        kl: 0.022286972030997276
        policy_loss: -0.07030458003282547
        total_loss: -0.06961653381586075
        vf_explained_var: 0.9375327825546265
        vf_loss: 0.0006880409200675786
    load_time_ms: 0.882
    num_steps_sampled: 62550
    num_steps_trained: 62550
    sample_time_ms: 1484.704
    update_time_ms: 3.421
  iterations_since_restore: 278
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.266666666666666
    ram_util_percent: 76.0
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.377249300090675
    mean_inference_ms: 0.6948713588403298
    mean_processing_ms: 0.4898438437828009
  time_since_restore: 441.8044099807739
  time_this_iter_s: 1.6174280643463135
  time_total_s: 441.8044099807739
  timestamp: 1744206665
  timesteps_since_restore: 62550
  timesteps_this_iter: 225
  timesteps_total: 62550
  training_iteration: 278
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.7/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    278 |          441.804 |       62550 | 0.380241 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-51-11
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.41078407050338733
  episode_reward_mean: 0.3706076676744129
  episode_reward_min: 0.31892800245188874
  episodes_this_iter: 5
  episodes_total: 1410
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 87.483
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 18.514862060546875
        entropy_coeff: 0.0
        kl: 0.01936112344264984
        policy_loss: -0.0674528032541275
        total_loss: -0.06703834235668182
        vf_explained_var: 0.9605579376220703
        vf_loss: 0.000414454989368096
    load_time_ms: 0.96
    num_steps_sampled: 63450
    num_steps_trained: 63450
    sample_time_ms: 1465.967
    update_time_ms: 3.606
  iterations_since_restore: 282
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.633333333333336
    ram_util_percent: 76.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.375129592685954
    mean_inference_ms: 0.6947712852533264
    mean_processing_ms: 0.4897536437888985
  time_since_restore: 447.93098497390747
  time_this_iter_s: 1.4858489036560059
  time_total_s: 447.93098497390747
  timestamp: 1744206671
  timesteps_since_restore: 63450
  timesteps_this_iter: 225
  timesteps_total: 63450
  training_iteration: 282
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.7/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    282 |          447.931 |       63450 | 0.370608 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-51-18
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.41078407050338733
  episode_reward_mean: 0.36762003564083495
  episode_reward_min: 0.31892800245188874
  episodes_this_iter: 5
  episodes_total: 1430
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.531
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 18.26169776916504
        entropy_coeff: 0.0
        kl: 0.01662309281527996
        policy_loss: -0.07107478380203247
        total_loss: -0.07061167806386948
        vf_explained_var: 0.9570480585098267
        vf_loss: 0.00046310649486258626
    load_time_ms: 1.013
    num_steps_sampled: 64350
    num_steps_trained: 64350
    sample_time_ms: 1457.331
    update_time_ms: 3.669
  iterations_since_restore: 286
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.933333333333334
    ram_util_percent: 76.33333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.373133491001998
    mean_inference_ms: 0.6947192882842498
    mean_processing_ms: 0.4897173391717778
  time_since_restore: 454.22888946533203
  time_this_iter_s: 1.8352859020233154
  time_total_s: 454.22888946533203
  timestamp: 1744206678
  timesteps_since_restore: 64350
  timesteps_this_iter: 225
  timesteps_total: 64350
  training_iteration: 286
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.7/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    286 |          454.229 |       64350 |  0.36762 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-51-24
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.41078407050338733
  episode_reward_mean: 0.3627757774242012
  episode_reward_min: 0.31892800245188874
  episodes_this_iter: 5
  episodes_total: 1450
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.592
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 18.235950469970703
        entropy_coeff: 0.0
        kl: 0.02267959527671337
        policy_loss: -0.06701964884996414
        total_loss: -0.06644149124622345
        vf_explained_var: 0.945600688457489
        vf_loss: 0.0005781656946055591
    load_time_ms: 0.981
    num_steps_sampled: 65250
    num_steps_trained: 65250
    sample_time_ms: 1446.982
    update_time_ms: 3.702
  iterations_since_restore: 290
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.950000000000003
    ram_util_percent: 76.4
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.3720512253134505
    mean_inference_ms: 0.6948157416232654
    mean_processing_ms: 0.48984492394079565
  time_since_restore: 460.3899350166321
  time_this_iter_s: 1.5724611282348633
  time_total_s: 460.3899350166321
  timestamp: 1744206684
  timesteps_since_restore: 65250
  timesteps_this_iter: 225
  timesteps_total: 65250
  training_iteration: 290
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.7/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    290 |           460.39 |       65250 | 0.362776 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-51-30
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.41078407050338733
  episode_reward_mean: 0.3562880988311226
  episode_reward_min: 0.29411605498807203
  episodes_this_iter: 5
  episodes_total: 1470
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.306
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 18.45365333557129
        entropy_coeff: 0.0
        kl: 0.02080090343952179
        policy_loss: -0.07167626172304153
        total_loss: -0.07137961685657501
        vf_explained_var: 0.9689224362373352
        vf_loss: 0.00029665144393220544
    load_time_ms: 0.937
    num_steps_sampled: 66150
    num_steps_trained: 66150
    sample_time_ms: 1455.951
    update_time_ms: 3.683
  iterations_since_restore: 294
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.1
    ram_util_percent: 76.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.370322374689124
    mean_inference_ms: 0.6948782145914578
    mean_processing_ms: 0.48991612646065136
  time_since_restore: 466.4257118701935
  time_this_iter_s: 1.4910104274749756
  time_total_s: 466.4257118701935
  timestamp: 1744206690
  timesteps_since_restore: 66150
  timesteps_this_iter: 225
  timesteps_total: 66150
  training_iteration: 294
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.7/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    294 |          466.426 |       66150 | 0.356288 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-51-36
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.41078407050338733
  episode_reward_mean: 0.3522558517741945
  episode_reward_min: 0.29411605498807203
  episodes_this_iter: 5
  episodes_total: 1485
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.883
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 18.506114959716797
        entropy_coeff: 0.0
        kl: 0.01736919954419136
        policy_loss: -0.0632966086268425
        total_loss: -0.06295006722211838
        vf_explained_var: 0.9662773013114929
        vf_loss: 0.00034653968759812415
    load_time_ms: 0.953
    num_steps_sampled: 66825
    num_steps_trained: 66825
    sample_time_ms: 1530.804
    update_time_ms: 3.596
  iterations_since_restore: 297
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.733333333333334
    ram_util_percent: 76.4
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.3699475062512825
    mean_inference_ms: 0.6950879611058934
    mean_processing_ms: 0.49000791519514364
  time_since_restore: 472.0747814178467
  time_this_iter_s: 1.925839900970459
  time_total_s: 472.0747814178467
  timestamp: 1744206696
  timesteps_since_restore: 66825
  timesteps_this_iter: 225
  timesteps_total: 66825
  training_iteration: 297
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.7/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    297 |          472.075 |       66825 | 0.352256 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-51-41
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.39777355226799505
  episode_reward_mean: 0.3501669877916304
  episode_reward_min: 0.29411605498807203
  episodes_this_iter: 5
  episodes_total: 1500
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 97.114
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 17.99640464782715
        entropy_coeff: 0.0
        kl: 0.020075853914022446
        policy_loss: -0.0672023594379425
        total_loss: -0.06657235324382782
        vf_explained_var: 0.9354745745658875
        vf_loss: 0.0006300071836449206
    load_time_ms: 1.079
    num_steps_sampled: 67500
    num_steps_trained: 67500
    sample_time_ms: 1652.233
    update_time_ms: 3.881
  iterations_since_restore: 300
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.099999999999998
    ram_util_percent: 76.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.371499762633212
    mean_inference_ms: 0.6956607000079906
    mean_processing_ms: 0.4903043731183592
  time_since_restore: 477.9679582118988
  time_this_iter_s: 1.769881248474121
  time_total_s: 477.9679582118988
  timestamp: 1744206701
  timesteps_since_restore: 67500
  timesteps_this_iter: 225
  timesteps_total: 67500
  training_iteration: 300
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.7/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    300 |          477.968 |       67500 | 0.350167 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-51-48
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.3839057680313693
  episode_reward_mean: 0.3458269909677928
  episode_reward_min: 0.29411605498807203
  episodes_this_iter: 5
  episodes_total: 1515
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 102.76
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 17.931528091430664
        entropy_coeff: 0.0
        kl: 0.019282609224319458
        policy_loss: -0.06740085780620575
        total_loss: -0.06692599505186081
        vf_explained_var: 0.9479871988296509
        vf_loss: 0.0004748661885969341
    load_time_ms: 1.253
    num_steps_sampled: 68175
    num_steps_trained: 68175
    sample_time_ms: 1789.176
    update_time_ms: 4.303
  iterations_since_restore: 303
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.25
    ram_util_percent: 76.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.375330122159494
    mean_inference_ms: 0.6966250368797191
    mean_processing_ms: 0.4908453138188684
  time_since_restore: 483.9453353881836
  time_this_iter_s: 1.8694806098937988
  time_total_s: 483.9453353881836
  timestamp: 1744206708
  timesteps_since_restore: 68175
  timesteps_this_iter: 225
  timesteps_total: 68175
  training_iteration: 303
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.7/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    303 |          483.945 |       68175 | 0.345827 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-51-53
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.3839057680313693
  episode_reward_mean: 0.34183011377906797
  episode_reward_min: 0.29411605498807203
  episodes_this_iter: 5
  episodes_total: 1530
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 112.291
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 17.948598861694336
        entropy_coeff: 0.0
        kl: 0.020848780870437622
        policy_loss: -0.07799948751926422
        total_loss: -0.0776224285364151
        vf_explained_var: 0.9582727551460266
        vf_loss: 0.00037705013528466225
    load_time_ms: 1.387
    num_steps_sampled: 68850
    num_steps_trained: 68850
    sample_time_ms: 1848.392
    update_time_ms: 4.585
  iterations_since_restore: 306
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.86666666666667
    ram_util_percent: 77.93333333333332
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.380815936104533
    mean_inference_ms: 0.6978379844813
    mean_processing_ms: 0.49166320289508136
  time_since_restore: 489.8521797657013
  time_this_iter_s: 2.135390043258667
  time_total_s: 489.8521797657013
  timestamp: 1744206713
  timesteps_since_restore: 68850
  timesteps_this_iter: 225
  timesteps_total: 68850
  training_iteration: 306
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    306 |          489.852 |       68850 |  0.34183 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-52-00
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.3830173889041736
  episode_reward_mean: 0.33799946140576986
  episode_reward_min: 0.2904985083999294
  episodes_this_iter: 5
  episodes_total: 1545
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 109.563
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 17.658145904541016
        entropy_coeff: 0.0
        kl: 0.017096275463700294
        policy_loss: -0.07104616612195969
        total_loss: -0.07069715112447739
        vf_explained_var: 0.9606781005859375
        vf_loss: 0.000349021254805848
    load_time_ms: 1.271
    num_steps_sampled: 69525
    num_steps_trained: 69525
    sample_time_ms: 1855.324
    update_time_ms: 4.676
  iterations_since_restore: 309
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.7
    ram_util_percent: 77.6
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.389063969039999
    mean_inference_ms: 0.6994241097783683
    mean_processing_ms: 0.4926696489631226
  time_since_restore: 495.9431836605072
  time_this_iter_s: 1.8715455532073975
  time_total_s: 495.9431836605072
  timestamp: 1744206720
  timesteps_since_restore: 69525
  timesteps_this_iter: 225
  timesteps_total: 69525
  training_iteration: 309
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    309 |          495.943 |       69525 | 0.337999 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-52-05
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.38049834115293163
  episode_reward_mean: 0.33468570367378736
  episode_reward_min: 0.2904985083999294
  episodes_this_iter: 5
  episodes_total: 1560
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 105.301
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 17.659053802490234
        entropy_coeff: 0.0
        kl: 0.017448700964450836
        policy_loss: -0.07660117000341415
        total_loss: -0.07634573429822922
        vf_explained_var: 0.9708811640739441
        vf_loss: 0.00025544301024638116
    load_time_ms: 1.199
    num_steps_sampled: 70200
    num_steps_trained: 70200
    sample_time_ms: 1807.538
    update_time_ms: 4.213
  iterations_since_restore: 312
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.05
    ram_util_percent: 77.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.398691229493936
    mean_inference_ms: 0.7012230286506131
    mean_processing_ms: 0.4938296463274132
  time_since_restore: 501.29520869255066
  time_this_iter_s: 1.6838366985321045
  time_total_s: 501.29520869255066
  timestamp: 1744206725
  timesteps_since_restore: 70200
  timesteps_this_iter: 225
  timesteps_total: 70200
  training_iteration: 312
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    312 |          501.295 |       70200 | 0.334686 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-52-11
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.37654635031514205
  episode_reward_mean: 0.33025206991069017
  episode_reward_min: 0.27538002911643206
  episodes_this_iter: 5
  episodes_total: 1575
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 97.601
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 17.628475189208984
        entropy_coeff: 0.0
        kl: 0.01759127713739872
        policy_loss: -0.07091300934553146
        total_loss: -0.07055948674678802
        vf_explained_var: 0.9592055082321167
        vf_loss: 0.0003535256255418062
    load_time_ms: 0.913
    num_steps_sampled: 70875
    num_steps_trained: 70875
    sample_time_ms: 1826.898
    update_time_ms: 4.037
  iterations_since_restore: 315
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.933333333333334
    ram_util_percent: 77.53333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.4094501161954565
    mean_inference_ms: 0.7031583237828548
    mean_processing_ms: 0.4951947979541486
  time_since_restore: 507.0459175109863
  time_this_iter_s: 1.9876809120178223
  time_total_s: 507.0459175109863
  timestamp: 1744206731
  timesteps_since_restore: 70875
  timesteps_this_iter: 225
  timesteps_total: 70875
  training_iteration: 315
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    315 |          507.046 |       70875 | 0.330252 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-52-16
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.37654635031514205
  episode_reward_mean: 0.3281937191744697
  episode_reward_min: 0.27538002911643206
  episodes_this_iter: 5
  episodes_total: 1590
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 96.297
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 17.386653900146484
        entropy_coeff: 0.0
        kl: 0.020834922790527344
        policy_loss: -0.06789585202932358
        total_loss: -0.06732034683227539
        vf_explained_var: 0.9336512684822083
        vf_loss: 0.0005755041493102908
    load_time_ms: 0.867
    num_steps_sampled: 71550
    num_steps_trained: 71550
    sample_time_ms: 1765.298
    update_time_ms: 3.832
  iterations_since_restore: 318
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.55
    ram_util_percent: 77.5
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.420482144891435
    mean_inference_ms: 0.7051035238988212
    mean_processing_ms: 0.496647412370224
  time_since_restore: 512.7696821689606
  time_this_iter_s: 1.866762399673462
  time_total_s: 512.7696821689606
  timestamp: 1744206736
  timesteps_since_restore: 71550
  timesteps_this_iter: 225
  timesteps_total: 71550
  training_iteration: 318
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    318 |           512.77 |       71550 | 0.328194 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-52-22
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.36058105504328775
  episode_reward_mean: 0.3241083998128764
  episode_reward_min: 0.27538002911643206
  episodes_this_iter: 5
  episodes_total: 1605
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 98.111
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 17.503055572509766
        entropy_coeff: 0.0
        kl: 0.02221592888236046
        policy_loss: -0.06999921053647995
        total_loss: -0.06970055401325226
        vf_explained_var: 0.9653279185295105
        vf_loss: 0.00029865276883356273
    load_time_ms: 0.881
    num_steps_sampled: 72225
    num_steps_trained: 72225
    sample_time_ms: 1800.778
    update_time_ms: 3.737
  iterations_since_restore: 321
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.400000000000002
    ram_util_percent: 77.43333333333334
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.43132155133867
    mean_inference_ms: 0.7069487709695673
    mean_processing_ms: 0.49803881106142567
  time_since_restore: 518.6823890209198
  time_this_iter_s: 1.8744573593139648
  time_total_s: 518.6823890209198
  timestamp: 1744206742
  timesteps_since_restore: 72225
  timesteps_this_iter: 225
  timesteps_total: 72225
  training_iteration: 321
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    321 |          518.682 |       72225 | 0.324108 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-52-29
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.36058105504328775
  episode_reward_mean: 0.32205872477887854
  episode_reward_min: 0.27538002911643206
  episodes_this_iter: 5
  episodes_total: 1620
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 107.58
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 17.402334213256836
        entropy_coeff: 0.0
        kl: 0.022230643779039383
        policy_loss: -0.05869102478027344
        total_loss: -0.058316610753536224
        vf_explained_var: 0.9551520347595215
        vf_loss: 0.0003744108253158629
    load_time_ms: 1.014
    num_steps_sampled: 72900
    num_steps_trained: 72900
    sample_time_ms: 1926.173
    update_time_ms: 4.055
  iterations_since_restore: 324
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.366666666666664
    ram_util_percent: 77.83333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.442944473894199
    mean_inference_ms: 0.7088439297544036
    mean_processing_ms: 0.49961341698049394
  time_since_restore: 525.4848802089691
  time_this_iter_s: 2.135674238204956
  time_total_s: 525.4848802089691
  timestamp: 1744206749
  timesteps_since_restore: 72900
  timesteps_this_iter: 225
  timesteps_total: 72900
  training_iteration: 324
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    324 |          525.485 |       72900 | 0.322059 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-52-36
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.3547896492087277
  episode_reward_mean: 0.31878342387832803
  episode_reward_min: 0.27538002911643206
  episodes_this_iter: 5
  episodes_total: 1635
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 114.891
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 17.43675994873047
        entropy_coeff: 0.0
        kl: 0.030100181698799133
        policy_loss: -0.0719165951013565
        total_loss: -0.07160154730081558
        vf_explained_var: 0.9573296308517456
        vf_loss: 0.00031503947684541345
    load_time_ms: 1.075
    num_steps_sampled: 73575
    num_steps_trained: 73575
    sample_time_ms: 2003.884
    update_time_ms: 4.046
  iterations_since_restore: 327
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.866666666666664
    ram_util_percent: 78.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.455314711163437
    mean_inference_ms: 0.7108790610164302
    mean_processing_ms: 0.5012459867198512
  time_since_restore: 532.1820695400238
  time_this_iter_s: 2.246504068374634
  time_total_s: 532.1820695400238
  timestamp: 1744206756
  timesteps_since_restore: 73575
  timesteps_this_iter: 225
  timesteps_total: 73575
  training_iteration: 327
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    327 |          532.182 |       73575 | 0.318783 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-52-42
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.3547896492087277
  episode_reward_mean: 0.3182690903230628
  episode_reward_min: 0.27538002911643206
  episodes_this_iter: 5
  episodes_total: 1650
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 113.793
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 17.677114486694336
        entropy_coeff: 0.0
        kl: 0.011784850619733334
        policy_loss: -0.04384047910571098
        total_loss: -0.043387580662965775
        vf_explained_var: 0.9463205337524414
        vf_loss: 0.0004529152938630432
    load_time_ms: 1.09
    num_steps_sampled: 74250
    num_steps_trained: 74250
    sample_time_ms: 2039.614
    update_time_ms: 4.295
  iterations_since_restore: 330
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.45
    ram_util_percent: 78.4
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.468239508092475
    mean_inference_ms: 0.7130262937129109
    mean_processing_ms: 0.5029903564439295
  time_since_restore: 538.437760591507
  time_this_iter_s: 1.7476463317871094
  time_total_s: 538.437760591507
  timestamp: 1744206762
  timesteps_since_restore: 74250
  timesteps_this_iter: 225
  timesteps_total: 74250
  training_iteration: 330
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    330 |          538.438 |       74250 | 0.318269 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-52-48
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.3547896492087277
  episode_reward_mean: 0.31448510021557174
  episode_reward_min: 0.24924667164592726
  episodes_this_iter: 5
  episodes_total: 1665
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 106.799
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 17.742788314819336
        entropy_coeff: 0.0
        kl: 0.017906202003359795
        policy_loss: -0.06290043145418167
        total_loss: -0.062685027718544
        vf_explained_var: 0.9714318513870239
        vf_loss: 0.00021540329908020794
    load_time_ms: 1.086
    num_steps_sampled: 74925
    num_steps_trained: 74925
    sample_time_ms: 1999.458
    update_time_ms: 3.925
  iterations_since_restore: 333
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 37.26666666666667
    ram_util_percent: 78.83333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.481845091685119
    mean_inference_ms: 0.7152962281161576
    mean_processing_ms: 0.5047811642207257
  time_since_restore: 544.5010495185852
  time_this_iter_s: 2.1653530597686768
  time_total_s: 544.5010495185852
  timestamp: 1744206768
  timesteps_since_restore: 74925
  timesteps_this_iter: 225
  timesteps_total: 74925
  training_iteration: 333
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.2/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    333 |          544.501 |       74925 | 0.314485 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-52-55
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.3547896492087277
  episode_reward_mean: 0.3124353495792076
  episode_reward_min: 0.24924667164592726
  episodes_this_iter: 5
  episodes_total: 1680
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 101.287
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 17.470836639404297
        entropy_coeff: 0.0
        kl: 0.016370262950658798
        policy_loss: -0.05788453668355942
        total_loss: -0.05767037346959114
        vf_explained_var: 0.973244845867157
        vf_loss: 0.00021416817617136985
    load_time_ms: 1.03
    num_steps_sampled: 75600
    num_steps_trained: 75600
    sample_time_ms: 1971.393
    update_time_ms: 3.833
  iterations_since_restore: 336
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 37.43333333333333
    ram_util_percent: 77.86666666666666
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.496105378124015
    mean_inference_ms: 0.7177386353628907
    mean_processing_ms: 0.506523666496648
  time_since_restore: 550.7482919692993
  time_this_iter_s: 2.1475319862365723
  time_total_s: 550.7482919692993
  timestamp: 1744206775
  timesteps_since_restore: 75600
  timesteps_this_iter: 225
  timesteps_total: 75600
  training_iteration: 336
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    336 |          550.748 |       75600 | 0.312435 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-53-00
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.34095974174845517
  episode_reward_mean: 0.3085171796533471
  episode_reward_min: 0.24924667164592726
  episodes_this_iter: 5
  episodes_total: 1695
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 97.466
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 17.479259490966797
        entropy_coeff: 0.0
        kl: 0.022274989634752274
        policy_loss: -0.06086445599794388
        total_loss: -0.06058827042579651
        vf_explained_var: 0.9633970260620117
        vf_loss: 0.0002761780342552811
    load_time_ms: 1.084
    num_steps_sampled: 76275
    num_steps_trained: 76275
    sample_time_ms: 1844.533
    update_time_ms: 3.658
  iterations_since_restore: 339
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.0
    ram_util_percent: 77.7
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.509690086793093
    mean_inference_ms: 0.7200792203357474
    mean_processing_ms: 0.5082003883644135
  time_since_restore: 556.1914963722229
  time_this_iter_s: 2.2128047943115234
  time_total_s: 556.1914963722229
  timestamp: 1744206780
  timesteps_since_restore: 76275
  timesteps_this_iter: 225
  timesteps_total: 76275
  training_iteration: 339
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    339 |          556.191 |       76275 | 0.308517 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-53-06
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.34091487679148136
  episode_reward_mean: 0.3049539431408819
  episode_reward_min: 0.24435971176953256
  episodes_this_iter: 5
  episodes_total: 1710
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 98.836
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 17.15506362915039
        entropy_coeff: 0.0
        kl: 0.018313830718398094
        policy_loss: -0.0612279549241066
        total_loss: -0.06092366576194763
        vf_explained_var: 0.9554335474967957
        vf_loss: 0.000304289220366627
    load_time_ms: 1.122
    num_steps_sampled: 76950
    num_steps_trained: 76950
    sample_time_ms: 1823.548
    update_time_ms: 3.799
  iterations_since_restore: 342
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.05
    ram_util_percent: 77.5
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.522671571498786
    mean_inference_ms: 0.7223947807254857
    mean_processing_ms: 0.5097163488438562
  time_since_restore: 561.6426737308502
  time_this_iter_s: 1.8318312168121338
  time_total_s: 561.6426737308502
  timestamp: 1744206786
  timesteps_since_restore: 76950
  timesteps_this_iter: 225
  timesteps_total: 76950
  training_iteration: 342
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    342 |          561.643 |       76950 | 0.304954 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-53-11
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.34091487679148136
  episode_reward_mean: 0.30112651101307314
  episode_reward_min: 0.24435971176953256
  episodes_this_iter: 5
  episodes_total: 1725
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 95.267
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 16.999923706054688
        entropy_coeff: 0.0
        kl: 0.03228437155485153
        policy_loss: -0.07852286845445633
        total_loss: -0.07819022238254547
        vf_explained_var: 0.9487749934196472
        vf_loss: 0.00033265125239267945
    load_time_ms: 1.082
    num_steps_sampled: 77625
    num_steps_trained: 77625
    sample_time_ms: 1706.019
    update_time_ms: 4.062
  iterations_since_restore: 345
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.200000000000003
    ram_util_percent: 77.4
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.533224007801305
    mean_inference_ms: 0.7243301200622156
    mean_processing_ms: 0.5108698280262954
  time_since_restore: 566.6986191272736
  time_this_iter_s: 1.6515593528747559
  time_total_s: 566.6986191272736
  timestamp: 1744206791
  timesteps_since_restore: 77625
  timesteps_this_iter: 225
  timesteps_total: 77625
  training_iteration: 345
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    345 |          566.699 |       77625 | 0.301127 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-53-16
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.34086728721579707
  episode_reward_mean: 0.2960952314571567
  episode_reward_min: 0.24435971176953256
  episodes_this_iter: 5
  episodes_total: 1740
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 97.696
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 16.82472801208496
        entropy_coeff: 0.0
        kl: 0.018979955464601517
        policy_loss: -0.06378324329853058
        total_loss: -0.06356051564216614
        vf_explained_var: 0.9675434231758118
        vf_loss: 0.00022271827037911862
    load_time_ms: 1.113
    num_steps_sampled: 78300
    num_steps_trained: 78300
    sample_time_ms: 1715.836
    update_time_ms: 4.086
  iterations_since_restore: 348
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.45
    ram_util_percent: 77.69999999999999
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.54128767133303
    mean_inference_ms: 0.7258397541302094
    mean_processing_ms: 0.511761278188477
  time_since_restore: 572.2005898952484
  time_this_iter_s: 2.2319834232330322
  time_total_s: 572.2005898952484
  timestamp: 1744206796
  timesteps_since_restore: 78300
  timesteps_this_iter: 225
  timesteps_total: 78300
  training_iteration: 348
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    348 |          572.201 |       78300 | 0.296095 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-53-22
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.3277414181077528
  episode_reward_mean: 0.29130036348998223
  episode_reward_min: 0.2434550264367796
  episodes_this_iter: 5
  episodes_total: 1755
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 97.502
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 16.79788589477539
        entropy_coeff: 0.0
        kl: 0.014439982362091541
        policy_loss: -0.06275980919599533
        total_loss: -0.062457311898469925
        vf_explained_var: 0.9525629281997681
        vf_loss: 0.0003024890902452171
    load_time_ms: 1.147
    num_steps_sampled: 78975
    num_steps_trained: 78975
    sample_time_ms: 1715.012
    update_time_ms: 4.348
  iterations_since_restore: 351
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.45
    ram_util_percent: 77.7
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.548889381761094
    mean_inference_ms: 0.7272255079494394
    mean_processing_ms: 0.5126027623971541
  time_since_restore: 578.0252637863159
  time_this_iter_s: 1.6611318588256836
  time_total_s: 578.0252637863159
  timestamp: 1744206802
  timesteps_since_restore: 78975
  timesteps_this_iter: 225
  timesteps_total: 78975
  training_iteration: 351
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    351 |          578.025 |       78975 |   0.2913 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-53-27
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.3277414181077528
  episode_reward_mean: 0.2874349176983849
  episode_reward_min: 0.2434550264367796
  episodes_this_iter: 5
  episodes_total: 1770
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 95.247
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 16.81252670288086
        entropy_coeff: 0.0
        kl: 0.020540310069918633
        policy_loss: -0.06358795613050461
        total_loss: -0.06322412937879562
        vf_explained_var: 0.9450531005859375
        vf_loss: 0.00036382509279064834
    load_time_ms: 1.133
    num_steps_sampled: 79650
    num_steps_trained: 79650
    sample_time_ms: 1699.971
    update_time_ms: 4.064
  iterations_since_restore: 354
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.1
    ram_util_percent: 77.6
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.555302423425339
    mean_inference_ms: 0.7283958064466658
    mean_processing_ms: 0.5133519350867585
  time_since_restore: 583.0858907699585
  time_this_iter_s: 1.5450489521026611
  time_total_s: 583.0858907699585
  timestamp: 1744206807
  timesteps_since_restore: 79650
  timesteps_this_iter: 225
  timesteps_total: 79650
  training_iteration: 354
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    354 |          583.086 |       79650 | 0.287435 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-53-32
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.3277414181077528
  episode_reward_mean: 0.28445183981678346
  episode_reward_min: 0.2434550264367796
  episodes_this_iter: 5
  episodes_total: 1785
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 97.452
    learner:
      default_policy:
        cur_kl_coeff: 1.0658141459917976e-15
        cur_lr: 4.999999873689376e-05
        entropy: 16.57916831970215
        entropy_coeff: 0.0
        kl: 0.01889481022953987
        policy_loss: -0.0627439096570015
        total_loss: -0.06255225837230682
        vf_explained_var: 0.970586895942688
        vf_loss: 0.00019165247795172036
    load_time_ms: 1.004
    num_steps_sampled: 80325
    num_steps_trained: 80325
    sample_time_ms: 1709.05
    update_time_ms: 4.159
  iterations_since_restore: 357
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.75
    ram_util_percent: 77.6
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.559821138216227
    mean_inference_ms: 0.7292423513028858
    mean_processing_ms: 0.5139090156587762
  time_since_restore: 588.121297121048
  time_this_iter_s: 1.650036096572876
  time_total_s: 588.121297121048
  timestamp: 1744206812
  timesteps_since_restore: 80325
  timesteps_this_iter: 225
  timesteps_total: 80325
  training_iteration: 357
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    357 |          588.121 |       80325 | 0.284452 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-53-37
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.3207450819495074
  episode_reward_mean: 0.2816117463927618
  episode_reward_min: 0.2434550264367796
  episodes_this_iter: 5
  episodes_total: 1800
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.726
    learner:
      default_policy:
        cur_kl_coeff: 1.0658141459917976e-15
        cur_lr: 4.999999873689376e-05
        entropy: 16.947290420532227
        entropy_coeff: 0.0
        kl: 0.016345854848623276
        policy_loss: -0.06041613966226578
        total_loss: -0.06017483025789261
        vf_explained_var: 0.9631460905075073
        vf_loss: 0.00024130412202794105
    load_time_ms: 0.927
    num_steps_sampled: 81000
    num_steps_trained: 81000
    sample_time_ms: 1598.211
    update_time_ms: 3.941
  iterations_since_restore: 360
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.7
    ram_util_percent: 77.73333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.563625293947224
    mean_inference_ms: 0.7299638349630725
    mean_processing_ms: 0.5143893787547787
  time_since_restore: 593.3274128437042
  time_this_iter_s: 1.8557329177856445
  time_total_s: 593.3274128437042
  timestamp: 1744206817
  timesteps_since_restore: 81000
  timesteps_this_iter: 225
  timesteps_total: 81000
  training_iteration: 360
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    360 |          593.327 |       81000 | 0.281612 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-53-43
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.3207450819495074
  episode_reward_mean: 0.280446902166609
  episode_reward_min: 0.2434550264367796
  episodes_this_iter: 5
  episodes_total: 1815
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.817
    learner:
      default_policy:
        cur_kl_coeff: 1.0658141459917976e-15
        cur_lr: 4.999999873689376e-05
        entropy: 16.6968936920166
        entropy_coeff: 0.0
        kl: 0.025686586275696754
        policy_loss: -0.07065054029226303
        total_loss: -0.07043738663196564
        vf_explained_var: 0.966515839099884
        vf_loss: 0.00021315764752216637
    load_time_ms: 0.943
    num_steps_sampled: 81675
    num_steps_trained: 81675
    sample_time_ms: 1623.46
    update_time_ms: 3.945
  iterations_since_restore: 363
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.566666666666663
    ram_util_percent: 77.6
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.567300263056674
    mean_inference_ms: 0.7306372439282336
    mean_processing_ms: 0.5148976212859173
  time_since_restore: 598.7787535190582
  time_this_iter_s: 1.8626103401184082
  time_total_s: 598.7787535190582
  timestamp: 1744206823
  timesteps_since_restore: 81675
  timesteps_this_iter: 225
  timesteps_total: 81675
  training_iteration: 363
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    363 |          598.779 |       81675 | 0.280447 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-53-48
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.3207450819495074
  episode_reward_mean: 0.27814350407154864
  episode_reward_min: 0.24304303596038088
  episodes_this_iter: 5
  episodes_total: 1830
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 95.807
    learner:
      default_policy:
        cur_kl_coeff: 1.0658141459917976e-15
        cur_lr: 4.999999873689376e-05
        entropy: 16.567806243896484
        entropy_coeff: 0.0
        kl: 0.03621508926153183
        policy_loss: -0.08402731269598007
        total_loss: -0.08381067216396332
        vf_explained_var: 0.9639771580696106
        vf_loss: 0.00021664102678187191
    load_time_ms: 1.011
    num_steps_sampled: 82350
    num_steps_trained: 82350
    sample_time_ms: 1625.956
    update_time_ms: 4.089
  iterations_since_restore: 366
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.03333333333333
    ram_util_percent: 77.6
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.571034100136049
    mean_inference_ms: 0.7312997238070794
    mean_processing_ms: 0.5153905611782253
  time_since_restore: 603.7759914398193
  time_this_iter_s: 1.672990083694458
  time_total_s: 603.7759914398193
  timestamp: 1744206828
  timesteps_since_restore: 82350
  timesteps_this_iter: 225
  timesteps_total: 82350
  training_iteration: 366
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    366 |          603.776 |       82350 | 0.278144 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-53-54
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.3105177616998964
  episode_reward_mean: 0.27594420239503686
  episode_reward_min: 0.24304303596038088
  episodes_this_iter: 5
  episodes_total: 1850
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 96.842
    learner:
      default_policy:
        cur_kl_coeff: 1.0658141459917976e-15
        cur_lr: 4.999999873689376e-05
        entropy: 16.574504852294922
        entropy_coeff: 0.0
        kl: 0.021287109702825546
        policy_loss: -0.07280831784009933
        total_loss: -0.07261965423822403
        vf_explained_var: 0.9697405099868774
        vf_loss: 0.00018866200116463006
    load_time_ms: 1.009
    num_steps_sampled: 83250
    num_steps_trained: 83250
    sample_time_ms: 1565.843
    update_time_ms: 4.083
  iterations_since_restore: 370
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.25
    ram_util_percent: 77.5
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.574091687101696
    mean_inference_ms: 0.7319261692752486
    mean_processing_ms: 0.5157980228184083
  time_since_restore: 610.038941860199
  time_this_iter_s: 1.5604805946350098
  time_total_s: 610.038941860199
  timestamp: 1744206834
  timesteps_since_restore: 83250
  timesteps_this_iter: 225
  timesteps_total: 83250
  training_iteration: 370
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    370 |          610.039 |       83250 | 0.275944 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-54-00
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.3051463257050758
  episode_reward_mean: 0.275045347791236
  episode_reward_min: 0.24304303596038088
  episodes_this_iter: 5
  episodes_total: 1870
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 93.987
    learner:
      default_policy:
        cur_kl_coeff: 1.0658141459917976e-15
        cur_lr: 4.999999873689376e-05
        entropy: 16.66259765625
        entropy_coeff: 0.0
        kl: 0.016109205782413483
        policy_loss: -0.06616067886352539
        total_loss: -0.06597605347633362
        vf_explained_var: 0.9706131815910339
        vf_loss: 0.00018462445586919785
    load_time_ms: 0.917
    num_steps_sampled: 84150
    num_steps_trained: 84150
    sample_time_ms: 1476.091
    update_time_ms: 4.058
  iterations_since_restore: 374
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.333333333333332
    ram_util_percent: 77.73333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.574933256592754
    mean_inference_ms: 0.7321930558542814
    mean_processing_ms: 0.5159688967130837
  time_since_restore: 616.2312612533569
  time_this_iter_s: 1.5500454902648926
  time_total_s: 616.2312612533569
  timestamp: 1744206840
  timesteps_since_restore: 84150
  timesteps_this_iter: 225
  timesteps_total: 84150
  training_iteration: 374
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    374 |          616.231 |       84150 | 0.275045 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-54-07
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.3051463257050758
  episode_reward_mean: 0.27373746758270157
  episode_reward_min: 0.24304303596038088
  episodes_this_iter: 5
  episodes_total: 1890
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.212
    learner:
      default_policy:
        cur_kl_coeff: 1.0658141459917976e-15
        cur_lr: 4.999999873689376e-05
        entropy: 16.402965545654297
        entropy_coeff: 0.0
        kl: 0.013522175140678883
        policy_loss: -0.06665469706058502
        total_loss: -0.0665288195014
        vf_explained_var: 0.9795932769775391
        vf_loss: 0.00012588934623636305
    load_time_ms: 0.853
    num_steps_sampled: 85050
    num_steps_trained: 85050
    sample_time_ms: 1484.453
    update_time_ms: 3.718
  iterations_since_restore: 378
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.35
    ram_util_percent: 77.5
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.575451501566522
    mean_inference_ms: 0.7323337600305857
    mean_processing_ms: 0.5161186825180337
  time_since_restore: 622.7392303943634
  time_this_iter_s: 1.5429964065551758
  time_total_s: 622.7392303943634
  timestamp: 1744206847
  timesteps_since_restore: 85050
  timesteps_this_iter: 225
  timesteps_total: 85050
  training_iteration: 378
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    378 |          622.739 |       85050 | 0.273737 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-54-12
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.3051463257050758
  episode_reward_mean: 0.273178301813995
  episode_reward_min: 0.24304303596038088
  episodes_this_iter: 5
  episodes_total: 1905
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 93.28
    learner:
      default_policy:
        cur_kl_coeff: 1.0658141459917976e-15
        cur_lr: 4.999999873689376e-05
        entropy: 16.288049697875977
        entropy_coeff: 0.0
        kl: 0.022174734622240067
        policy_loss: -0.0593392476439476
        total_loss: -0.05915786698460579
        vf_explained_var: 0.9717567563056946
        vf_loss: 0.00018138422456104308
    load_time_ms: 0.905
    num_steps_sampled: 85725
    num_steps_trained: 85725
    sample_time_ms: 1509.998
    update_time_ms: 3.771
  iterations_since_restore: 381
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.033333333333335
    ram_util_percent: 77.7
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.57517039740807
    mean_inference_ms: 0.7323151860659992
    mean_processing_ms: 0.5161551346278734
  time_since_restore: 627.8830714225769
  time_this_iter_s: 2.0230295658111572
  time_total_s: 627.8830714225769
  timestamp: 1744206852
  timesteps_since_restore: 85725
  timesteps_this_iter: 225
  timesteps_total: 85725
  training_iteration: 381
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    381 |          627.883 |       85725 | 0.273178 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-54-17
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.2996933414963347
  episode_reward_mean: 0.2722489998115354
  episode_reward_min: 0.24467008605786514
  episodes_this_iter: 5
  episodes_total: 1920
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 92.064
    learner:
      default_policy:
        cur_kl_coeff: 1.0658141459917976e-15
        cur_lr: 4.999999873689376e-05
        entropy: 16.38641929626465
        entropy_coeff: 0.0
        kl: 0.023301715031266212
        policy_loss: -0.07587091624736786
        total_loss: -0.07564633339643478
        vf_explained_var: 0.9618304371833801
        vf_loss: 0.00022458071180153638
    load_time_ms: 0.929
    num_steps_sampled: 86400
    num_steps_trained: 86400
    sample_time_ms: 1567.034
    update_time_ms: 3.626
  iterations_since_restore: 384
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.2
    ram_util_percent: 77.53333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.574731389320621
    mean_inference_ms: 0.7322618126176298
    mean_processing_ms: 0.5161142207770579
  time_since_restore: 632.9016265869141
  time_this_iter_s: 1.6629180908203125
  time_total_s: 632.9016265869141
  timestamp: 1744206857
  timesteps_since_restore: 86400
  timesteps_this_iter: 225
  timesteps_total: 86400
  training_iteration: 384
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    384 |          632.902 |       86400 | 0.272249 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-54-24
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.2996933414963347
  episode_reward_mean: 0.2720656613606424
  episode_reward_min: 0.24467008605786514
  episodes_this_iter: 5
  episodes_total: 1935
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 103.356
    learner:
      default_policy:
        cur_kl_coeff: 1.0658141459917976e-15
        cur_lr: 4.999999873689376e-05
        entropy: 16.3624267578125
        entropy_coeff: 0.0
        kl: 0.021070541813969612
        policy_loss: -0.05870930105447769
        total_loss: -0.05848371237516403
        vf_explained_var: 0.9648189544677734
        vf_loss: 0.000225607625907287
    load_time_ms: 0.998
    num_steps_sampled: 87075
    num_steps_trained: 87075
    sample_time_ms: 1738.928
    update_time_ms: 5.671
  iterations_since_restore: 387
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 45.56666666666666
    ram_util_percent: 78.36666666666666
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.575768563503259
    mean_inference_ms: 0.7324742346810887
    mean_processing_ms: 0.5162083505318041
  time_since_restore: 639.7216794490814
  time_this_iter_s: 2.208723306655884
  time_total_s: 639.7216794490814
  timestamp: 1744206864
  timesteps_since_restore: 87075
  timesteps_this_iter: 225
  timesteps_total: 87075
  training_iteration: 387
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    387 |          639.722 |       87075 | 0.272066 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-54-29
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.2996933414963347
  episode_reward_mean: 0.2720009523048633
  episode_reward_min: 0.24467008605786514
  episodes_this_iter: 5
  episodes_total: 1950
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 101.17
    learner:
      default_policy:
        cur_kl_coeff: 1.0658141459917976e-15
        cur_lr: 4.999999873689376e-05
        entropy: 16.916641235351562
        entropy_coeff: 0.0
        kl: 0.0186015497893095
        policy_loss: -0.06710261106491089
        total_loss: -0.06692247092723846
        vf_explained_var: 0.9716567993164062
        vf_loss: 0.0001801355101633817
    load_time_ms: 1.002
    num_steps_sampled: 87750
    num_steps_trained: 87750
    sample_time_ms: 1779.659
    update_time_ms: 5.861
  iterations_since_restore: 390
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.46666666666667
    ram_util_percent: 77.7
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.57803319910174
    mean_inference_ms: 0.7328637533340766
    mean_processing_ms: 0.5164273221392643
  time_since_restore: 644.7731049060822
  time_this_iter_s: 1.6644842624664307
  time_total_s: 644.7731049060822
  timestamp: 1744206869
  timesteps_since_restore: 87750
  timesteps_this_iter: 225
  timesteps_total: 87750
  training_iteration: 390
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    390 |          644.773 |       87750 | 0.272001 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-54-34
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.2996933414963347
  episode_reward_mean: 0.27141386291481384
  episode_reward_min: 0.24467008605786514
  episodes_this_iter: 5
  episodes_total: 1965
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 103.14
    learner:
      default_policy:
        cur_kl_coeff: 1.0658141459917976e-15
        cur_lr: 4.999999873689376e-05
        entropy: 17.428373336791992
        entropy_coeff: 0.0
        kl: 0.029587959870696068
        policy_loss: -0.07875452190637589
        total_loss: -0.07846131175756454
        vf_explained_var: 0.9496026039123535
        vf_loss: 0.0002932194038294256
    load_time_ms: 1.03
    num_steps_sampled: 88425
    num_steps_trained: 88425
    sample_time_ms: 1751.996
    update_time_ms: 5.798
  iterations_since_restore: 393
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.96666666666667
    ram_util_percent: 77.5
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.580498065724023
    mean_inference_ms: 0.7333037847229846
    mean_processing_ms: 0.5166578958382813
  time_since_restore: 649.8937096595764
  time_this_iter_s: 1.9855260848999023
  time_total_s: 649.8937096595764
  timestamp: 1744206874
  timesteps_since_restore: 88425
  timesteps_this_iter: 225
  timesteps_total: 88425
  training_iteration: 393
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    393 |          649.894 |       88425 | 0.271414 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-54-40
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.2996933414963347
  episode_reward_mean: 0.27019534194616673
  episode_reward_min: 0.24467008605786514
  episodes_this_iter: 5
  episodes_total: 1985
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.92
    learner:
      default_policy:
        cur_kl_coeff: 1.0658141459917976e-15
        cur_lr: 4.999999873689376e-05
        entropy: 17.025333404541016
        entropy_coeff: 0.0
        kl: 0.02544994279742241
        policy_loss: -0.06065633147954941
        total_loss: -0.0604306161403656
        vf_explained_var: 0.9648629426956177
        vf_loss: 0.0002257172018289566
    load_time_ms: 0.924
    num_steps_sampled: 89325
    num_steps_trained: 89325
    sample_time_ms: 1529.741
    update_time_ms: 3.883
  iterations_since_restore: 397
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.03333333333333
    ram_util_percent: 77.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.583888080758411
    mean_inference_ms: 0.7339988332710056
    mean_processing_ms: 0.5169813627845383
  time_since_restore: 655.999274969101
  time_this_iter_s: 1.5787208080291748
  time_total_s: 655.999274969101
  timestamp: 1744206880
  timesteps_since_restore: 89325
  timesteps_this_iter: 225
  timesteps_total: 89325
  training_iteration: 397
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    397 |          655.999 |       89325 | 0.270195 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-54-46
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.2949788600129631
  episode_reward_mean: 0.26847019541658873
  episode_reward_min: 0.24413878199940858
  episodes_this_iter: 5
  episodes_total: 2000
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 94.308
    learner:
      default_policy:
        cur_kl_coeff: 1.0658141459917976e-15
        cur_lr: 4.999999873689376e-05
        entropy: 17.028423309326172
        entropy_coeff: 0.0
        kl: 0.020834043622016907
        policy_loss: -0.06304820626974106
        total_loss: -0.06290537118911743
        vf_explained_var: 0.9757764935493469
        vf_loss: 0.0001428285031579435
    load_time_ms: 0.981
    num_steps_sampled: 90000
    num_steps_trained: 90000
    sample_time_ms: 1617.117
    update_time_ms: 4.095
  iterations_since_restore: 400
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.2
    ram_util_percent: 77.6
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.5874094239317
    mean_inference_ms: 0.734673980909609
    mean_processing_ms: 0.5173327959331493
  time_since_restore: 661.9726402759552
  time_this_iter_s: 1.8667223453521729
  time_total_s: 661.9726402759552
  timestamp: 1744206886
  timesteps_since_restore: 90000
  timesteps_this_iter: 225
  timesteps_total: 90000
  training_iteration: 400
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    400 |          661.973 |       90000 |  0.26847 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-54-51
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.2949788600129631
  episode_reward_mean: 0.26841151838413974
  episode_reward_min: 0.24413878199940858
  episodes_this_iter: 5
  episodes_total: 2015
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.946
    learner:
      default_policy:
        cur_kl_coeff: 1.0658141459917976e-15
        cur_lr: 4.999999873689376e-05
        entropy: 17.179553985595703
        entropy_coeff: 0.0
        kl: 0.02192864380776882
        policy_loss: -0.06458000093698502
        total_loss: -0.06436623632907867
        vf_explained_var: 0.9649027585983276
        vf_loss: 0.00021375443611759692
    load_time_ms: 0.921
    num_steps_sampled: 90675
    num_steps_trained: 90675
    sample_time_ms: 1607.653
    update_time_ms: 4.218
  iterations_since_restore: 403
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.3
    ram_util_percent: 77.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.591184577040007
    mean_inference_ms: 0.7353628976942989
    mean_processing_ms: 0.5177146595673363
  time_since_restore: 666.974125623703
  time_this_iter_s: 1.438852310180664
  time_total_s: 666.974125623703
  timestamp: 1744206891
  timesteps_since_restore: 90675
  timesteps_this_iter: 225
  timesteps_total: 90675
  training_iteration: 403
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    403 |          666.974 |       90675 | 0.268412 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-54-57
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.29158048286519633
  episode_reward_mean: 0.26623019979068857
  episode_reward_min: 0.24413878199940858
  episodes_this_iter: 5
  episodes_total: 2035
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 94.133
    learner:
      default_policy:
        cur_kl_coeff: 1.0658141459917976e-15
        cur_lr: 4.999999873689376e-05
        entropy: 17.172536849975586
        entropy_coeff: 0.0
        kl: 0.02229425311088562
        policy_loss: -0.05589873343706131
        total_loss: -0.055678922683000565
        vf_explained_var: 0.9634617567062378
        vf_loss: 0.00021981338795740157
    load_time_ms: 0.985
    num_steps_sampled: 91575
    num_steps_trained: 91575
    sample_time_ms: 1603.486
    update_time_ms: 4.219
  iterations_since_restore: 407
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.85
    ram_util_percent: 77.1
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.593729220412473
    mean_inference_ms: 0.735844761036928
    mean_processing_ms: 0.5179937396199824
  time_since_restore: 673.0611367225647
  time_this_iter_s: 1.6413171291351318
  time_total_s: 673.0611367225647
  timestamp: 1744206897
  timesteps_since_restore: 91575
  timesteps_this_iter: 225
  timesteps_total: 91575
  training_iteration: 407
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    407 |          673.061 |       91575 |  0.26623 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-55-03
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.29158048286519633
  episode_reward_mean: 0.2646320973597723
  episode_reward_min: 0.23209004502629693
  episodes_this_iter: 5
  episodes_total: 2050
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.66
    learner:
      default_policy:
        cur_kl_coeff: 1.0658141459917976e-15
        cur_lr: 4.999999873689376e-05
        entropy: 16.958393096923828
        entropy_coeff: 0.0
        kl: 0.031172871589660645
        policy_loss: -0.07320885360240936
        total_loss: -0.07307998836040497
        vf_explained_var: 0.9777823686599731
        vf_loss: 0.0001288754283450544
    load_time_ms: 0.877
    num_steps_sampled: 92250
    num_steps_trained: 92250
    sample_time_ms: 1522.427
    update_time_ms: 4.061
  iterations_since_restore: 410
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.05
    ram_util_percent: 77.1
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.594269508627226
    mean_inference_ms: 0.7360163005115146
    mean_processing_ms: 0.5180841933368453
  time_since_restore: 678.1755101680756
  time_this_iter_s: 1.750575304031372
  time_total_s: 678.1755101680756
  timestamp: 1744206903
  timesteps_since_restore: 92250
  timesteps_this_iter: 225
  timesteps_total: 92250
  training_iteration: 410
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    410 |          678.176 |       92250 | 0.264632 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-55-09
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.29166585337242623
  episode_reward_mean: 0.2627443893641834
  episode_reward_min: 0.23209004502629693
  episodes_this_iter: 5
  episodes_total: 2070
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.669
    learner:
      default_policy:
        cur_kl_coeff: 1.598721113108578e-15
        cur_lr: 4.999999873689376e-05
        entropy: 16.4229679107666
        entropy_coeff: 0.0
        kl: 0.024673929437994957
        policy_loss: -0.07506789267063141
        total_loss: -0.07492904365062714
        vf_explained_var: 0.9757676124572754
        vf_loss: 0.00013884727377444506
    load_time_ms: 0.9
    num_steps_sampled: 93150
    num_steps_trained: 93150
    sample_time_ms: 1503.844
    update_time_ms: 3.994
  iterations_since_restore: 414
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.566666666666666
    ram_util_percent: 77.16666666666667
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.594631864593375
    mean_inference_ms: 0.7361861978193827
    mean_processing_ms: 0.5181846287529148
  time_since_restore: 684.5396046638489
  time_this_iter_s: 1.8065998554229736
  time_total_s: 684.5396046638489
  timestamp: 1744206909
  timesteps_since_restore: 93150
  timesteps_this_iter: 225
  timesteps_total: 93150
  training_iteration: 414
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    414 |           684.54 |       93150 | 0.262744 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-55-15
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.29166585337242623
  episode_reward_mean: 0.26121649424646326
  episode_reward_min: 0.23209004502629693
  episodes_this_iter: 5
  episodes_total: 2090
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.37
    learner:
      default_policy:
        cur_kl_coeff: 1.598721113108578e-15
        cur_lr: 4.999999873689376e-05
        entropy: 17.02918815612793
        entropy_coeff: 0.0
        kl: 0.04838871583342552
        policy_loss: -0.08160124719142914
        total_loss: -0.08143280446529388
        vf_explained_var: 0.9713836908340454
        vf_loss: 0.0001684420567471534
    load_time_ms: 0.973
    num_steps_sampled: 94050
    num_steps_trained: 94050
    sample_time_ms: 1514.543
    update_time_ms: 3.928
  iterations_since_restore: 418
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.95
    ram_util_percent: 77.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.595207143939053
    mean_inference_ms: 0.7363915015524932
    mean_processing_ms: 0.5183230252432047
  time_since_restore: 690.9963228702545
  time_this_iter_s: 1.4807920455932617
  time_total_s: 690.9963228702545
  timestamp: 1744206915
  timesteps_since_restore: 94050
  timesteps_this_iter: 225
  timesteps_total: 94050
  training_iteration: 418
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    418 |          690.996 |       94050 | 0.261216 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-55-21
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.29166585337242623
  episode_reward_mean: 0.25826837665920604
  episode_reward_min: 0.21350499016309454
  episodes_this_iter: 5
  episodes_total: 2110
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.659
    learner:
      default_policy:
        cur_kl_coeff: 2.3980817755419855e-15
        cur_lr: 4.999999873689376e-05
        entropy: 17.036788940429688
        entropy_coeff: 0.0
        kl: 0.03982362523674965
        policy_loss: -0.07312963902950287
        total_loss: -0.0730341449379921
        vf_explained_var: 0.9821282625198364
        vf_loss: 9.550391405355185e-05
    load_time_ms: 1.01
    num_steps_sampled: 94950
    num_steps_trained: 94950
    sample_time_ms: 1478.115
    update_time_ms: 3.919
  iterations_since_restore: 422
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.1
    ram_util_percent: 77.15
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.593231277340312
    mean_inference_ms: 0.7362428679924335
    mean_processing_ms: 0.5182467873119898
  time_since_restore: 696.9781229496002
  time_this_iter_s: 1.4885461330413818
  time_total_s: 696.9781229496002
  timestamp: 1744206921
  timesteps_since_restore: 94950
  timesteps_this_iter: 225
  timesteps_total: 94950
  training_iteration: 422
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    422 |          696.978 |       94950 | 0.258268 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-55-27
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.29166585337242623
  episode_reward_mean: 0.2553703818309402
  episode_reward_min: 0.21350499016309454
  episodes_this_iter: 5
  episodes_total: 2125
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.077
    learner:
      default_policy:
        cur_kl_coeff: 2.3980817755419855e-15
        cur_lr: 4.999999873689376e-05
        entropy: 17.305397033691406
        entropy_coeff: 0.0
        kl: 0.020695645362138748
        policy_loss: -0.07197465747594833
        total_loss: -0.07183631509542465
        vf_explained_var: 0.9727608561515808
        vf_loss: 0.00013834022684022784
    load_time_ms: 0.962
    num_steps_sampled: 95625
    num_steps_trained: 95625
    sample_time_ms: 1484.599
    update_time_ms: 3.89
  iterations_since_restore: 425
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.8
    ram_util_percent: 77.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.591748006925429
    mean_inference_ms: 0.7361878239060325
    mean_processing_ms: 0.5181960786231163
  time_since_restore: 702.0043885707855
  time_this_iter_s: 1.580674409866333
  time_total_s: 702.0043885707855
  timestamp: 1744206927
  timesteps_since_restore: 95625
  timesteps_this_iter: 225
  timesteps_total: 95625
  training_iteration: 425
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    425 |          702.004 |       95625 |  0.25537 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-55-32
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.29166585337242623
  episode_reward_mean: 0.2533286522172735
  episode_reward_min: 0.21350499016309454
  episodes_this_iter: 5
  episodes_total: 2140
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.882
    learner:
      default_policy:
        cur_kl_coeff: 2.3980817755419855e-15
        cur_lr: 4.999999873689376e-05
        entropy: 17.14861488342285
        entropy_coeff: 0.0
        kl: 0.02840026095509529
        policy_loss: -0.06693659722805023
        total_loss: -0.06678014248609543
        vf_explained_var: 0.9691497683525085
        vf_loss: 0.00015644489030819386
    load_time_ms: 0.926
    num_steps_sampled: 96300
    num_steps_trained: 96300
    sample_time_ms: 1569.493
    update_time_ms: 4.232
  iterations_since_restore: 428
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.366666666666664
    ram_util_percent: 77.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.591387806138662
    mean_inference_ms: 0.736327308367593
    mean_processing_ms: 0.5182363845189804
  time_since_restore: 707.6742963790894
  time_this_iter_s: 1.8452658653259277
  time_total_s: 707.6742963790894
  timestamp: 1744206932
  timesteps_since_restore: 96300
  timesteps_this_iter: 225
  timesteps_total: 96300
  training_iteration: 428
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    428 |          707.674 |       96300 | 0.253329 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-55-38
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.29166585337242623
  episode_reward_mean: 0.24939461704559274
  episode_reward_min: 0.21350499016309454
  episodes_this_iter: 5
  episodes_total: 2160
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.686
    learner:
      default_policy:
        cur_kl_coeff: 2.3980817755419855e-15
        cur_lr: 4.999999873689376e-05
        entropy: 17.212377548217773
        entropy_coeff: 0.0
        kl: 0.011857466772198677
        policy_loss: -0.04843714460730553
        total_loss: -0.048276036977767944
        vf_explained_var: 0.9670165181159973
        vf_loss: 0.00016111924196593463
    load_time_ms: 0.935
    num_steps_sampled: 97200
    num_steps_trained: 97200
    sample_time_ms: 1576.06
    update_time_ms: 4.323
  iterations_since_restore: 432
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.1
    ram_util_percent: 77.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.590719609100806
    mean_inference_ms: 0.7364599689516703
    mean_processing_ms: 0.5182881517211477
  time_since_restore: 713.7303216457367
  time_this_iter_s: 1.4542059898376465
  time_total_s: 713.7303216457367
  timestamp: 1744206938
  timesteps_since_restore: 97200
  timesteps_this_iter: 225
  timesteps_total: 97200
  training_iteration: 432
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    432 |           713.73 |       97200 | 0.249395 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-55-44
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.2728247726806045
  episode_reward_mean: 0.2468512447040661
  episode_reward_min: 0.21350499016309454
  episodes_this_iter: 5
  episodes_total: 2175
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 92.287
    learner:
      default_policy:
        cur_kl_coeff: 2.3980817755419855e-15
        cur_lr: 4.999999873689376e-05
        entropy: 17.056177139282227
        entropy_coeff: 0.0
        kl: 0.03009103611111641
        policy_loss: -0.07173126190900803
        total_loss: -0.07155470550060272
        vf_explained_var: 0.9625382423400879
        vf_loss: 0.00017656083218753338
    load_time_ms: 0.919
    num_steps_sampled: 97875
    num_steps_trained: 97875
    sample_time_ms: 1646.34
    update_time_ms: 4.328
  iterations_since_restore: 435
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.5
    ram_util_percent: 77.0
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.590644421997158
    mean_inference_ms: 0.7366104563742653
    mean_processing_ms: 0.5183506614001526
  time_since_restore: 719.477068901062
  time_this_iter_s: 2.0416343212127686
  time_total_s: 719.477068901062
  timestamp: 1744206944
  timesteps_since_restore: 97875
  timesteps_this_iter: 225
  timesteps_total: 97875
  training_iteration: 435
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    435 |          719.477 |       97875 | 0.246851 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-55-50
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.2661839824807505
  episode_reward_mean: 0.242935315545948
  episode_reward_min: 0.21350499016309454
  episodes_this_iter: 5
  episodes_total: 2190
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 92.076
    learner:
      default_policy:
        cur_kl_coeff: 2.3980817755419855e-15
        cur_lr: 4.999999873689376e-05
        entropy: 17.018497467041016
        entropy_coeff: 0.0
        kl: 0.016351085156202316
        policy_loss: -0.04629044979810715
        total_loss: -0.04614764451980591
        vf_explained_var: 0.9711202383041382
        vf_loss: 0.00014279804599937052
    load_time_ms: 0.889
    num_steps_sampled: 98550
    num_steps_trained: 98550
    sample_time_ms: 1666.987
    update_time_ms: 3.952
  iterations_since_restore: 438
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.36666666666667
    ram_util_percent: 77.53333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.591710901591877
    mean_inference_ms: 0.7369517563611475
    mean_processing_ms: 0.5184987767956594
  time_since_restore: 725.3470258712769
  time_this_iter_s: 1.915097713470459
  time_total_s: 725.3470258712769
  timestamp: 1744206950
  timesteps_since_restore: 98550
  timesteps_this_iter: 225
  timesteps_total: 98550
  training_iteration: 438
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    438 |          725.347 |       98550 | 0.242935 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-55-55
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.2639103699481904
  episode_reward_mean: 0.24111113560582928
  episode_reward_min: 0.21805955780116387
  episodes_this_iter: 5
  episodes_total: 2205
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 92.505
    learner:
      default_policy:
        cur_kl_coeff: 2.3980817755419855e-15
        cur_lr: 4.999999873689376e-05
        entropy: 16.970495223999023
        entropy_coeff: 0.0
        kl: 0.03184373676776886
        policy_loss: -0.07575218379497528
        total_loss: -0.07565698772668839
        vf_explained_var: 0.9799003601074219
        vf_loss: 9.520226012682542e-05
    load_time_ms: 0.912
    num_steps_sampled: 99225
    num_steps_trained: 99225
    sample_time_ms: 1712.642
    update_time_ms: 3.855
  iterations_since_restore: 441
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.549999999999997
    ram_util_percent: 77.4
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.593888590419187
    mean_inference_ms: 0.7374320881445535
    mean_processing_ms: 0.5187219704514447
  time_since_restore: 730.4102032184601
  time_this_iter_s: 1.617978572845459
  time_total_s: 730.4102032184601
  timestamp: 1744206955
  timesteps_since_restore: 99225
  timesteps_this_iter: 225
  timesteps_total: 99225
  training_iteration: 441
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    441 |           730.41 |       99225 | 0.241111 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-56-00
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.26257749697068977
  episode_reward_mean: 0.2395041974873263
  episode_reward_min: 0.21805955780116387
  episodes_this_iter: 5
  episodes_total: 2220
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.056
    learner:
      default_policy:
        cur_kl_coeff: 2.3980817755419855e-15
        cur_lr: 4.999999873689376e-05
        entropy: 17.537261962890625
        entropy_coeff: 0.0
        kl: 0.03189147263765335
        policy_loss: -0.06650488823652267
        total_loss: -0.06637437641620636
        vf_explained_var: 0.9735428094863892
        vf_loss: 0.00013051312998868525
    load_time_ms: 0.898
    num_steps_sampled: 99900
    num_steps_trained: 99900
    sample_time_ms: 1714.556
    update_time_ms: 4.187
  iterations_since_restore: 444
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.7
    ram_util_percent: 77.23333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.596533267957245
    mean_inference_ms: 0.7379613079076114
    mean_processing_ms: 0.518997264390736
  time_since_restore: 735.5763342380524
  time_this_iter_s: 1.6009416580200195
  time_total_s: 735.5763342380524
  timestamp: 1744206960
  timesteps_since_restore: 99900
  timesteps_this_iter: 225
  timesteps_total: 99900
  training_iteration: 444
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    444 |          735.576 |       99900 | 0.239504 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-56-06
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.26257749697068977
  episode_reward_mean: 0.237956695632986
  episode_reward_min: 0.20604911751549262
  episodes_this_iter: 5
  episodes_total: 2235
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.609
    learner:
      default_policy:
        cur_kl_coeff: 2.3980817755419855e-15
        cur_lr: 4.999999873689376e-05
        entropy: 16.499608993530273
        entropy_coeff: 0.0
        kl: 0.018957089632749557
        policy_loss: -0.051848821341991425
        total_loss: -0.051720429211854935
        vf_explained_var: 0.9724729657173157
        vf_loss: 0.00012840909766964614
    load_time_ms: 0.925
    num_steps_sampled: 100575
    num_steps_trained: 100575
    sample_time_ms: 1676.57
    update_time_ms: 4.236
  iterations_since_restore: 447
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.7
    ram_util_percent: 77.4
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.599366325019465
    mean_inference_ms: 0.7384841959739417
    mean_processing_ms: 0.5193155913004327
  time_since_restore: 741.1905810832977
  time_this_iter_s: 1.7564144134521484
  time_total_s: 741.1905810832977
  timestamp: 1744206966
  timesteps_since_restore: 100575
  timesteps_this_iter: 225
  timesteps_total: 100575
  training_iteration: 447
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    447 |          741.191 |      100575 | 0.237957 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-56-11
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.26123724939539866
  episode_reward_mean: 0.23592014598858588
  episode_reward_min: 0.20604911751549262
  episodes_this_iter: 5
  episodes_total: 2250
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 96.878
    learner:
      default_policy:
        cur_kl_coeff: 2.3980817755419855e-15
        cur_lr: 4.999999873689376e-05
        entropy: 16.677602767944336
        entropy_coeff: 0.0
        kl: 0.01831938698887825
        policy_loss: -0.06560397148132324
        total_loss: -0.06546957790851593
        vf_explained_var: 0.9705089330673218
        vf_loss: 0.00013440426846500486
    load_time_ms: 0.941
    num_steps_sampled: 101250
    num_steps_trained: 101250
    sample_time_ms: 1666.62
    update_time_ms: 4.234
  iterations_since_restore: 450
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.1
    ram_util_percent: 77.5
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.6022758775303965
    mean_inference_ms: 0.7390131159727886
    mean_processing_ms: 0.5196911836981197
  time_since_restore: 746.5145442485809
  time_this_iter_s: 1.6379730701446533
  time_total_s: 746.5145442485809
  timestamp: 1744206971
  timesteps_since_restore: 101250
  timesteps_this_iter: 225
  timesteps_total: 101250
  training_iteration: 450
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    450 |          746.515 |      101250 |  0.23592 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-56-18
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.26123724939539866
  episode_reward_mean: 0.23290982876470498
  episode_reward_min: 0.20451025143041693
  episodes_this_iter: 5
  episodes_total: 2270
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 96.847
    learner:
      default_policy:
        cur_kl_coeff: 5.395683730271671e-15
        cur_lr: 4.999999873689376e-05
        entropy: 16.76116371154785
        entropy_coeff: 0.0
        kl: 0.041128166019916534
        policy_loss: -0.07871626317501068
        total_loss: -0.07861711084842682
        vf_explained_var: 0.9774936437606812
        vf_loss: 9.915349073708057e-05
    load_time_ms: 0.991
    num_steps_sampled: 102150
    num_steps_trained: 102150
    sample_time_ms: 1672.948
    update_time_ms: 3.988
  iterations_since_restore: 454
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.73333333333333
    ram_util_percent: 77.6
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.606750028090589
    mean_inference_ms: 0.7398035134228226
    mean_processing_ms: 0.5202385347164045
  time_since_restore: 753.3592376708984
  time_this_iter_s: 1.9306144714355469
  time_total_s: 753.3592376708984
  timestamp: 1744206978
  timesteps_since_restore: 102150
  timesteps_this_iter: 225
  timesteps_total: 102150
  training_iteration: 454
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    454 |          753.359 |      102150 |  0.23291 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-56-24
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.26123724939539866
  episode_reward_mean: 0.23058644322144964
  episode_reward_min: 0.19206607846735468
  episodes_this_iter: 5
  episodes_total: 2285
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 102.0
    learner:
      default_policy:
        cur_kl_coeff: 8.09352601892398e-15
        cur_lr: 4.999999873689376e-05
        entropy: 16.61583137512207
        entropy_coeff: 0.0
        kl: 0.016058925539255142
        policy_loss: -0.06367477774620056
        total_loss: -0.06357288360595703
        vf_explained_var: 0.9750224947929382
        vf_loss: 0.00010190003376919776
    load_time_ms: 0.962
    num_steps_sampled: 102825
    num_steps_trained: 102825
    sample_time_ms: 1679.665
    update_time_ms: 3.849
  iterations_since_restore: 457
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.95
    ram_util_percent: 77.75
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.609798454075506
    mean_inference_ms: 0.7403580654169026
    mean_processing_ms: 0.5206284165439226
  time_since_restore: 759.0900681018829
  time_this_iter_s: 1.878981590270996
  time_total_s: 759.0900681018829
  timestamp: 1744206984
  timesteps_since_restore: 102825
  timesteps_this_iter: 225
  timesteps_total: 102825
  training_iteration: 457
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    457 |           759.09 |      102825 | 0.230586 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-56-29
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.26123724939539866
  episode_reward_mean: 0.2276334342500817
  episode_reward_min: 0.19206607846735468
  episodes_this_iter: 5
  episodes_total: 2300
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 97.224
    learner:
      default_policy:
        cur_kl_coeff: 8.09352601892398e-15
        cur_lr: 4.999999873689376e-05
        entropy: 16.373193740844727
        entropy_coeff: 0.0
        kl: 0.03333807736635208
        policy_loss: -0.08477403968572617
        total_loss: -0.08458499610424042
        vf_explained_var: 0.952342689037323
        vf_loss: 0.00018904756871052086
    load_time_ms: 1.04
    num_steps_sampled: 103500
    num_steps_trained: 103500
    sample_time_ms: 1658.7
    update_time_ms: 3.931
  iterations_since_restore: 460
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.433333333333337
    ram_util_percent: 77.7
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.61228113268314
    mean_inference_ms: 0.740836894127805
    mean_processing_ms: 0.5209928332693555
  time_since_restore: 764.1585001945496
  time_this_iter_s: 1.6676561832427979
  time_total_s: 764.1585001945496
  timestamp: 1744206989
  timesteps_since_restore: 103500
  timesteps_this_iter: 225
  timesteps_total: 103500
  training_iteration: 460
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    460 |          764.159 |      103500 | 0.227633 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-56-34
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.26123724939539866
  episode_reward_mean: 0.22502460315610828
  episode_reward_min: 0.19206607846735468
  episodes_this_iter: 5
  episodes_total: 2315
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 93.401
    learner:
      default_policy:
        cur_kl_coeff: 8.09352601892398e-15
        cur_lr: 4.999999873689376e-05
        entropy: 16.426532745361328
        entropy_coeff: 0.0
        kl: 0.040145259350538254
        policy_loss: -0.0817621722817421
        total_loss: -0.08164788782596588
        vf_explained_var: 0.971082329750061
        vf_loss: 0.00011427867866586894
    load_time_ms: 0.947
    num_steps_sampled: 104175
    num_steps_trained: 104175
    sample_time_ms: 1673.281
    update_time_ms: 4.369
  iterations_since_restore: 463
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.9
    ram_util_percent: 77.7
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.6147240656239275
    mean_inference_ms: 0.741312098743855
    mean_processing_ms: 0.521349874787545
  time_since_restore: 769.1830885410309
  time_this_iter_s: 1.5783300399780273
  time_total_s: 769.1830885410309
  timestamp: 1744206994
  timesteps_since_restore: 104175
  timesteps_this_iter: 225
  timesteps_total: 104175
  training_iteration: 463
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    463 |          769.183 |      104175 | 0.225025 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-56-40
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.24867128385266496
  episode_reward_mean: 0.21968463888563566
  episode_reward_min: 0.17851651077641684
  episodes_this_iter: 5
  episodes_total: 2335
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.257
    learner:
      default_policy:
        cur_kl_coeff: 1.8210432483787772e-14
        cur_lr: 4.999999873689376e-05
        entropy: 16.162250518798828
        entropy_coeff: 0.0
        kl: 0.03327884525060654
        policy_loss: -0.08415278047323227
        total_loss: -0.08406496047973633
        vf_explained_var: 0.9753605723381042
        vf_loss: 8.782408258412033e-05
    load_time_ms: 0.973
    num_steps_sampled: 105075
    num_steps_trained: 105075
    sample_time_ms: 1553.942
    update_time_ms: 4.454
  iterations_since_restore: 467
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.75
    ram_util_percent: 77.5
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.617130454591679
    mean_inference_ms: 0.741828388917377
    mean_processing_ms: 0.5217794097266177
  time_since_restore: 775.6097707748413
  time_this_iter_s: 1.5273408889770508
  time_total_s: 775.6097707748413
  timestamp: 1744207000
  timesteps_since_restore: 105075
  timesteps_this_iter: 225
  timesteps_total: 105075
  training_iteration: 467
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    467 |           775.61 |      105075 | 0.219685 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-56-46
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.24867128385266496
  episode_reward_mean: 0.21581784707308216
  episode_reward_min: 0.17851651077641684
  episodes_this_iter: 5
  episodes_total: 2350
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 86.275
    learner:
      default_policy:
        cur_kl_coeff: 1.8210432483787772e-14
        cur_lr: 4.999999873689376e-05
        entropy: 16.04043960571289
        entropy_coeff: 0.0
        kl: 0.026736179366707802
        policy_loss: -0.0713428407907486
        total_loss: -0.07112693041563034
        vf_explained_var: 0.9398849606513977
        vf_loss: 0.00021590324467979372
    load_time_ms: 0.928
    num_steps_sampled: 105750
    num_steps_trained: 105750
    sample_time_ms: 1570.641
    update_time_ms: 4.337
  iterations_since_restore: 470
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.8
    ram_util_percent: 77.6
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.618378247164831
    mean_inference_ms: 0.7421135262068944
    mean_processing_ms: 0.521990567281434
  time_since_restore: 780.8121783733368
  time_this_iter_s: 1.653045654296875
  time_total_s: 780.8121783733368
  timestamp: 1744207006
  timesteps_since_restore: 105750
  timesteps_this_iter: 225
  timesteps_total: 105750
  training_iteration: 470
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    470 |          780.812 |      105750 | 0.215818 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-56-52
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.24544141603779357
  episode_reward_mean: 0.21162627394946928
  episode_reward_min: 0.17851651077641684
  episodes_this_iter: 5
  episodes_total: 2370
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 88.426
    learner:
      default_policy:
        cur_kl_coeff: 1.8210432483787772e-14
        cur_lr: 4.999999873689376e-05
        entropy: 15.530634880065918
        entropy_coeff: 0.0
        kl: 0.033934514969587326
        policy_loss: -0.07115688174962997
        total_loss: -0.07105066627264023
        vf_explained_var: 0.9683406949043274
        vf_loss: 0.0001062108640326187
    load_time_ms: 0.964
    num_steps_sampled: 106650
    num_steps_trained: 106650
    sample_time_ms: 1543.281
    update_time_ms: 3.935
  iterations_since_restore: 474
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.400000000000002
    ram_util_percent: 77.56666666666666
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.619746882698099
    mean_inference_ms: 0.7423873694666457
    mean_processing_ms: 0.52223226944672
  time_since_restore: 787.3231225013733
  time_this_iter_s: 1.8451967239379883
  time_total_s: 787.3231225013733
  timestamp: 1744207012
  timesteps_since_restore: 106650
  timesteps_this_iter: 225
  timesteps_total: 106650
  training_iteration: 474
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    474 |          787.323 |      106650 | 0.211626 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-56-57
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.23274935971285107
  episode_reward_mean: 0.21016349601902373
  episode_reward_min: 0.17851651077641684
  episodes_this_iter: 5
  episodes_total: 2385
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.382
    learner:
      default_policy:
        cur_kl_coeff: 1.8210432483787772e-14
        cur_lr: 4.999999873689376e-05
        entropy: 15.685585021972656
        entropy_coeff: 0.0
        kl: 0.07363331317901611
        policy_loss: -0.10026393085718155
        total_loss: -0.10016831010580063
        vf_explained_var: 0.9748409390449524
        vf_loss: 9.560829494148493e-05
    load_time_ms: 0.982
    num_steps_sampled: 107325
    num_steps_trained: 107325
    sample_time_ms: 1570.199
    update_time_ms: 3.943
  iterations_since_restore: 477
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.3
    ram_util_percent: 77.8
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.620095736372775
    mean_inference_ms: 0.742461855037661
    mean_processing_ms: 0.5223646147362032
  time_since_restore: 792.3078935146332
  time_this_iter_s: 1.6209983825683594
  time_total_s: 792.3078935146332
  timestamp: 1744207017
  timesteps_since_restore: 107325
  timesteps_this_iter: 225
  timesteps_total: 107325
  training_iteration: 477
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    477 |          792.308 |      107325 | 0.210163 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-57-03
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.23134211696244014
  episode_reward_mean: 0.20916632477860211
  episode_reward_min: 0.17851651077641684
  episodes_this_iter: 5
  episodes_total: 2400
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 93.291
    learner:
      default_policy:
        cur_kl_coeff: 2.7315650419747553e-14
        cur_lr: 4.999999873689376e-05
        entropy: 15.377116203308105
        entropy_coeff: 0.0
        kl: 0.049875181168317795
        policy_loss: -0.08596019446849823
        total_loss: -0.08582236617803574
        vf_explained_var: 0.9637155532836914
        vf_loss: 0.00013784195471089333
    load_time_ms: 0.932
    num_steps_sampled: 108000
    num_steps_trained: 108000
    sample_time_ms: 1579.928
    update_time_ms: 3.939
  iterations_since_restore: 480
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.133333333333333
    ram_util_percent: 77.66666666666666
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.620416505244755
    mean_inference_ms: 0.7425454493620808
    mean_processing_ms: 0.5224861307112552
  time_since_restore: 797.6274840831757
  time_this_iter_s: 1.6933751106262207
  time_total_s: 797.6274840831757
  timestamp: 1744207023
  timesteps_since_restore: 108000
  timesteps_this_iter: 225
  timesteps_total: 108000
  training_iteration: 480
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    480 |          797.627 |      108000 | 0.209166 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-57-09
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.23058320468919977
  episode_reward_mean: 0.2090331241382226
  episode_reward_min: 0.18136154703270804
  episodes_this_iter: 5
  episodes_total: 2420
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 92.373
    learner:
      default_policy:
        cur_kl_coeff: 4.0973473935555435e-14
        cur_lr: 4.999999873689376e-05
        entropy: 15.440402030944824
        entropy_coeff: 0.0
        kl: 0.04319313168525696
        policy_loss: -0.07454369962215424
        total_loss: -0.07441660016775131
        vf_explained_var: 0.9675763249397278
        vf_loss: 0.00012708830763585865
    load_time_ms: 0.925
    num_steps_sampled: 108900
    num_steps_trained: 108900
    sample_time_ms: 1590.246
    update_time_ms: 3.76
  iterations_since_restore: 484
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.96666666666667
    ram_util_percent: 77.76666666666667
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.62059386534125
    mean_inference_ms: 0.7426327555295705
    mean_processing_ms: 0.5226004867754613
  time_since_restore: 804.2286014556885
  time_this_iter_s: 1.8682968616485596
  time_total_s: 804.2286014556885
  timestamp: 1744207029
  timesteps_since_restore: 108900
  timesteps_this_iter: 225
  timesteps_total: 108900
  training_iteration: 484
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    484 |          804.229 |      108900 | 0.209033 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-57-16
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.23058320468919977
  episode_reward_mean: 0.2092880747701329
  episode_reward_min: 0.18136154703270804
  episodes_this_iter: 5
  episodes_total: 2440
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.825
    learner:
      default_policy:
        cur_kl_coeff: 6.146020920926726e-14
        cur_lr: 4.999999873689376e-05
        entropy: 15.349780082702637
        entropy_coeff: 0.0
        kl: 0.036429982632398605
        policy_loss: -0.07754833996295929
        total_loss: -0.07741613686084747
        vf_explained_var: 0.9659149050712585
        vf_loss: 0.0001321962772635743
    load_time_ms: 0.939
    num_steps_sampled: 109800
    num_steps_trained: 109800
    sample_time_ms: 1565.022
    update_time_ms: 3.667
  iterations_since_restore: 488
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.133333333333336
    ram_util_percent: 77.96666666666667
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.621100440222096
    mean_inference_ms: 0.7427719657607301
    mean_processing_ms: 0.5227448323011405
  time_since_restore: 810.8242857456207
  time_this_iter_s: 1.644561767578125
  time_total_s: 810.8242857456207
  timestamp: 1744207036
  timesteps_since_restore: 109800
  timesteps_this_iter: 225
  timesteps_total: 109800
  training_iteration: 488
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    488 |          810.824 |      109800 | 0.209288 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-57-22
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.23058320468919977
  episode_reward_mean: 0.21069094543711817
  episode_reward_min: 0.19279400710463074
  episodes_this_iter: 5
  episodes_total: 2460
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.914
    learner:
      default_policy:
        cur_kl_coeff: 9.219032059016447e-14
        cur_lr: 4.999999873689376e-05
        entropy: 15.321237564086914
        entropy_coeff: 0.0
        kl: 0.026914602145552635
        policy_loss: -0.07605143636465073
        total_loss: -0.07596763223409653
        vf_explained_var: 0.9777676463127136
        vf_loss: 8.380600047530606e-05
    load_time_ms: 0.913
    num_steps_sampled: 110700
    num_steps_trained: 110700
    sample_time_ms: 1564.163
    update_time_ms: 3.758
  iterations_since_restore: 492
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.35
    ram_util_percent: 77.7
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.621372848979984
    mean_inference_ms: 0.7429901143969238
    mean_processing_ms: 0.5229222700172503
  time_since_restore: 817.3909182548523
  time_this_iter_s: 1.6680171489715576
  time_total_s: 817.3909182548523
  timestamp: 1744207042
  timesteps_since_restore: 110700
  timesteps_this_iter: 225
  timesteps_total: 110700
  training_iteration: 492
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    492 |          817.391 |      110700 | 0.210691 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-57-28
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.23058320468919977
  episode_reward_mean: 0.20988447407787988
  episode_reward_min: 0.1900648534386961
  episodes_this_iter: 5
  episodes_total: 2475
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.167
    learner:
      default_policy:
        cur_kl_coeff: 1.3828547410898312e-13
        cur_lr: 4.999999873689376e-05
        entropy: 15.106008529663086
        entropy_coeff: 0.0
        kl: 0.04110727459192276
        policy_loss: -0.07388315349817276
        total_loss: -0.0737508088350296
        vf_explained_var: 0.9644610285758972
        vf_loss: 0.00013234862126410007
    load_time_ms: 0.94
    num_steps_sampled: 111375
    num_steps_trained: 111375
    sample_time_ms: 1570.92
    update_time_ms: 3.831
  iterations_since_restore: 495
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.4
    ram_util_percent: 77.8
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.621996119767773
    mean_inference_ms: 0.7432272524899182
    mean_processing_ms: 0.5230645858200142
  time_since_restore: 822.6488265991211
  time_this_iter_s: 1.4763844013214111
  time_total_s: 822.6488265991211
  timestamp: 1744207048
  timesteps_since_restore: 111375
  timesteps_this_iter: 225
  timesteps_total: 111375
  training_iteration: 495
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    495 |          822.649 |      111375 | 0.209884 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-57-34
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.22854703075777727
  episode_reward_mean: 0.20949926622324155
  episode_reward_min: 0.1900648534386961
  episodes_this_iter: 5
  episodes_total: 2495
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.449
    learner:
      default_policy:
        cur_kl_coeff: 2.0742821793973826e-13
        cur_lr: 4.999999873689376e-05
        entropy: 14.5501127243042
        entropy_coeff: 0.0
        kl: 0.03521459549665451
        policy_loss: -0.07754535973072052
        total_loss: -0.0774635523557663
        vf_explained_var: 0.978377640247345
        vf_loss: 8.181323937606066e-05
    load_time_ms: 0.888
    num_steps_sampled: 112275
    num_steps_trained: 112275
    sample_time_ms: 1558.356
    update_time_ms: 3.928
  iterations_since_restore: 499
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.266666666666666
    ram_util_percent: 77.86666666666666
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.622139535711328
    mean_inference_ms: 0.7433850867135205
    mean_processing_ms: 0.5231834131779264
  time_since_restore: 829.1156175136566
  time_this_iter_s: 1.714965581893921
  time_total_s: 829.1156175136566
  timestamp: 1744207054
  timesteps_since_restore: 112275
  timesteps_this_iter: 225
  timesteps_total: 112275
  training_iteration: 499
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    499 |          829.116 |      112275 | 0.209499 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-57-40
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.22854703075777727
  episode_reward_mean: 0.20823265134255414
  episode_reward_min: 0.18639755785010503
  episodes_this_iter: 5
  episodes_total: 2510
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.06
    learner:
      default_policy:
        cur_kl_coeff: 3.1114233368587096e-13
        cur_lr: 4.999999873689376e-05
        entropy: 14.970207214355469
        entropy_coeff: 0.0
        kl: 0.030543634667992592
        policy_loss: -0.06569350510835648
        total_loss: -0.06556171923875809
        vf_explained_var: 0.964643657207489
        vf_loss: 0.00013178715016692877
    load_time_ms: 0.921
    num_steps_sampled: 112950
    num_steps_trained: 112950
    sample_time_ms: 1604.387
    update_time_ms: 3.837
  iterations_since_restore: 502
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.5
    ram_util_percent: 77.85
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.622490769095719
    mean_inference_ms: 0.743542069084889
    mean_processing_ms: 0.5233843943287547
  time_since_restore: 834.4243218898773
  time_this_iter_s: 1.5936803817749023
  time_total_s: 834.4243218898773
  timestamp: 1744207060
  timesteps_since_restore: 112950
  timesteps_this_iter: 225
  timesteps_total: 112950
  training_iteration: 502
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    502 |          834.424 |      112950 | 0.208233 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-57-45
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.22795018000603856
  episode_reward_mean: 0.2077643039644226
  episode_reward_min: 0.18639755785010503
  episodes_this_iter: 5
  episodes_total: 2525
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 96.385
    learner:
      default_policy:
        cur_kl_coeff: 3.1114233368587096e-13
        cur_lr: 4.999999873689376e-05
        entropy: 14.7762451171875
        entropy_coeff: 0.0
        kl: 0.03950270265340805
        policy_loss: -0.07643483579158783
        total_loss: -0.07632287591695786
        vf_explained_var: 0.9701337814331055
        vf_loss: 0.00011197811545571312
    load_time_ms: 0.936
    num_steps_sampled: 113625
    num_steps_trained: 113625
    sample_time_ms: 1601.655
    update_time_ms: 3.65
  iterations_since_restore: 505
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.35
    ram_util_percent: 77.7
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.6231050695510465
    mean_inference_ms: 0.7437771099811218
    mean_processing_ms: 0.5236233502644829
  time_since_restore: 839.7091872692108
  time_this_iter_s: 1.6397168636322021
  time_total_s: 839.7091872692108
  timestamp: 1744207065
  timesteps_since_restore: 113625
  timesteps_this_iter: 225
  timesteps_total: 113625
  training_iteration: 505
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    505 |          839.709 |      113625 | 0.207764 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-57-50
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.2255294358732303
  episode_reward_mean: 0.20722788725563315
  episode_reward_min: 0.18639755785010503
  episodes_this_iter: 5
  episodes_total: 2540
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 94.061
    learner:
      default_policy:
        cur_kl_coeff: 4.667134734237521e-13
        cur_lr: 4.999999873689376e-05
        entropy: 14.864709854125977
        entropy_coeff: 0.0
        kl: 0.029249077662825584
        policy_loss: -0.060933541506528854
        total_loss: -0.06086263805627823
        vf_explained_var: 0.9802865982055664
        vf_loss: 7.09020605427213e-05
    load_time_ms: 0.964
    num_steps_sampled: 114300
    num_steps_trained: 114300
    sample_time_ms: 1644.783
    update_time_ms: 3.771
  iterations_since_restore: 508
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.049999999999997
    ram_util_percent: 78.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.623804236662027
    mean_inference_ms: 0.744027257272978
    mean_processing_ms: 0.523827477208778
  time_since_restore: 844.8708491325378
  time_this_iter_s: 1.7254083156585693
  time_total_s: 844.8708491325378
  timestamp: 1744207070
  timesteps_since_restore: 114300
  timesteps_this_iter: 225
  timesteps_total: 114300
  training_iteration: 508
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    508 |          844.871 |      114300 | 0.207228 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-57-55
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.2255294358732303
  episode_reward_mean: 0.2060494420875781
  episode_reward_min: 0.18639755785010503
  episodes_this_iter: 5
  episodes_total: 2555
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 95.642
    learner:
      default_policy:
        cur_kl_coeff: 4.667134734237521e-13
        cur_lr: 4.999999873689376e-05
        entropy: 14.767578125
        entropy_coeff: 0.0
        kl: 0.04792844131588936
        policy_loss: -0.07719464600086212
        total_loss: -0.07711400091648102
        vf_explained_var: 0.9768298864364624
        vf_loss: 8.064234862104058e-05
    load_time_ms: 0.992
    num_steps_sampled: 114975
    num_steps_trained: 114975
    sample_time_ms: 1624.34
    update_time_ms: 3.898
  iterations_since_restore: 511
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.46666666666667
    ram_util_percent: 78.16666666666667
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.624835303252103
    mean_inference_ms: 0.7443220654989539
    mean_processing_ms: 0.5240143277356729
  time_since_restore: 850.1148762702942
  time_this_iter_s: 1.7033216953277588
  time_total_s: 850.1148762702942
  timestamp: 1744207075
  timesteps_since_restore: 114975
  timesteps_this_iter: 225
  timesteps_total: 114975
  training_iteration: 511
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    511 |          850.115 |      114975 | 0.206049 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-58-01
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.2255294358732303
  episode_reward_mean: 0.20511225789403442
  episode_reward_min: 0.18639755785010503
  episodes_this_iter: 5
  episodes_total: 2570
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 95.62
    learner:
      default_policy:
        cur_kl_coeff: 1.0501053152034423e-12
        cur_lr: 4.999999873689376e-05
        entropy: 14.781087875366211
        entropy_coeff: 0.0
        kl: 0.04163765907287598
        policy_loss: -0.0726313591003418
        total_loss: -0.07255516946315765
        vf_explained_var: 0.9788839221000671
        vf_loss: 7.618371455464512e-05
    load_time_ms: 0.971
    num_steps_sampled: 115650
    num_steps_trained: 115650
    sample_time_ms: 1629.449
    update_time_ms: 3.87
  iterations_since_restore: 514
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.6
    ram_util_percent: 78.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.625869304865585
    mean_inference_ms: 0.7446356483359008
    mean_processing_ms: 0.5242315354186453
  time_since_restore: 855.4025752544403
  time_this_iter_s: 1.8859763145446777
  time_total_s: 855.4025752544403
  timestamp: 1744207081
  timesteps_since_restore: 115650
  timesteps_this_iter: 225
  timesteps_total: 115650
  training_iteration: 514
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    514 |          855.403 |      115650 | 0.205112 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-58-06
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.22470790446659167
  episode_reward_mean: 0.2034941114182427
  episode_reward_min: 0.1791357782495067
  episodes_this_iter: 5
  episodes_total: 2585
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.61
    learner:
      default_policy:
        cur_kl_coeff: 1.5751579728051635e-12
        cur_lr: 4.999999873689376e-05
        entropy: 15.145135879516602
        entropy_coeff: 0.0
        kl: 0.049693409353494644
        policy_loss: -0.0714825838804245
        total_loss: -0.07140392810106277
        vf_explained_var: 0.9754932522773743
        vf_loss: 7.865742372814566e-05
    load_time_ms: 0.982
    num_steps_sampled: 116325
    num_steps_trained: 116325
    sample_time_ms: 1633.478
    update_time_ms: 3.747
  iterations_since_restore: 517
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.566666666666663
    ram_util_percent: 77.73333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.6271953817870894
    mean_inference_ms: 0.7450452298218155
    mean_processing_ms: 0.5244794387162492
  time_since_restore: 860.4761424064636
  time_this_iter_s: 1.694371223449707
  time_total_s: 860.4761424064636
  timestamp: 1744207086
  timesteps_since_restore: 116325
  timesteps_this_iter: 225
  timesteps_total: 116325
  training_iteration: 517
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    517 |          860.476 |      116325 | 0.203494 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-58-11
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.22470790446659167
  episode_reward_mean: 0.2021710341396346
  episode_reward_min: 0.1791357782495067
  episodes_this_iter: 5
  episodes_total: 2600
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.254
    learner:
      default_policy:
        cur_kl_coeff: 2.362736959207745e-12
        cur_lr: 4.999999873689376e-05
        entropy: 14.664216995239258
        entropy_coeff: 0.0
        kl: 0.051399994641542435
        policy_loss: -0.08222205936908722
        total_loss: -0.0821019634604454
        vf_explained_var: 0.9646619558334351
        vf_loss: 0.00012008182238787413
    load_time_ms: 0.962
    num_steps_sampled: 117000
    num_steps_trained: 117000
    sample_time_ms: 1613.047
    update_time_ms: 3.7
  iterations_since_restore: 520
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.75
    ram_util_percent: 78.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.6284985695060366
    mean_inference_ms: 0.7454618461753424
    mean_processing_ms: 0.524680600692088
  time_since_restore: 865.5232510566711
  time_this_iter_s: 1.6011767387390137
  time_total_s: 865.5232510566711
  timestamp: 1744207091
  timesteps_since_restore: 117000
  timesteps_this_iter: 225
  timesteps_total: 117000
  training_iteration: 520
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    520 |          865.523 |      117000 | 0.202171 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-58-16
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.22470790446659167
  episode_reward_mean: 0.201025641355723
  episode_reward_min: 0.1791357782495067
  episodes_this_iter: 5
  episodes_total: 2615
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.802
    learner:
      default_policy:
        cur_kl_coeff: 3.544105547231835e-12
        cur_lr: 4.999999873689376e-05
        entropy: 15.05864429473877
        entropy_coeff: 0.0
        kl: 0.035996876657009125
        policy_loss: -0.0768098533153534
        total_loss: -0.07672576606273651
        vf_explained_var: 0.9736239314079285
        vf_loss: 8.409335714532062e-05
    load_time_ms: 0.975
    num_steps_sampled: 117675
    num_steps_trained: 117675
    sample_time_ms: 1653.763
    update_time_ms: 3.656
  iterations_since_restore: 523
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 41.699999999999996
    ram_util_percent: 78.7
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.629722172940958
    mean_inference_ms: 0.7458285902194223
    mean_processing_ms: 0.5248029762631904
  time_since_restore: 871.0310251712799
  time_this_iter_s: 2.1900720596313477
  time_total_s: 871.0310251712799
  timestamp: 1744207096
  timesteps_since_restore: 117675
  timesteps_this_iter: 225
  timesteps_total: 117675
  training_iteration: 523
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.2/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    523 |          871.031 |      117675 | 0.201026 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-58-21
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.21609670318120444
  episode_reward_mean: 0.19984394303156405
  episode_reward_min: 0.1791357782495067
  episodes_this_iter: 5
  episodes_total: 2630
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.597
    learner:
      default_policy:
        cur_kl_coeff: 3.544105547231835e-12
        cur_lr: 4.999999873689376e-05
        entropy: 15.000356674194336
        entropy_coeff: 0.0
        kl: 0.024535631760954857
        policy_loss: -0.05365724489092827
        total_loss: -0.053499143570661545
        vf_explained_var: 0.9528775215148926
        vf_loss: 0.00015809758042450994
    load_time_ms: 0.937
    num_steps_sampled: 118350
    num_steps_trained: 118350
    sample_time_ms: 1625.02
    update_time_ms: 3.692
  iterations_since_restore: 526
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.299999999999997
    ram_util_percent: 78.4
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.631233058693608
    mean_inference_ms: 0.7461976415680049
    mean_processing_ms: 0.5249356695686855
  time_since_restore: 876.0266599655151
  time_this_iter_s: 1.586038589477539
  time_total_s: 876.0266599655151
  timestamp: 1744207101
  timesteps_since_restore: 118350
  timesteps_this_iter: 225
  timesteps_total: 118350
  training_iteration: 526
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    526 |          876.027 |      118350 | 0.199844 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-58-28
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.21322413147212296
  episode_reward_mean: 0.1988996550334636
  episode_reward_min: 0.1791357782495067
  episodes_this_iter: 5
  episodes_total: 2650
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.048
    learner:
      default_policy:
        cur_kl_coeff: 7.974237589691846e-12
        cur_lr: 4.999999873689376e-05
        entropy: 15.329444885253906
        entropy_coeff: 0.0
        kl: 0.021033931523561478
        policy_loss: -0.05859934538602829
        total_loss: -0.05850347876548767
        vf_explained_var: 0.9715582132339478
        vf_loss: 9.586960368324071e-05
    load_time_ms: 0.903
    num_steps_sampled: 119250
    num_steps_trained: 119250
    sample_time_ms: 1590.395
    update_time_ms: 3.82
  iterations_since_restore: 530
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.6
    ram_util_percent: 78.1
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.632534431541687
    mean_inference_ms: 0.7465553112756419
    mean_processing_ms: 0.5251265106657541
  time_since_restore: 882.408714056015
  time_this_iter_s: 1.6674559116363525
  time_total_s: 882.408714056015
  timestamp: 1744207108
  timesteps_since_restore: 119250
  timesteps_this_iter: 225
  timesteps_total: 119250
  training_iteration: 530
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    530 |          882.409 |      119250 |   0.1989 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-58-34
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.21322413147212296
  episode_reward_mean: 0.19770057591575632
  episode_reward_min: 0.1791357782495067
  episodes_this_iter: 5
  episodes_total: 2670
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.613
    learner:
      default_policy:
        cur_kl_coeff: 7.974237589691846e-12
        cur_lr: 4.999999873689376e-05
        entropy: 15.041691780090332
        entropy_coeff: 0.0
        kl: 0.02952023409307003
        policy_loss: -0.0665355771780014
        total_loss: -0.06645609438419342
        vf_explained_var: 0.9758604168891907
        vf_loss: 7.947543053887784e-05
    load_time_ms: 0.9
    num_steps_sampled: 120150
    num_steps_trained: 120150
    sample_time_ms: 1462.826
    update_time_ms: 3.782
  iterations_since_restore: 534
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.45
    ram_util_percent: 78.15
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.632930030702646
    mean_inference_ms: 0.7467106632205067
    mean_processing_ms: 0.5252357336533745
  time_since_restore: 888.5551133155823
  time_this_iter_s: 1.616466999053955
  time_total_s: 888.5551133155823
  timestamp: 1744207114
  timesteps_since_restore: 120150
  timesteps_this_iter: 225
  timesteps_total: 120150
  training_iteration: 534
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    534 |          888.555 |      120150 | 0.197701 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-58-39
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.21322413147212296
  episode_reward_mean: 0.1973394726237439
  episode_reward_min: 0.17860668229203222
  episodes_this_iter: 5
  episodes_total: 2685
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 94.261
    learner:
      default_policy:
        cur_kl_coeff: 7.974237589691846e-12
        cur_lr: 4.999999873689376e-05
        entropy: 15.879669189453125
        entropy_coeff: 0.0
        kl: 0.022453222423791885
        policy_loss: -0.05702179670333862
        total_loss: -0.056929029524326324
        vf_explained_var: 0.9708881378173828
        vf_loss: 9.275850607082248e-05
    load_time_ms: 0.941
    num_steps_sampled: 120825
    num_steps_trained: 120825
    sample_time_ms: 1531.246
    update_time_ms: 3.879
  iterations_since_restore: 537
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.8
    ram_util_percent: 78.76666666666667
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.63315828543334
    mean_inference_ms: 0.7467753632926133
    mean_processing_ms: 0.525296855864715
  time_since_restore: 894.0734221935272
  time_this_iter_s: 1.763227939605713
  time_total_s: 894.0734221935272
  timestamp: 1744207119
  timesteps_since_restore: 120825
  timesteps_this_iter: 225
  timesteps_total: 120825
  training_iteration: 537
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    537 |          894.073 |      120825 | 0.197339 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-58-45
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.21322413147212296
  episode_reward_mean: 0.1963026893397749
  episode_reward_min: 0.16422058369600168
  episodes_this_iter: 5
  episodes_total: 2700
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 96.903
    learner:
      default_policy:
        cur_kl_coeff: 1.7942035010487523e-11
        cur_lr: 4.999999873689376e-05
        entropy: 14.461164474487305
        entropy_coeff: 0.0
        kl: 0.021112453192472458
        policy_loss: -0.0716860219836235
        total_loss: -0.07161197066307068
        vf_explained_var: 0.9767440557479858
        vf_loss: 7.406472286675125e-05
    load_time_ms: 1.069
    num_steps_sampled: 121500
    num_steps_trained: 121500
    sample_time_ms: 1600.446
    update_time_ms: 3.992
  iterations_since_restore: 540
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.099999999999998
    ram_util_percent: 78.7
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.633685170007706
    mean_inference_ms: 0.7468893394493028
    mean_processing_ms: 0.5254298172089459
  time_since_restore: 899.4685270786285
  time_this_iter_s: 1.9086084365844727
  time_total_s: 899.4685270786285
  timestamp: 1744207125
  timesteps_since_restore: 121500
  timesteps_this_iter: 225
  timesteps_total: 121500
  training_iteration: 540
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    540 |          899.469 |      121500 | 0.196303 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-58-50
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.2084596249627027
  episode_reward_mean: 0.19492200665427767
  episode_reward_min: 0.16422058369600168
  episodes_this_iter: 5
  episodes_total: 2715
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 111.61
    learner:
      default_policy:
        cur_kl_coeff: 2.6913051648369546e-11
        cur_lr: 4.999999873689376e-05
        entropy: 15.07105827331543
        entropy_coeff: 0.0
        kl: 0.04506296664476395
        policy_loss: -0.07552850991487503
        total_loss: -0.07545100152492523
        vf_explained_var: 0.9761555790901184
        vf_loss: 7.751576777081937e-05
    load_time_ms: 1.102
    num_steps_sampled: 122175
    num_steps_trained: 122175
    sample_time_ms: 1668.231
    update_time_ms: 5.057
  iterations_since_restore: 543
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.699999999999996
    ram_util_percent: 78.63333333333334
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.6341352051509865
    mean_inference_ms: 0.74702807079889
    mean_processing_ms: 0.5256041225994685
  time_since_restore: 904.8377180099487
  time_this_iter_s: 1.9590606689453125
  time_total_s: 904.8377180099487
  timestamp: 1744207130
  timesteps_since_restore: 122175
  timesteps_this_iter: 225
  timesteps_total: 122175
  training_iteration: 543
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    543 |          904.838 |      122175 | 0.194922 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-58-56
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.20799887972669945
  episode_reward_mean: 0.19330663976229687
  episode_reward_min: 0.16422058369600168
  episodes_this_iter: 5
  episodes_total: 2730
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 113.753
    learner:
      default_policy:
        cur_kl_coeff: 6.055436707619322e-11
        cur_lr: 4.999999873689376e-05
        entropy: 15.127349853515625
        entropy_coeff: 0.0
        kl: 0.017144229263067245
        policy_loss: -0.051475606858730316
        total_loss: -0.05138733983039856
        vf_explained_var: 0.9711105227470398
        vf_loss: 8.827251440379769e-05
    load_time_ms: 1.118
    num_steps_sampled: 122850
    num_steps_trained: 122850
    sample_time_ms: 1690.928
    update_time_ms: 5.101
  iterations_since_restore: 546
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.25
    ram_util_percent: 79.15
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.634620435477168
    mean_inference_ms: 0.7471820765587703
    mean_processing_ms: 0.5257854027135629
  time_since_restore: 910.4587802886963
  time_this_iter_s: 1.8745436668395996
  time_total_s: 910.4587802886963
  timestamp: 1744207136
  timesteps_since_restore: 122850
  timesteps_this_iter: 225
  timesteps_total: 122850
  training_iteration: 546
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.2/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    546 |          910.459 |      122850 | 0.193307 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-59-01
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.2073514230380226
  episode_reward_mean: 0.19188567180845356
  episode_reward_min: 0.16422058369600168
  episodes_this_iter: 5
  episodes_total: 2745
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 115.24
    learner:
      default_policy:
        cur_kl_coeff: 6.055436707619322e-11
        cur_lr: 4.999999873689376e-05
        entropy: 15.584518432617188
        entropy_coeff: 0.0
        kl: 0.019879285246133804
        policy_loss: -0.05748165771365166
        total_loss: -0.05734232813119888
        vf_explained_var: 0.9547508358955383
        vf_loss: 0.00013932572619523853
    load_time_ms: 1.048
    num_steps_sampled: 123525
    num_steps_trained: 123525
    sample_time_ms: 1714.639
    update_time_ms: 5.202
  iterations_since_restore: 549
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.9
    ram_util_percent: 78.95
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.636042847502849
    mean_inference_ms: 0.7474865226102761
    mean_processing_ms: 0.5260680474976092
  time_since_restore: 915.9623250961304
  time_this_iter_s: 1.6296768188476562
  time_total_s: 915.9623250961304
  timestamp: 1744207141
  timesteps_since_restore: 123525
  timesteps_this_iter: 225
  timesteps_total: 123525
  training_iteration: 549
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    549 |          915.962 |      123525 | 0.191886 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-59-07
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.2073514230380226
  episode_reward_mean: 0.19091733239484943
  episode_reward_min: 0.16422058369600168
  episodes_this_iter: 5
  episodes_total: 2760
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 102.672
    learner:
      default_policy:
        cur_kl_coeff: 9.083155061428982e-11
        cur_lr: 4.999999873689376e-05
        entropy: 15.501919746398926
        entropy_coeff: 0.0
        kl: 0.026741083711385727
        policy_loss: -0.05586918443441391
        total_loss: -0.0557825081050396
        vf_explained_var: 0.9717634320259094
        vf_loss: 8.666075154906139e-05
    load_time_ms: 1.024
    num_steps_sampled: 124200
    num_steps_trained: 124200
    sample_time_ms: 1713.647
    update_time_ms: 5.017
  iterations_since_restore: 552
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.633333333333333
    ram_util_percent: 79.13333333333334
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.637958611377289
    mean_inference_ms: 0.7478778971533874
    mean_processing_ms: 0.5263675701256575
  time_since_restore: 921.139524936676
  time_this_iter_s: 1.5572175979614258
  time_total_s: 921.139524936676
  timestamp: 1744207147
  timesteps_since_restore: 124200
  timesteps_this_iter: 225
  timesteps_total: 124200
  training_iteration: 552
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.2/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    552 |           921.14 |      124200 | 0.190917 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-59-12
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.2073514230380226
  episode_reward_mean: 0.1890432778064431
  episode_reward_min: 0.16422058369600168
  episodes_this_iter: 5
  episodes_total: 2775
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 96.64
    learner:
      default_policy:
        cur_kl_coeff: 1.3624731898254083e-10
        cur_lr: 4.999999873689376e-05
        entropy: 14.819664001464844
        entropy_coeff: 0.0
        kl: 0.032185330986976624
        policy_loss: -0.08914735913276672
        total_loss: -0.08908817917108536
        vf_explained_var: 0.9793812036514282
        vf_loss: 5.916643931414001e-05
    load_time_ms: 0.92
    num_steps_sampled: 124875
    num_steps_trained: 124875
    sample_time_ms: 1687.543
    update_time_ms: 3.969
  iterations_since_restore: 555
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.85
    ram_util_percent: 78.85
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.640336224443529
    mean_inference_ms: 0.7483378543370922
    mean_processing_ms: 0.5267067470973366
  time_since_restore: 926.5102758407593
  time_this_iter_s: 1.747138500213623
  time_total_s: 926.5102758407593
  timestamp: 1744207152
  timesteps_since_restore: 124875
  timesteps_this_iter: 225
  timesteps_total: 124875
  training_iteration: 555
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    555 |           926.51 |      124875 | 0.189043 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-59-19
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.2073514230380226
  episode_reward_mean: 0.18804080986106167
  episode_reward_min: 0.1661204598626409
  episodes_this_iter: 5
  episodes_total: 2795
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.923
    learner:
      default_policy:
        cur_kl_coeff: 2.0437097847381125e-10
        cur_lr: 4.999999873689376e-05
        entropy: 14.86524486541748
        entropy_coeff: 0.0
        kl: 0.019862741231918335
        policy_loss: -0.06814855337142944
        total_loss: -0.06807149946689606
        vf_explained_var: 0.9731651544570923
        vf_loss: 7.705160533078015e-05
    load_time_ms: 0.943
    num_steps_sampled: 125775
    num_steps_trained: 125775
    sample_time_ms: 1607.654
    update_time_ms: 3.629
  iterations_since_restore: 559
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.53333333333333
    ram_util_percent: 78.5
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.642914462437486
    mean_inference_ms: 0.7488457710798184
    mean_processing_ms: 0.527075199110435
  time_since_restore: 933.017028093338
  time_this_iter_s: 1.6217546463012695
  time_total_s: 933.017028093338
  timestamp: 1744207159
  timesteps_since_restore: 125775
  timesteps_this_iter: 225
  timesteps_total: 125775
  training_iteration: 559
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    559 |          933.017 |      125775 | 0.188041 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-59-24
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.2031069377979507
  episode_reward_mean: 0.18706400059823744
  episode_reward_min: 0.1661204598626409
  episodes_this_iter: 5
  episodes_total: 2810
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 92.23
    learner:
      default_policy:
        cur_kl_coeff: 2.0437097847381125e-10
        cur_lr: 4.999999873689376e-05
        entropy: 14.304136276245117
        entropy_coeff: 0.0
        kl: 0.02800549566745758
        policy_loss: -0.06272481381893158
        total_loss: -0.06262031197547913
        vf_explained_var: 0.9646746516227722
        vf_loss: 0.00010450993431732059
    load_time_ms: 0.942
    num_steps_sampled: 126450
    num_steps_trained: 126450
    sample_time_ms: 1646.583
    update_time_ms: 3.633
  iterations_since_restore: 562
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.73333333333333
    ram_util_percent: 78.73333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.6447869757709785
    mean_inference_ms: 0.7491977088706446
    mean_processing_ms: 0.5273096661257967
  time_since_restore: 938.6074879169464
  time_this_iter_s: 2.132768392562866
  time_total_s: 938.6074879169464
  timestamp: 1744207164
  timesteps_since_restore: 126450
  timesteps_this_iter: 225
  timesteps_total: 126450
  training_iteration: 562
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    562 |          938.607 |      126450 | 0.187064 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-59-30
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.20534471936131407
  episode_reward_mean: 0.1864342531397722
  episode_reward_min: 0.1661204598626409
  episodes_this_iter: 5
  episodes_total: 2825
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 94.006
    learner:
      default_policy:
        cur_kl_coeff: 4.5983472585220397e-10
        cur_lr: 4.999999873689376e-05
        entropy: 15.123641967773438
        entropy_coeff: 0.0
        kl: 0.02777700498700142
        policy_loss: -0.0743715763092041
        total_loss: -0.07430180162191391
        vf_explained_var: 0.9763391613960266
        vf_loss: 6.977705925237387e-05
    load_time_ms: 0.957
    num_steps_sampled: 127125
    num_steps_trained: 127125
    sample_time_ms: 1647.132
    update_time_ms: 4.376
  iterations_since_restore: 565
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.5
    ram_util_percent: 78.75
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.646808375568137
    mean_inference_ms: 0.7495496822871982
    mean_processing_ms: 0.5275254060017437
  time_since_restore: 944.0092239379883
  time_this_iter_s: 1.8847718238830566
  time_total_s: 944.0092239379883
  timestamp: 1744207170
  timesteps_since_restore: 127125
  timesteps_this_iter: 225
  timesteps_total: 127125
  training_iteration: 565
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    565 |          944.009 |      127125 | 0.186434 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-59-35
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.20534471936131407
  episode_reward_mean: 0.18512846829964194
  episode_reward_min: 0.1661204598626409
  episodes_this_iter: 5
  episodes_total: 2840
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 99.893
    learner:
      default_policy:
        cur_kl_coeff: 4.5983472585220397e-10
        cur_lr: 4.999999873689376e-05
        entropy: 14.772216796875
        entropy_coeff: 0.0
        kl: 0.03177634999155998
        policy_loss: -0.061015285551548004
        total_loss: -0.06095608323812485
        vf_explained_var: 0.9792758226394653
        vf_loss: 5.920171315665357e-05
    load_time_ms: 1.091
    num_steps_sampled: 127800
    num_steps_trained: 127800
    sample_time_ms: 1678.877
    update_time_ms: 4.503
  iterations_since_restore: 568
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.5
    ram_util_percent: 78.7
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.648336216397513
    mean_inference_ms: 0.749845460142192
    mean_processing_ms: 0.5277159723243906
  time_since_restore: 949.2733125686646
  time_this_iter_s: 1.79671049118042
  time_total_s: 949.2733125686646
  timestamp: 1744207175
  timesteps_since_restore: 127800
  timesteps_this_iter: 225
  timesteps_total: 127800
  training_iteration: 568
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    568 |          949.273 |      127800 | 0.185128 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-59-41
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.20534471936131407
  episode_reward_mean: 0.1841130937091005
  episode_reward_min: 0.16168592756649686
  episodes_this_iter: 5
  episodes_total: 2855
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 103.467
    learner:
      default_policy:
        cur_kl_coeff: 6.89752088778306e-10
        cur_lr: 4.999999873689376e-05
        entropy: 15.063562393188477
        entropy_coeff: 0.0
        kl: 0.02463473007082939
        policy_loss: -0.05298713594675064
        total_loss: -0.05291286110877991
        vf_explained_var: 0.9759432673454285
        vf_loss: 7.427904347423464e-05
    load_time_ms: 1.107
    num_steps_sampled: 128475
    num_steps_trained: 128475
    sample_time_ms: 1728.905
    update_time_ms: 4.539
  iterations_since_restore: 571
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.5
    ram_util_percent: 78.65
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.650015181368158
    mean_inference_ms: 0.7501901638809312
    mean_processing_ms: 0.52798149104141
  time_since_restore: 954.8899614810944
  time_this_iter_s: 1.6738402843475342
  time_total_s: 954.8899614810944
  timestamp: 1744207181
  timesteps_since_restore: 128475
  timesteps_this_iter: 225
  timesteps_total: 128475
  training_iteration: 571
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    571 |           954.89 |      128475 | 0.184113 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-59-46
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.20534471936131407
  episode_reward_mean: 0.18430874953591306
  episode_reward_min: 0.16168592756649686
  episodes_this_iter: 5
  episodes_total: 2870
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 104.782
    learner:
      default_policy:
        cur_kl_coeff: 6.89752088778306e-10
        cur_lr: 4.999999873689376e-05
        entropy: 15.33184814453125
        entropy_coeff: 0.0
        kl: 0.03648003190755844
        policy_loss: -0.0860990360379219
        total_loss: -0.08604593575000763
        vf_explained_var: 0.9816776514053345
        vf_loss: 5.309345942805521e-05
    load_time_ms: 1.117
    num_steps_sampled: 129150
    num_steps_trained: 129150
    sample_time_ms: 1669.673
    update_time_ms: 3.698
  iterations_since_restore: 574
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.799999999999997
    ram_util_percent: 78.6
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.651599485905598
    mean_inference_ms: 0.750549730926103
    mean_processing_ms: 0.5282390309405686
  time_since_restore: 959.951771736145
  time_this_iter_s: 1.6951136589050293
  time_total_s: 959.951771736145
  timestamp: 1744207186
  timesteps_since_restore: 129150
  timesteps_this_iter: 225
  timesteps_total: 129150
  training_iteration: 574
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    574 |          959.952 |      129150 | 0.184309 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-59-51
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.20534471936131407
  episode_reward_mean: 0.18354948613226038
  episode_reward_min: 0.16168592756649686
  episodes_this_iter: 5
  episodes_total: 2885
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 104.74
    learner:
      default_policy:
        cur_kl_coeff: 6.89752088778306e-10
        cur_lr: 4.999999873689376e-05
        entropy: 14.374231338500977
        entropy_coeff: 0.0
        kl: 0.021197419613599777
        policy_loss: -0.06996046006679535
        total_loss: -0.06991413235664368
        vf_explained_var: 0.9838634729385376
        vf_loss: 4.6328197640832514e-05
    load_time_ms: 1.048
    num_steps_sampled: 129825
    num_steps_trained: 129825
    sample_time_ms: 1642.786
    update_time_ms: 3.811
  iterations_since_restore: 577
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.866666666666664
    ram_util_percent: 78.66666666666667
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.653069443797062
    mean_inference_ms: 0.7509316202826756
    mean_processing_ms: 0.5284812779139412
  time_since_restore: 965.0352227687836
  time_this_iter_s: 1.660083293914795
  time_total_s: 965.0352227687836
  timestamp: 1744207191
  timesteps_since_restore: 129825
  timesteps_this_iter: 225
  timesteps_total: 129825
  training_iteration: 577
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    577 |          965.035 |      129825 | 0.183549 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_09-59-57
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.20534471936131407
  episode_reward_mean: 0.1825946887991321
  episode_reward_min: 0.16168592756649686
  episodes_this_iter: 5
  episodes_total: 2900
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 101.132
    learner:
      default_policy:
        cur_kl_coeff: 1.034628049900732e-09
        cur_lr: 4.999999873689376e-05
        entropy: 14.791067123413086
        entropy_coeff: 0.0
        kl: 0.05894362926483154
        policy_loss: -0.07296861708164215
        total_loss: -0.07291895151138306
        vf_explained_var: 0.9821692705154419
        vf_loss: 4.966302731190808e-05
    load_time_ms: 0.994
    num_steps_sampled: 130500
    num_steps_trained: 130500
    sample_time_ms: 1713.941
    update_time_ms: 3.828
  iterations_since_restore: 580
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 41.150000000000006
    ram_util_percent: 78.8
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.655220166996551
    mean_inference_ms: 0.7514277142598061
    mean_processing_ms: 0.528785223392908
  time_since_restore: 971.4509563446045
  time_this_iter_s: 2.479357957839966
  time_total_s: 971.4509563446045
  timestamp: 1744207197
  timesteps_since_restore: 130500
  timesteps_this_iter: 225
  timesteps_total: 130500
  training_iteration: 580
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    580 |          971.451 |      130500 | 0.182595 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-00-03
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.19828718333069642
  episode_reward_mean: 0.18219934779786529
  episode_reward_min: 0.16168592756649686
  episodes_this_iter: 5
  episodes_total: 2915
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 96.726
    learner:
      default_policy:
        cur_kl_coeff: 2.327913195543374e-09
        cur_lr: 4.999999873689376e-05
        entropy: 14.265151977539062
        entropy_coeff: 0.0
        kl: 0.03245268762111664
        policy_loss: -0.0874188169836998
        total_loss: -0.087368443608284
        vf_explained_var: 0.9816219210624695
        vf_loss: 5.03771188959945e-05
    load_time_ms: 0.967
    num_steps_sampled: 131175
    num_steps_trained: 131175
    sample_time_ms: 1749.582
    update_time_ms: 3.959
  iterations_since_restore: 583
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.65
    ram_util_percent: 78.4
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.657857423172902
    mean_inference_ms: 0.7520092795042413
    mean_processing_ms: 0.5291350526272369
  time_since_restore: 976.8046553134918
  time_this_iter_s: 1.7094902992248535
  time_total_s: 976.8046553134918
  timestamp: 1744207203
  timesteps_since_restore: 131175
  timesteps_this_iter: 225
  timesteps_total: 131175
  training_iteration: 583
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    583 |          976.805 |      131175 | 0.182199 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-00-08
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.19828718333069642
  episode_reward_mean: 0.1816226020484688
  episode_reward_min: 0.16168592756649686
  episodes_this_iter: 5
  episodes_total: 2930
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 95.748
    learner:
      default_policy:
        cur_kl_coeff: 2.327913195543374e-09
        cur_lr: 4.999999873689376e-05
        entropy: 13.70991039276123
        entropy_coeff: 0.0
        kl: 0.04238683730363846
        policy_loss: -0.06407923996448517
        total_loss: -0.06402410566806793
        vf_explained_var: 0.9810999035835266
        vf_loss: 5.514746226253919e-05
    load_time_ms: 1.022
    num_steps_sampled: 131850
    num_steps_trained: 131850
    sample_time_ms: 1775.861
    update_time_ms: 3.906
  iterations_since_restore: 586
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.25
    ram_util_percent: 78.4
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.66029988339199
    mean_inference_ms: 0.7525456055266835
    mean_processing_ms: 0.5294827458962469
  time_since_restore: 982.1760723590851
  time_this_iter_s: 1.8398852348327637
  time_total_s: 982.1760723590851
  timestamp: 1744207208
  timesteps_since_restore: 131850
  timesteps_this_iter: 225
  timesteps_total: 131850
  training_iteration: 586
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    586 |          982.176 |      131850 | 0.181623 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-00-13
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.19828718333069642
  episode_reward_mean: 0.1796766667784208
  episode_reward_min: 0.16000664778391285
  episodes_this_iter: 5
  episodes_total: 2945
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.83
    learner:
      default_policy:
        cur_kl_coeff: 3.4918699043373636e-09
        cur_lr: 4.999999873689376e-05
        entropy: 13.607309341430664
        entropy_coeff: 0.0
        kl: 0.03751248121261597
        policy_loss: -0.07969050109386444
        total_loss: -0.07964365184307098
        vf_explained_var: 0.9820579290390015
        vf_loss: 4.684580198954791e-05
    load_time_ms: 0.937
    num_steps_sampled: 132525
    num_steps_trained: 132525
    sample_time_ms: 1722.324
    update_time_ms: 3.989
  iterations_since_restore: 589
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.049999999999997
    ram_util_percent: 78.0
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.66272770054404
    mean_inference_ms: 0.7530458876250262
    mean_processing_ms: 0.5297726377224197
  time_since_restore: 987.195564031601
  time_this_iter_s: 1.4668934345245361
  time_total_s: 987.195564031601
  timestamp: 1744207213
  timesteps_since_restore: 132525
  timesteps_this_iter: 225
  timesteps_total: 132525
  training_iteration: 589
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    589 |          987.196 |      132525 | 0.179677 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-00-19
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.1936262747312042
  episode_reward_mean: 0.17701732801712575
  episode_reward_min: 0.1578048700490238
  episodes_this_iter: 5
  episodes_total: 2965
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.182
    learner:
      default_policy:
        cur_kl_coeff: 7.856707284759068e-09
        cur_lr: 4.999999873689376e-05
        entropy: 14.604562759399414
        entropy_coeff: 0.0
        kl: 0.044509001076221466
        policy_loss: -0.07938577234745026
        total_loss: -0.07932327687740326
        vf_explained_var: 0.9750644564628601
        vf_loss: 6.250369915505871e-05
    load_time_ms: 0.943
    num_steps_sampled: 133425
    num_steps_trained: 133425
    sample_time_ms: 1570.536
    update_time_ms: 3.921
  iterations_since_restore: 593
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.55
    ram_util_percent: 77.75
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.665140842921
    mean_inference_ms: 0.7535575848415852
    mean_processing_ms: 0.5300410497655555
  time_since_restore: 993.5031006336212
  time_this_iter_s: 1.5727434158325195
  time_total_s: 993.5031006336212
  timestamp: 1744207219
  timesteps_since_restore: 133425
  timesteps_this_iter: 225
  timesteps_total: 133425
  training_iteration: 593
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    593 |          993.503 |      133425 | 0.177017 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-00-26
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.1936262747312042
  episode_reward_mean: 0.17520021028868538
  episode_reward_min: 0.1578048700490238
  episodes_this_iter: 5
  episodes_total: 2985
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.889
    learner:
      default_policy:
        cur_kl_coeff: 1.1785060927138602e-08
        cur_lr: 4.999999873689376e-05
        entropy: 14.396267890930176
        entropy_coeff: 0.0
        kl: 0.02509589120745659
        policy_loss: -0.06756545603275299
        total_loss: -0.067488893866539
        vf_explained_var: 0.9689361453056335
        vf_loss: 7.655766239622608e-05
    load_time_ms: 0.977
    num_steps_sampled: 134325
    num_steps_trained: 134325
    sample_time_ms: 1495.452
    update_time_ms: 3.816
  iterations_since_restore: 597
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.46666666666667
    ram_util_percent: 77.8
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.667032366078292
    mean_inference_ms: 0.7538933522425111
    mean_processing_ms: 0.5302849169830346
  time_since_restore: 999.9302709102631
  time_this_iter_s: 1.6636743545532227
  time_total_s: 999.9302709102631
  timestamp: 1744207226
  timesteps_since_restore: 134325
  timesteps_this_iter: 225
  timesteps_total: 134325
  training_iteration: 597
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    597 |           999.93 |      134325 |   0.1752 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-00-32
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.18919711281182353
  episode_reward_mean: 0.17342317312291058
  episode_reward_min: 0.1578048700490238
  episodes_this_iter: 5
  episodes_total: 3005
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 88.718
    learner:
      default_policy:
        cur_kl_coeff: 1.1785060927138602e-08
        cur_lr: 4.999999873689376e-05
        entropy: 13.724912643432617
        entropy_coeff: 0.0
        kl: 0.05636148527264595
        policy_loss: -0.09263040870428085
        total_loss: -0.09258469194173813
        vf_explained_var: 0.9818111658096313
        vf_loss: 4.5720946218352765e-05
    load_time_ms: 0.96
    num_steps_sampled: 135225
    num_steps_trained: 135225
    sample_time_ms: 1431.779
    update_time_ms: 3.775
  iterations_since_restore: 601
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.6
    ram_util_percent: 77.75
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.667059647450692
    mean_inference_ms: 0.7538715071482597
    mean_processing_ms: 0.5303544278094858
  time_since_restore: 1005.7792367935181
  time_this_iter_s: 1.4923560619354248
  time_total_s: 1005.7792367935181
  timestamp: 1744207232
  timesteps_since_restore: 135225
  timesteps_this_iter: 225
  timesteps_total: 135225
  training_iteration: 601
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    601 |          1005.78 |      135225 | 0.173423 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-00-37
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.18364134487387018
  episode_reward_mean: 0.1717385650695806
  episode_reward_min: 0.1578048700490238
  episodes_this_iter: 5
  episodes_total: 3020
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.251
    learner:
      default_policy:
        cur_kl_coeff: 2.651638730810646e-08
        cur_lr: 4.999999873689376e-05
        entropy: 13.78955078125
        entropy_coeff: 0.0
        kl: 0.02935294434428215
        policy_loss: -0.06220127269625664
        total_loss: -0.06216127797961235
        vf_explained_var: 0.984759509563446
        vf_loss: 4.000118497060612e-05
    load_time_ms: 0.937
    num_steps_sampled: 135900
    num_steps_trained: 135900
    sample_time_ms: 1496.012
    update_time_ms: 4.296
  iterations_since_restore: 604
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.53333333333333
    ram_util_percent: 78.5
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.666196887899838
    mean_inference_ms: 0.7537014709038681
    mean_processing_ms: 0.5303226073671723
  time_since_restore: 1011.0540225505829
  time_this_iter_s: 1.9050242900848389
  time_total_s: 1011.0540225505829
  timestamp: 1744207237
  timesteps_since_restore: 135900
  timesteps_this_iter: 225
  timesteps_total: 135900
  training_iteration: 604
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    604 |          1011.05 |      135900 | 0.171739 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-00-43
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.1820665819217733
  episode_reward_mean: 0.17069497724087415
  episode_reward_min: 0.1578048700490238
  episodes_this_iter: 5
  episodes_total: 3035
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.209
    learner:
      default_policy:
        cur_kl_coeff: 2.651638730810646e-08
        cur_lr: 4.999999873689376e-05
        entropy: 13.888198852539062
        entropy_coeff: 0.0
        kl: 0.050805915147066116
        policy_loss: -0.08722758293151855
        total_loss: -0.08717282861471176
        vf_explained_var: 0.9774651527404785
        vf_loss: 5.475921352626756e-05
    load_time_ms: 0.91
    num_steps_sampled: 136575
    num_steps_trained: 136575
    sample_time_ms: 1561.857
    update_time_ms: 4.243
  iterations_since_restore: 607
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.450000000000003
    ram_util_percent: 78.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.665566979530517
    mean_inference_ms: 0.7536102267553977
    mean_processing_ms: 0.5303400081868319
  time_since_restore: 1016.5351362228394
  time_this_iter_s: 1.7101986408233643
  time_total_s: 1016.5351362228394
  timestamp: 1744207243
  timesteps_since_restore: 136575
  timesteps_this_iter: 225
  timesteps_total: 136575
  training_iteration: 607
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    607 |          1016.54 |      136575 | 0.170695 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-00-49
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.1820665819217733
  episode_reward_mean: 0.16987251069356613
  episode_reward_min: 0.15397782013798345
  episodes_this_iter: 5
  episodes_total: 3055
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.492
    learner:
      default_policy:
        cur_kl_coeff: 8.949280783099312e-08
        cur_lr: 4.999999873689376e-05
        entropy: 13.623971939086914
        entropy_coeff: 0.0
        kl: 0.03738981857895851
        policy_loss: -0.0686642974615097
        total_loss: -0.06862802803516388
        vf_explained_var: 0.9847960472106934
        vf_loss: 3.6267661926103756e-05
    load_time_ms: 0.921
    num_steps_sampled: 137475
    num_steps_trained: 137475
    sample_time_ms: 1629.49
    update_time_ms: 4.232
  iterations_since_restore: 611
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.950000000000003
    ram_util_percent: 77.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.6645118698477175
    mean_inference_ms: 0.7534809205107283
    mean_processing_ms: 0.5303419679304
  time_since_restore: 1023.0743539333344
  time_this_iter_s: 1.5824010372161865
  time_total_s: 1023.0743539333344
  timestamp: 1744207249
  timesteps_since_restore: 137475
  timesteps_this_iter: 225
  timesteps_total: 137475
  training_iteration: 611
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    611 |          1023.07 |      137475 | 0.169873 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-00-55
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.1820665819217733
  episode_reward_mean: 0.16840895207696552
  episode_reward_min: 0.1505464298801959
  episodes_this_iter: 5
  episodes_total: 3070
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 100.937
    learner:
      default_policy:
        cur_kl_coeff: 1.3423920108834864e-07
        cur_lr: 4.999999873689376e-05
        entropy: 13.523101806640625
        entropy_coeff: 0.0
        kl: 0.10042685270309448
        policy_loss: -0.09968816488981247
        total_loss: -0.09961028397083282
        vf_explained_var: 0.964943528175354
        vf_loss: 7.787512004142627e-05
    load_time_ms: 0.96
    num_steps_sampled: 138150
    num_steps_trained: 138150
    sample_time_ms: 1661.515
    update_time_ms: 3.712
  iterations_since_restore: 614
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 41.56666666666666
    ram_util_percent: 78.23333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.664236298211943
    mean_inference_ms: 0.7534620798670953
    mean_processing_ms: 0.5303916616218884
  time_since_restore: 1028.761215209961
  time_this_iter_s: 2.3381519317626953
  time_total_s: 1028.761215209961
  timestamp: 1744207255
  timesteps_since_restore: 138150
  timesteps_this_iter: 225
  timesteps_total: 138150
  training_iteration: 614
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    614 |          1028.76 |      138150 | 0.168409 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-01-00
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.18021325974271848
  episode_reward_mean: 0.1654815064954342
  episode_reward_min: 0.1426083696294163
  episodes_this_iter: 5
  episodes_total: 3085
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 99.453
    learner:
      default_policy:
        cur_kl_coeff: 2.0135881584337767e-07
        cur_lr: 4.999999873689376e-05
        entropy: 13.297686576843262
        entropy_coeff: 0.0
        kl: 0.026558484882116318
        policy_loss: -0.0574977807700634
        total_loss: -0.05744589492678642
        vf_explained_var: 0.9746400713920593
        vf_loss: 5.189657167647965e-05
    load_time_ms: 0.933
    num_steps_sampled: 138825
    num_steps_trained: 138825
    sample_time_ms: 1639.503
    update_time_ms: 4.08
  iterations_since_restore: 617
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.5
    ram_util_percent: 78.25
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.6647776383
    mean_inference_ms: 0.7535961032501524
    mean_processing_ms: 0.5305069406059197
  time_since_restore: 1034.009917974472
  time_this_iter_s: 1.5363667011260986
  time_total_s: 1034.009917974472
  timestamp: 1744207260
  timesteps_since_restore: 138825
  timesteps_this_iter: 225
  timesteps_total: 138825
  training_iteration: 617
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    617 |          1034.01 |      138825 | 0.165482 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-01-07
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.18021325974271848
  episode_reward_mean: 0.1625168145317172
  episode_reward_min: 0.1426083696294163
  episodes_this_iter: 5
  episodes_total: 3105
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 98.614
    learner:
      default_policy:
        cur_kl_coeff: 3.0203821665963915e-07
        cur_lr: 4.999999873689376e-05
        entropy: 13.337387084960938
        entropy_coeff: 0.0
        kl: 0.034427884966135025
        policy_loss: -0.07527129352092743
        total_loss: -0.07522472739219666
        vf_explained_var: 0.9778748750686646
        vf_loss: 4.65627817902714e-05
    load_time_ms: 0.902
    num_steps_sampled: 139725
    num_steps_trained: 139725
    sample_time_ms: 1638.199
    update_time_ms: 4.144
  iterations_since_restore: 621
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.166666666666668
    ram_util_percent: 78.33333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.6658044515084995
    mean_inference_ms: 0.7538517871035996
    mean_processing_ms: 0.5306784110020343
  time_since_restore: 1040.5279638767242
  time_this_iter_s: 1.781834363937378
  time_total_s: 1040.5279638767242
  timestamp: 1744207267
  timesteps_since_restore: 139725
  timesteps_this_iter: 225
  timesteps_total: 139725
  training_iteration: 621
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    621 |          1040.53 |      139725 | 0.162517 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-01-13
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.18021325974271848
  episode_reward_mean: 0.1605721909235074
  episode_reward_min: 0.1426083696294163
  episodes_this_iter: 5
  episodes_total: 3120
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.581
    learner:
      default_policy:
        cur_kl_coeff: 3.0203821665963915e-07
        cur_lr: 4.999999873689376e-05
        entropy: 13.497116088867188
        entropy_coeff: 0.0
        kl: 0.025220375508069992
        policy_loss: -0.07700271904468536
        total_loss: -0.07695381343364716
        vf_explained_var: 0.9758681058883667
        vf_loss: 4.8908143071457744e-05
    load_time_ms: 0.868
    num_steps_sampled: 140400
    num_steps_trained: 140400
    sample_time_ms: 1688.181
    update_time_ms: 4.175
  iterations_since_restore: 624
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 40.325
    ram_util_percent: 79.175
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.6672448716708095
    mean_inference_ms: 0.7541505869553446
    mean_processing_ms: 0.530870043127602
  time_since_restore: 1046.6223092079163
  time_this_iter_s: 2.2142112255096436
  time_total_s: 1046.6223092079163
  timestamp: 1744207273
  timesteps_since_restore: 140400
  timesteps_this_iter: 225
  timesteps_total: 140400
  training_iteration: 624
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.2/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    624 |          1046.62 |      140400 | 0.160572 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-01-18
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.17674647476919245
  episode_reward_mean: 0.15794306287114263
  episode_reward_min: 0.1394575794928584
  episodes_this_iter: 5
  episodes_total: 3135
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 93.295
    learner:
      default_policy:
        cur_kl_coeff: 3.0203821665963915e-07
        cur_lr: 4.999999873689376e-05
        entropy: 12.585688591003418
        entropy_coeff: 0.0
        kl: 0.04315471649169922
        policy_loss: -0.05754394456744194
        total_loss: -0.05748545005917549
        vf_explained_var: 0.9692128300666809
        vf_loss: 5.8485788031248376e-05
    load_time_ms: 0.94
    num_steps_sampled: 141075
    num_steps_trained: 141075
    sample_time_ms: 1709.887
    update_time_ms: 3.742
  iterations_since_restore: 627
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.349999999999998
    ram_util_percent: 79.1
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.668840631066832
    mean_inference_ms: 0.7544290663780626
    mean_processing_ms: 0.5310305438439673
  time_since_restore: 1052.121285200119
  time_this_iter_s: 1.757174015045166
  time_total_s: 1052.121285200119
  timestamp: 1744207278
  timesteps_since_restore: 141075
  timesteps_this_iter: 225
  timesteps_total: 141075
  training_iteration: 627
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    627 |          1052.12 |      141075 | 0.157943 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-01-24
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.16867739960151562
  episode_reward_mean: 0.15537869672596866
  episode_reward_min: 0.13616006716758208
  episodes_this_iter: 5
  episodes_total: 3150
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 96.218
    learner:
      default_policy:
        cur_kl_coeff: 4.5305733920031344e-07
        cur_lr: 4.999999873689376e-05
        entropy: 12.1469087600708
        entropy_coeff: 0.0
        kl: 0.03400823473930359
        policy_loss: -0.0768543928861618
        total_loss: -0.07678668200969696
        vf_explained_var: 0.9657049179077148
        vf_loss: 6.770714389858767e-05
    load_time_ms: 0.961
    num_steps_sampled: 141750
    num_steps_trained: 141750
    sample_time_ms: 1800.427
    update_time_ms: 3.839
  iterations_since_restore: 630
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.8
    ram_util_percent: 78.8
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.671040927851587
    mean_inference_ms: 0.7547839922847973
    mean_processing_ms: 0.5312371203547674
  time_since_restore: 1057.794507265091
  time_this_iter_s: 1.9337472915649414
  time_total_s: 1057.794507265091
  timestamp: 1744207284
  timesteps_since_restore: 141750
  timesteps_this_iter: 225
  timesteps_total: 141750
  training_iteration: 630
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    630 |          1057.79 |      141750 | 0.155379 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-01-30
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.16654782285328357
  episode_reward_mean: 0.15407782621170982
  episode_reward_min: 0.13616006716758208
  episodes_this_iter: 5
  episodes_total: 3170
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 94.111
    learner:
      default_policy:
        cur_kl_coeff: 4.5305733920031344e-07
        cur_lr: 4.999999873689376e-05
        entropy: 12.176324844360352
        entropy_coeff: 0.0
        kl: 0.027625977993011475
        policy_loss: -0.06025470420718193
        total_loss: -0.06020922213792801
        vf_explained_var: 0.9776542782783508
        vf_loss: 4.5484426664188504e-05
    load_time_ms: 0.979
    num_steps_sampled: 142650
    num_steps_trained: 142650
    sample_time_ms: 1651.451
    update_time_ms: 3.919
  iterations_since_restore: 634
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.35
    ram_util_percent: 78.65
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.673961162097168
    mean_inference_ms: 0.7552645573768146
    mean_processing_ms: 0.5315013076082394
  time_since_restore: 1064.1605155467987
  time_this_iter_s: 1.518523931503296
  time_total_s: 1064.1605155467987
  timestamp: 1744207290
  timesteps_since_restore: 142650
  timesteps_this_iter: 225
  timesteps_total: 142650
  training_iteration: 634
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    634 |          1064.16 |      142650 | 0.154078 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-01-36
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.16654782285328357
  episode_reward_mean: 0.15383875409862072
  episode_reward_min: 0.13616006716758208
  episodes_this_iter: 5
  episodes_total: 3190
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 88.485
    learner:
      default_policy:
        cur_kl_coeff: 4.5305733920031344e-07
        cur_lr: 4.999999873689376e-05
        entropy: 12.510659217834473
        entropy_coeff: 0.0
        kl: 0.03812670335173607
        policy_loss: -0.08219422399997711
        total_loss: -0.08213673532009125
        vf_explained_var: 0.9686816930770874
        vf_loss: 5.747506656916812e-05
    load_time_ms: 0.966
    num_steps_sampled: 143550
    num_steps_trained: 143550
    sample_time_ms: 1503.503
    update_time_ms: 3.768
  iterations_since_restore: 638
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.5
    ram_util_percent: 78.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.675514125071953
    mean_inference_ms: 0.7554870307774888
    mean_processing_ms: 0.5316538042622908
  time_since_restore: 1070.2418780326843
  time_this_iter_s: 1.4685933589935303
  time_total_s: 1070.2418780326843
  timestamp: 1744207296
  timesteps_since_restore: 143550
  timesteps_this_iter: 225
  timesteps_total: 143550
  training_iteration: 638
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    638 |          1070.24 |      143550 | 0.153839 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-01-43
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.16654782285328357
  episode_reward_mean: 0.1526529902833664
  episode_reward_min: 0.13616006716758208
  episodes_this_iter: 5
  episodes_total: 3210
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 88.46
    learner:
      default_policy:
        cur_kl_coeff: 4.5305733920031344e-07
        cur_lr: 4.999999873689376e-05
        entropy: 12.452824592590332
        entropy_coeff: 0.0
        kl: 0.02762584760785103
        policy_loss: -0.08225215971469879
        total_loss: -0.08220193535089493
        vf_explained_var: 0.9745035171508789
        vf_loss: 5.022019104217179e-05
    load_time_ms: 0.9
    num_steps_sampled: 144450
    num_steps_trained: 144450
    sample_time_ms: 1450.239
    update_time_ms: 3.745
  iterations_since_restore: 642
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.833333333333332
    ram_util_percent: 78.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.676864855820557
    mean_inference_ms: 0.7556912364773126
    mean_processing_ms: 0.5318130361541984
  time_since_restore: 1076.6407051086426
  time_this_iter_s: 1.6084213256835938
  time_total_s: 1076.6407051086426
  timestamp: 1744207303
  timesteps_since_restore: 144450
  timesteps_this_iter: 225
  timesteps_total: 144450
  training_iteration: 642
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    642 |          1076.64 |      144450 | 0.152653 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-01-48
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.1665256589063876
  episode_reward_mean: 0.15185088104834457
  episode_reward_min: 0.13616006716758208
  episodes_this_iter: 5
  episodes_total: 3225
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 93.234
    learner:
      default_policy:
        cur_kl_coeff: 6.795859803787607e-07
        cur_lr: 4.999999873689376e-05
        entropy: 12.35252857208252
        entropy_coeff: 0.0
        kl: 0.037644270807504654
        policy_loss: -0.06553075462579727
        total_loss: -0.06547565013170242
        vf_explained_var: 0.9727731943130493
        vf_loss: 5.506643356056884e-05
    load_time_ms: 0.964
    num_steps_sampled: 145125
    num_steps_trained: 145125
    sample_time_ms: 1481.255
    update_time_ms: 3.542
  iterations_since_restore: 645
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.633333333333336
    ram_util_percent: 78.5
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.676870393233005
    mean_inference_ms: 0.7556895025923123
    mean_processing_ms: 0.5318357554861503
  time_since_restore: 1081.626900434494
  time_this_iter_s: 1.8199901580810547
  time_total_s: 1081.626900434494
  timestamp: 1744207308
  timesteps_since_restore: 145125
  timesteps_this_iter: 225
  timesteps_total: 145125
  training_iteration: 645
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    645 |          1081.63 |      145125 | 0.151851 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-01-53
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.1665256589063876
  episode_reward_mean: 0.1520994367910371
  episode_reward_min: 0.13616006716758208
  episodes_this_iter: 5
  episodes_total: 3240
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 97.814
    learner:
      default_policy:
        cur_kl_coeff: 6.795859803787607e-07
        cur_lr: 4.999999873689376e-05
        entropy: 12.668414115905762
        entropy_coeff: 0.0
        kl: 0.033135078847408295
        policy_loss: -0.061813920736312866
        total_loss: -0.061754535883665085
        vf_explained_var: 0.9699674844741821
        vf_loss: 5.9357942518545315e-05
    load_time_ms: 0.94
    num_steps_sampled: 145800
    num_steps_trained: 145800
    sample_time_ms: 1573.063
    update_time_ms: 3.818
  iterations_since_restore: 648
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.15
    ram_util_percent: 78.4
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.676464230680856
    mean_inference_ms: 0.7556356796787683
    mean_processing_ms: 0.531861668204446
  time_since_restore: 1087.0323314666748
  time_this_iter_s: 1.6808111667633057
  time_total_s: 1087.0323314666748
  timestamp: 1744207313
  timesteps_since_restore: 145800
  timesteps_this_iter: 225
  timesteps_total: 145800
  training_iteration: 648
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    648 |          1087.03 |      145800 | 0.152099 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-01-59
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.1665256589063876
  episode_reward_mean: 0.1519700604150013
  episode_reward_min: 0.13753031757888842
  episodes_this_iter: 5
  episodes_total: 3255
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 101.571
    learner:
      default_policy:
        cur_kl_coeff: 1.0193789421464317e-06
        cur_lr: 4.999999873689376e-05
        entropy: 12.36668586730957
        entropy_coeff: 0.0
        kl: 0.028339218348264694
        policy_loss: -0.07610652595758438
        total_loss: -0.07605733722448349
        vf_explained_var: 0.974748969078064
        vf_loss: 4.9166766984853894e-05
    load_time_ms: 1.065
    num_steps_sampled: 146475
    num_steps_trained: 146475
    sample_time_ms: 1665.168
    update_time_ms: 4.319
  iterations_since_restore: 651
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.766666666666666
    ram_util_percent: 78.26666666666667
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.676074051941757
    mean_inference_ms: 0.7556066929243098
    mean_processing_ms: 0.5319285940318486
  time_since_restore: 1092.7886414527893
  time_this_iter_s: 1.9818909168243408
  time_total_s: 1092.7886414527893
  timestamp: 1744207319
  timesteps_since_restore: 146475
  timesteps_this_iter: 225
  timesteps_total: 146475
  training_iteration: 651
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    651 |          1092.79 |      146475 |  0.15197 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-02-04
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.1665256589063876
  episode_reward_mean: 0.15123633605706852
  episode_reward_min: 0.13753031757888842
  episodes_this_iter: 5
  episodes_total: 3270
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 101.917
    learner:
      default_policy:
        cur_kl_coeff: 1.0193789421464317e-06
        cur_lr: 4.999999873689376e-05
        entropy: 13.123369216918945
        entropy_coeff: 0.0
        kl: 0.029607757925987244
        policy_loss: -0.06834990531206131
        total_loss: -0.06829001009464264
        vf_explained_var: 0.9687961339950562
        vf_loss: 5.9878278989344835e-05
    load_time_ms: 1.049
    num_steps_sampled: 147150
    num_steps_trained: 147150
    sample_time_ms: 1717.767
    update_time_ms: 4.275
  iterations_since_restore: 654
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.1
    ram_util_percent: 78.0
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.676099006679906
    mean_inference_ms: 0.7556606251277864
    mean_processing_ms: 0.5320666464846013
  time_since_restore: 1098.0919604301453
  time_this_iter_s: 1.634355068206787
  time_total_s: 1098.0919604301453
  timestamp: 1744207324
  timesteps_since_restore: 147150
  timesteps_this_iter: 225
  timesteps_total: 147150
  training_iteration: 654
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    654 |          1098.09 |      147150 | 0.151236 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-02-10
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.16610428293054305
  episode_reward_mean: 0.15089281736397314
  episode_reward_min: 0.13597082263561144
  episodes_this_iter: 5
  episodes_total: 3285
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 99.909
    learner:
      default_policy:
        cur_kl_coeff: 1.5290685269064852e-06
        cur_lr: 4.999999873689376e-05
        entropy: 13.024667739868164
        entropy_coeff: 0.0
        kl: 0.041081540286540985
        policy_loss: -0.07234647125005722
        total_loss: -0.07231034338474274
        vf_explained_var: 0.9813529253005981
        vf_loss: 3.6074146919418126e-05
    load_time_ms: 1.003
    num_steps_sampled: 147825
    num_steps_trained: 147825
    sample_time_ms: 1701.747
    update_time_ms: 4.255
  iterations_since_restore: 657
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.65
    ram_util_percent: 78.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.676554810648777
    mean_inference_ms: 0.7558194699259184
    mean_processing_ms: 0.5322504944381646
  time_since_restore: 1103.4560115337372
  time_this_iter_s: 1.6791343688964844
  time_total_s: 1103.4560115337372
  timestamp: 1744207330
  timesteps_since_restore: 147825
  timesteps_this_iter: 225
  timesteps_total: 147825
  training_iteration: 657
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    657 |          1103.46 |      147825 | 0.150893 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-02-15
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.16610428293054305
  episode_reward_mean: 0.15036972198864604
  episode_reward_min: 0.13597082263561144
  episodes_this_iter: 5
  episodes_total: 3300
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 99.265
    learner:
      default_policy:
        cur_kl_coeff: 2.2936026198294712e-06
        cur_lr: 4.999999873689376e-05
        entropy: 13.365254402160645
        entropy_coeff: 0.0
        kl: 0.06532052904367447
        policy_loss: -0.10635194927453995
        total_loss: -0.10630612075328827
        vf_explained_var: 0.9758034944534302
        vf_loss: 4.56652014690917e-05
    load_time_ms: 1.009
    num_steps_sampled: 148500
    num_steps_trained: 148500
    sample_time_ms: 1706.615
    update_time_ms: 3.88
  iterations_since_restore: 660
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.099999999999998
    ram_util_percent: 78.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.67762159108441
    mean_inference_ms: 0.7560774245438165
    mean_processing_ms: 0.5324908564531812
  time_since_restore: 1108.9484102725983
  time_this_iter_s: 1.7729442119598389
  time_total_s: 1108.9484102725983
  timestamp: 1744207335
  timesteps_since_restore: 148500
  timesteps_this_iter: 225
  timesteps_total: 148500
  training_iteration: 660
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    660 |          1108.95 |      148500 |  0.15037 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-02-22
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.16610428293054305
  episode_reward_mean: 0.1490265011182461
  episode_reward_min: 0.13584397736335713
  episodes_this_iter: 5
  episodes_total: 3320
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 97.932
    learner:
      default_policy:
        cur_kl_coeff: 7.740909495623782e-06
        cur_lr: 4.999999873689376e-05
        entropy: 13.289129257202148
        entropy_coeff: 0.0
        kl: 0.030202407389879227
        policy_loss: -0.07196129113435745
        total_loss: -0.07193230092525482
        vf_explained_var: 0.9843512773513794
        vf_loss: 2.8746082534780726e-05
    load_time_ms: 1.01
    num_steps_sampled: 149400
    num_steps_trained: 149400
    sample_time_ms: 1643.712
    update_time_ms: 4.003
  iterations_since_restore: 664
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.75
    ram_util_percent: 78.15
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.6795668247900695
    mean_inference_ms: 0.7565018360803613
    mean_processing_ms: 0.5328919822766491
  time_since_restore: 1115.5942785739899
  time_this_iter_s: 1.7315125465393066
  time_total_s: 1115.5942785739899
  timestamp: 1744207342
  timesteps_since_restore: 149400
  timesteps_this_iter: 225
  timesteps_total: 149400
  training_iteration: 664
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    664 |          1115.59 |      149400 | 0.149027 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-02-27
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.163047678575903
  episode_reward_mean: 0.1478657445729529
  episode_reward_min: 0.12633355160209453
  episodes_this_iter: 5
  episodes_total: 3335
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 93.683
    learner:
      default_policy:
        cur_kl_coeff: 7.740909495623782e-06
        cur_lr: 4.999999873689376e-05
        entropy: 13.459604263305664
        entropy_coeff: 0.0
        kl: 0.03536877781152725
        policy_loss: -0.07393376529216766
        total_loss: -0.07389728724956512
        vf_explained_var: 0.9801896214485168
        vf_loss: 3.620572533691302e-05
    load_time_ms: 1.045
    num_steps_sampled: 150075
    num_steps_trained: 150075
    sample_time_ms: 1626.894
    update_time_ms: 3.828
  iterations_since_restore: 667
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.333333333333332
    ram_util_percent: 78.23333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.68100039434181
    mean_inference_ms: 0.7568120893825
    mean_processing_ms: 0.5331755315384933
  time_since_restore: 1120.7455914020538
  time_this_iter_s: 1.6515693664550781
  time_total_s: 1120.7455914020538
  timestamp: 1744207347
  timesteps_since_restore: 150075
  timesteps_this_iter: 225
  timesteps_total: 150075
  training_iteration: 667
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    667 |          1120.75 |      150075 | 0.147866 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-02-34
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.1604651767328425
  episode_reward_mean: 0.14581419952906147
  episode_reward_min: 0.12633355160209453
  episodes_this_iter: 5
  episodes_total: 3355
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 88.197
    learner:
      default_policy:
        cur_kl_coeff: 7.740909495623782e-06
        cur_lr: 4.999999873689376e-05
        entropy: 13.072870254516602
        entropy_coeff: 0.0
        kl: 0.021835386753082275
        policy_loss: -0.0703795999288559
        total_loss: -0.07031578570604324
        vf_explained_var: 0.9648330807685852
        vf_loss: 6.363419379340485e-05
    load_time_ms: 0.996
    num_steps_sampled: 150975
    num_steps_trained: 150975
    sample_time_ms: 1533.506
    update_time_ms: 3.808
  iterations_since_restore: 671
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.15
    ram_util_percent: 78.1
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.682120482439151
    mean_inference_ms: 0.7570736847417657
    mean_processing_ms: 0.533431330773242
  time_since_restore: 1127.0059821605682
  time_this_iter_s: 1.4815993309020996
  time_total_s: 1127.0059821605682
  timestamp: 1744207354
  timesteps_since_restore: 150975
  timesteps_this_iter: 225
  timesteps_total: 150975
  training_iteration: 671
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    671 |          1127.01 |      150975 | 0.145814 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-02-40
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.15565715887583184
  episode_reward_mean: 0.1447542368311937
  episode_reward_min: 0.12633355160209453
  episodes_this_iter: 5
  episodes_total: 3375
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 85.784
    learner:
      default_policy:
        cur_kl_coeff: 1.1611363333940972e-05
        cur_lr: 4.999999873689376e-05
        entropy: 13.125264167785645
        entropy_coeff: 0.0
        kl: 0.025974690914154053
        policy_loss: -0.06486243009567261
        total_loss: -0.06483670324087143
        vf_explained_var: 0.9849752187728882
        vf_loss: 2.5413615730940364e-05
    load_time_ms: 0.938
    num_steps_sampled: 151875
    num_steps_trained: 151875
    sample_time_ms: 1506.805
    update_time_ms: 3.643
  iterations_since_restore: 675
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.8
    ram_util_percent: 78.06666666666666
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.6822964235334315
    mean_inference_ms: 0.7571182840437615
    mean_processing_ms: 0.5335402687077265
  time_since_restore: 1133.4040369987488
  time_this_iter_s: 1.7108895778656006
  time_total_s: 1133.4040369987488
  timestamp: 1744207360
  timesteps_since_restore: 151875
  timesteps_this_iter: 225
  timesteps_total: 151875
  training_iteration: 675
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    675 |           1133.4 |      151875 | 0.144754 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-02-46
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.15565715887583184
  episode_reward_mean: 0.14417753146000187
  episode_reward_min: 0.12633355160209453
  episodes_this_iter: 5
  episodes_total: 3390
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.093
    learner:
      default_policy:
        cur_kl_coeff: 1.1611363333940972e-05
        cur_lr: 4.999999873689376e-05
        entropy: 13.247278213500977
        entropy_coeff: 0.0
        kl: 0.02763352356851101
        policy_loss: -0.05832115560770035
        total_loss: -0.058276571333408356
        vf_explained_var: 0.974227249622345
        vf_loss: 4.425137740327045e-05
    load_time_ms: 0.904
    num_steps_sampled: 152550
    num_steps_trained: 152550
    sample_time_ms: 1595.513
    update_time_ms: 3.662
  iterations_since_restore: 678
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.300000000000004
    ram_util_percent: 78.13333333333334
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.6825089684286185
    mean_inference_ms: 0.7571510902689462
    mean_processing_ms: 0.5336376595678616
  time_since_restore: 1139.2073879241943
  time_this_iter_s: 1.9437270164489746
  time_total_s: 1139.2073879241943
  timestamp: 1744207366
  timesteps_since_restore: 152550
  timesteps_this_iter: 225
  timesteps_total: 152550
  training_iteration: 678
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    678 |          1139.21 |      152550 | 0.144178 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-02-51
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.15565715887583184
  episode_reward_mean: 0.14306695211732195
  episode_reward_min: 0.12040042942752782
  episodes_this_iter: 5
  episodes_total: 3405
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 92.886
    learner:
      default_policy:
        cur_kl_coeff: 1.1611363333940972e-05
        cur_lr: 4.999999873689376e-05
        entropy: 12.569928169250488
        entropy_coeff: 0.0
        kl: 0.03343658894300461
        policy_loss: -0.0716594010591507
        total_loss: -0.07159474492073059
        vf_explained_var: 0.9626725912094116
        vf_loss: 6.42693557892926e-05
    load_time_ms: 0.905
    num_steps_sampled: 153225
    num_steps_trained: 153225
    sample_time_ms: 1636.284
    update_time_ms: 3.749
  iterations_since_restore: 681
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.099999999999998
    ram_util_percent: 78.16666666666667
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.682731144826678
    mean_inference_ms: 0.7571740761283178
    mean_processing_ms: 0.5337240422798065
  time_since_restore: 1144.3791737556458
  time_this_iter_s: 1.6454594135284424
  time_total_s: 1144.3791737556458
  timestamp: 1744207371
  timesteps_since_restore: 153225
  timesteps_this_iter: 225
  timesteps_total: 153225
  training_iteration: 681
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    681 |          1144.38 |      153225 | 0.143067 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-02-56
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.15565715887583184
  episode_reward_mean: 0.1421584573618756
  episode_reward_min: 0.12040042942752782
  episodes_this_iter: 5
  episodes_total: 3420
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 95.711
    learner:
      default_policy:
        cur_kl_coeff: 1.741704545565881e-05
        cur_lr: 4.999999873689376e-05
        entropy: 13.122247695922852
        entropy_coeff: 0.0
        kl: 0.04123501479625702
        policy_loss: -0.07887623459100723
        total_loss: -0.0787917748093605
        vf_explained_var: 0.9496250152587891
        vf_loss: 8.375845209229738e-05
    load_time_ms: 0.917
    num_steps_sampled: 153900
    num_steps_trained: 153900
    sample_time_ms: 1686.405
    update_time_ms: 4.02
  iterations_since_restore: 684
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.75
    ram_util_percent: 78.1
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.683211765559129
    mean_inference_ms: 0.7572464986757365
    mean_processing_ms: 0.5338178475573342
  time_since_restore: 1149.5996658802032
  time_this_iter_s: 1.5422539710998535
  time_total_s: 1149.5996658802032
  timestamp: 1744207376
  timesteps_since_restore: 153900
  timesteps_this_iter: 225
  timesteps_total: 153900
  training_iteration: 684
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    684 |           1149.6 |      153900 | 0.142158 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-03-02
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.15565715887583184
  episode_reward_mean: 0.14080760401162368
  episode_reward_min: 0.12040042942752782
  episodes_this_iter: 5
  episodes_total: 3435
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 94.245
    learner:
      default_policy:
        cur_kl_coeff: 3.918835136573762e-05
        cur_lr: 4.999999873689376e-05
        entropy: 12.604849815368652
        entropy_coeff: 0.0
        kl: 0.02295323833823204
        policy_loss: -0.05605750158429146
        total_loss: -0.056007374078035355
        vf_explained_var: 0.9693540334701538
        vf_loss: 4.921936852042563e-05
    load_time_ms: 0.923
    num_steps_sampled: 154575
    num_steps_trained: 154575
    sample_time_ms: 1672.552
    update_time_ms: 4.339
  iterations_since_restore: 687
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.333333333333332
    ram_util_percent: 78.33333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.683758523753625
    mean_inference_ms: 0.7573319446253539
    mean_processing_ms: 0.5338746891890619
  time_since_restore: 1155.0205526351929
  time_this_iter_s: 1.8098421096801758
  time_total_s: 1155.0205526351929
  timestamp: 1744207382
  timesteps_since_restore: 154575
  timesteps_this_iter: 225
  timesteps_total: 154575
  training_iteration: 687
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    687 |          1155.02 |      154575 | 0.140808 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-03-08
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.1538310764980469
  episode_reward_mean: 0.13957532729101915
  episode_reward_min: 0.12040042942752782
  episodes_this_iter: 5
  episodes_total: 3455
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 95.864
    learner:
      default_policy:
        cur_kl_coeff: 5.8782527048606426e-05
        cur_lr: 4.999999873689376e-05
        entropy: 12.933174133300781
        entropy_coeff: 0.0
        kl: 0.03109402395784855
        policy_loss: -0.07182811200618744
        total_loss: -0.0717942863702774
        vf_explained_var: 0.9794759750366211
        vf_loss: 3.199997081537731e-05
    load_time_ms: 0.914
    num_steps_sampled: 155475
    num_steps_trained: 155475
    sample_time_ms: 1633.517
    update_time_ms: 4.324
  iterations_since_restore: 691
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.23333333333333
    ram_util_percent: 78.39999999999999
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.684761868374288
    mean_inference_ms: 0.7575150620892706
    mean_processing_ms: 0.5339916914034607
  time_since_restore: 1161.7614500522614
  time_this_iter_s: 1.7803194522857666
  time_total_s: 1161.7614500522614
  timestamp: 1744207388
  timesteps_since_restore: 155475
  timesteps_this_iter: 225
  timesteps_total: 155475
  training_iteration: 691
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    691 |          1161.76 |      155475 | 0.139575 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-03-14
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.15226763026047715
  episode_reward_mean: 0.13789452594461266
  episode_reward_min: 0.11450446091666974
  episodes_this_iter: 5
  episodes_total: 3470
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 94.81
    learner:
      default_policy:
        cur_kl_coeff: 0.00013226068404037505
        cur_lr: 4.999999873689376e-05
        entropy: 13.00769329071045
        entropy_coeff: 0.0
        kl: 0.023204201832413673
        policy_loss: -0.07099135220050812
        total_loss: -0.07094947248697281
        vf_explained_var: 0.9744764566421509
        vf_loss: 3.879053838318214e-05
    load_time_ms: 0.928
    num_steps_sampled: 156150
    num_steps_trained: 156150
    sample_time_ms: 1625.183
    update_time_ms: 4.33
  iterations_since_restore: 694
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.366666666666664
    ram_util_percent: 78.26666666666667
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.685858098891158
    mean_inference_ms: 0.757717321676134
    mean_processing_ms: 0.5341211275067476
  time_since_restore: 1166.8866674900055
  time_this_iter_s: 1.738553524017334
  time_total_s: 1166.8866674900055
  timestamp: 1744207394
  timesteps_since_restore: 156150
  timesteps_this_iter: 225
  timesteps_total: 156150
  training_iteration: 694
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    694 |          1166.89 |      156150 | 0.137895 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-03-19
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.15226763026047715
  episode_reward_mean: 0.13657419949284516
  episode_reward_min: 0.11450446091666974
  episodes_this_iter: 5
  episodes_total: 3485
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 95.072
    learner:
      default_policy:
        cur_kl_coeff: 0.00013226068404037505
        cur_lr: 4.999999873689376e-05
        entropy: 13.19275951385498
        entropy_coeff: 0.0
        kl: 0.04670468717813492
        policy_loss: -0.0713353380560875
        total_loss: -0.07129122316837311
        vf_explained_var: 0.9747603535652161
        vf_loss: 3.7956480809953064e-05
    load_time_ms: 0.973
    num_steps_sampled: 156825
    num_steps_trained: 156825
    sample_time_ms: 1652.581
    update_time_ms: 4.242
  iterations_since_restore: 697
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.0
    ram_util_percent: 79.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.6872804166328885
    mean_inference_ms: 0.7579887666200424
    mean_processing_ms: 0.5343019574442666
  time_since_restore: 1172.583151102066
  time_this_iter_s: 1.6799604892730713
  time_total_s: 1172.583151102066
  timestamp: 1744207399
  timesteps_since_restore: 156825
  timesteps_this_iter: 225
  timesteps_total: 156825
  training_iteration: 697
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.2/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    697 |          1172.58 |      156825 | 0.136574 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-03-24
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.1507068564387774
  episode_reward_mean: 0.13514661640824596
  episode_reward_min: 0.11450446091666974
  episodes_this_iter: 5
  episodes_total: 3500
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 93.546
    learner:
      default_policy:
        cur_kl_coeff: 0.00044637982500717044
        cur_lr: 4.999999873689376e-05
        entropy: 13.125907897949219
        entropy_coeff: 0.0
        kl: 0.04447391629219055
        policy_loss: -0.09409968554973602
        total_loss: -0.09403141587972641
        vf_explained_var: 0.9674402475357056
        vf_loss: 4.8418951337225735e-05
    load_time_ms: 1.004
    num_steps_sampled: 157500
    num_steps_trained: 157500
    sample_time_ms: 1671.461
    update_time_ms: 4.123
  iterations_since_restore: 700
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.049999999999997
    ram_util_percent: 78.6
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.688373467985904
    mean_inference_ms: 0.7582114948496438
    mean_processing_ms: 0.5344568350310586
  time_since_restore: 1177.7154831886292
  time_this_iter_s: 1.6051545143127441
  time_total_s: 1177.7154831886292
  timestamp: 1744207404
  timesteps_since_restore: 157500
  timesteps_this_iter: 225
  timesteps_total: 157500
  training_iteration: 700
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    700 |          1177.72 |      157500 | 0.135147 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-03-30
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.14888421832142137
  episode_reward_mean: 0.13429514519632954
  episode_reward_min: 0.11450446091666974
  episodes_this_iter: 5
  episodes_total: 3515
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.398
    learner:
      default_policy:
        cur_kl_coeff: 0.0006695697666145861
        cur_lr: 4.999999873689376e-05
        entropy: 13.219757080078125
        entropy_coeff: 0.0
        kl: 0.03223951905965805
        policy_loss: -0.07153251022100449
        total_loss: -0.07147041708230972
        vf_explained_var: 0.9717159271240234
        vf_loss: 4.0494931454304606e-05
    load_time_ms: 1.0
    num_steps_sampled: 158175
    num_steps_trained: 158175
    sample_time_ms: 1661.79
    update_time_ms: 3.756
  iterations_since_restore: 703
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.5
    ram_util_percent: 78.6
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.689343490126561
    mean_inference_ms: 0.7584111232860637
    mean_processing_ms: 0.5345986507251871
  time_since_restore: 1182.7392570972443
  time_this_iter_s: 1.5042622089385986
  time_total_s: 1182.7392570972443
  timestamp: 1744207410
  timesteps_since_restore: 158175
  timesteps_this_iter: 225
  timesteps_total: 158175
  training_iteration: 703
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    703 |          1182.74 |      158175 | 0.134295 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-03-36
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.14599221773362442
  episode_reward_mean: 0.1338598762076181
  episode_reward_min: 0.11450446091666974
  episodes_this_iter: 5
  episodes_total: 3535
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.942
    learner:
      default_policy:
        cur_kl_coeff: 0.0010043545626103878
        cur_lr: 4.999999873689376e-05
        entropy: 12.771873474121094
        entropy_coeff: 0.0
        kl: 0.045975543558597565
        policy_loss: -0.08052553236484528
        total_loss: -0.08043648302555084
        vf_explained_var: 0.9715073704719543
        vf_loss: 4.287981573725119e-05
    load_time_ms: 0.928
    num_steps_sampled: 159075
    num_steps_trained: 159075
    sample_time_ms: 1555.59
    update_time_ms: 3.554
  iterations_since_restore: 707
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.133333333333336
    ram_util_percent: 78.43333333333334
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.690049243597411
    mean_inference_ms: 0.7585639471011518
    mean_processing_ms: 0.534743612527623
  time_since_restore: 1189.1245493888855
  time_this_iter_s: 1.6240313053131104
  time_total_s: 1189.1245493888855
  timestamp: 1744207416
  timesteps_since_restore: 159075
  timesteps_this_iter: 225
  timesteps_total: 159075
  training_iteration: 707
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    707 |          1189.12 |      159075 |  0.13386 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-03-41
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.1456135360215005
  episode_reward_mean: 0.13326860797047851
  episode_reward_min: 0.11450446091666974
  episodes_this_iter: 5
  episodes_total: 3550
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.505
    learner:
      default_policy:
        cur_kl_coeff: 0.0022597978822886944
        cur_lr: 4.999999873689376e-05
        entropy: 12.69372272491455
        entropy_coeff: 0.0
        kl: 0.08638841658830643
        policy_loss: -0.06289224326610565
        total_loss: -0.06266967207193375
        vf_explained_var: 0.9815312623977661
        vf_loss: 2.733864494075533e-05
    load_time_ms: 0.93
    num_steps_sampled: 159750
    num_steps_trained: 159750
    sample_time_ms: 1593.623
    update_time_ms: 3.649
  iterations_since_restore: 710
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.733333333333334
    ram_util_percent: 79.0
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.690826669765517
    mean_inference_ms: 0.7587184028178859
    mean_processing_ms: 0.5348737285496468
  time_since_restore: 1194.6256375312805
  time_this_iter_s: 1.5894217491149902
  time_total_s: 1194.6256375312805
  timestamp: 1744207421
  timesteps_since_restore: 159750
  timesteps_this_iter: 225
  timesteps_total: 159750
  training_iteration: 710
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    710 |          1194.63 |      159750 | 0.133269 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-03-47
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.1456135360215005
  episode_reward_mean: 0.13235022634112362
  episode_reward_min: 0.11450446091666974
  episodes_this_iter: 5
  episodes_total: 3565
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.256
    learner:
      default_policy:
        cur_kl_coeff: 0.0033896968234330416
        cur_lr: 4.999999873689376e-05
        entropy: 12.489155769348145
        entropy_coeff: 0.0
        kl: 0.045343924313783646
        policy_loss: -0.07519755512475967
        total_loss: -0.07501280307769775
        vf_explained_var: 0.9780267477035522
        vf_loss: 3.1046864023664966e-05
    load_time_ms: 0.932
    num_steps_sampled: 160425
    num_steps_trained: 160425
    sample_time_ms: 1603.669
    update_time_ms: 3.767
  iterations_since_restore: 713
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.45
    ram_util_percent: 78.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.691583457567224
    mean_inference_ms: 0.7588830615512215
    mean_processing_ms: 0.5349917345156797
  time_since_restore: 1199.769103527069
  time_this_iter_s: 1.726181983947754
  time_total_s: 1199.769103527069
  timestamp: 1744207427
  timesteps_since_restore: 160425
  timesteps_this_iter: 225
  timesteps_total: 160425
  training_iteration: 713
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    713 |          1199.77 |      160425 |  0.13235 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-03-53
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.14402884339565775
  episode_reward_mean: 0.13208390840220602
  episode_reward_min: 0.11881211971954056
  episodes_this_iter: 5
  episodes_total: 3585
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 87.192
    learner:
      default_policy:
        cur_kl_coeff: 0.011440226808190346
        cur_lr: 4.999999873689376e-05
        entropy: 12.416751861572266
        entropy_coeff: 0.0
        kl: 0.040961407124996185
        policy_loss: -0.07891230285167694
        total_loss: -0.07841869443655014
        vf_explained_var: 0.983526349067688
        vf_loss: 2.5014791390276514e-05
    load_time_ms: 0.904
    num_steps_sampled: 161325
    num_steps_trained: 161325
    sample_time_ms: 1600.945
    update_time_ms: 3.893
  iterations_since_restore: 717
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.450000000000003
    ram_util_percent: 78.35
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.691969958269595
    mean_inference_ms: 0.7590101710576742
    mean_processing_ms: 0.5350390699173895
  time_since_restore: 1206.0878410339355
  time_this_iter_s: 1.4426295757293701
  time_total_s: 1206.0878410339355
  timestamp: 1744207433
  timesteps_since_restore: 161325
  timesteps_this_iter: 225
  timesteps_total: 161325
  training_iteration: 717
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    717 |          1206.09 |      161325 | 0.132084 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-04-00
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.14312512284840698
  episode_reward_mean: 0.13137659063587412
  episode_reward_min: 0.11881211971954056
  episodes_this_iter: 5
  episodes_total: 3605
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 86.309
    learner:
      default_policy:
        cur_kl_coeff: 0.03861076384782791
        cur_lr: 4.999999873689376e-05
        entropy: 12.235018730163574
        entropy_coeff: 0.0
        kl: 0.030485335737466812
        policy_loss: -0.072226881980896
        total_loss: -0.0710076093673706
        vf_explained_var: 0.9705856442451477
        vf_loss: 4.221100971335545e-05
    load_time_ms: 0.954
    num_steps_sampled: 162225
    num_steps_trained: 162225
    sample_time_ms: 1557.654
    update_time_ms: 3.926
  iterations_since_restore: 721
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.133333333333336
    ram_util_percent: 78.36666666666667
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.691628143680344
    mean_inference_ms: 0.7589926057276242
    mean_processing_ms: 0.5350209767758691
  time_since_restore: 1212.815546989441
  time_this_iter_s: 1.796067476272583
  time_total_s: 1212.815546989441
  timestamp: 1744207440
  timesteps_since_restore: 162225
  timesteps_this_iter: 225
  timesteps_total: 162225
  training_iteration: 721
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    721 |          1212.82 |      162225 | 0.131377 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-04-05
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.14184019631098377
  episode_reward_mean: 0.13038978942828663
  episode_reward_min: 0.11722456733716012
  episodes_this_iter: 5
  episodes_total: 3620
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 87.391
    learner:
      default_policy:
        cur_kl_coeff: 0.057916149497032166
        cur_lr: 4.999999873689376e-05
        entropy: 12.559364318847656
        entropy_coeff: 0.0
        kl: 0.02736290916800499
        policy_loss: -0.06748588383197784
        total_loss: -0.06587474048137665
        vf_explained_var: 0.9807825088500977
        vf_loss: 2.637695797602646e-05
    load_time_ms: 0.928
    num_steps_sampled: 162900
    num_steps_trained: 162900
    sample_time_ms: 1566.317
    update_time_ms: 3.948
  iterations_since_restore: 724
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.9
    ram_util_percent: 78.6
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.691679278135225
    mean_inference_ms: 0.7590324989172162
    mean_processing_ms: 0.5350640322755824
  time_since_restore: 1217.9623713493347
  time_this_iter_s: 1.5713188648223877
  time_total_s: 1217.9623713493347
  timestamp: 1744207445
  timesteps_since_restore: 162900
  timesteps_this_iter: 225
  timesteps_total: 162900
  training_iteration: 724
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    724 |          1217.96 |      162900 |  0.13039 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-04-10
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.14184019631098377
  episode_reward_mean: 0.12941993632983192
  episode_reward_min: 0.11722456733716012
  episodes_this_iter: 5
  episodes_total: 3635
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 88.669
    learner:
      default_policy:
        cur_kl_coeff: 0.057916149497032166
        cur_lr: 4.999999873689376e-05
        entropy: 12.167343139648438
        entropy_coeff: 0.0
        kl: 0.04109704867005348
        policy_loss: -0.07199351489543915
        total_loss: -0.06956930458545685
        vf_explained_var: 0.9686948657035828
        vf_loss: 4.404363426147029e-05
    load_time_ms: 0.937
    num_steps_sampled: 163575
    num_steps_trained: 163575
    sample_time_ms: 1614.05
    update_time_ms: 3.793
  iterations_since_restore: 727
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.666666666666668
    ram_util_percent: 79.1
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.692058724430854
    mean_inference_ms: 0.7591173574465437
    mean_processing_ms: 0.5351375396333328
  time_since_restore: 1223.1952567100525
  time_this_iter_s: 1.6106958389282227
  time_total_s: 1223.1952567100525
  timestamp: 1744207450
  timesteps_since_restore: 163575
  timesteps_this_iter: 225
  timesteps_total: 163575
  training_iteration: 727
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.2/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    727 |           1223.2 |      163575 |  0.12942 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-04-17
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.13764269756591946
  episode_reward_mean: 0.1283773739160545
  episode_reward_min: 0.11620649115477219
  episodes_this_iter: 5
  episodes_total: 3655
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.834
    learner:
      default_policy:
        cur_kl_coeff: 0.08687422424554825
        cur_lr: 4.999999873689376e-05
        entropy: 12.377195358276367
        entropy_coeff: 0.0
        kl: 0.0150894271209836
        policy_loss: -0.047472454607486725
        total_loss: -0.04613655060529709
        vf_explained_var: 0.9824013710021973
        vf_loss: 2.500598202459514e-05
    load_time_ms: 0.893
    num_steps_sampled: 164475
    num_steps_trained: 164475
    sample_time_ms: 1594.385
    update_time_ms: 3.714
  iterations_since_restore: 731
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.450000000000003
    ram_util_percent: 79.15
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.691960614514223
    mean_inference_ms: 0.7591172297894149
    mean_processing_ms: 0.5352093842853225
  time_since_restore: 1229.748114824295
  time_this_iter_s: 1.6599435806274414
  time_total_s: 1229.748114824295
  timestamp: 1744207457
  timesteps_since_restore: 164475
  timesteps_this_iter: 225
  timesteps_total: 164475
  training_iteration: 731
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    731 |          1229.75 |      164475 | 0.128377 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-04-23
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.13764269756591946
  episode_reward_mean: 0.12787479344500963
  episode_reward_min: 0.11620649115477219
  episodes_this_iter: 5
  episodes_total: 3670
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 98.002
    learner:
      default_policy:
        cur_kl_coeff: 0.08687422424554825
        cur_lr: 4.999999873689376e-05
        entropy: 12.007019996643066
        entropy_coeff: 0.0
        kl: 0.027392636984586716
        policy_loss: -0.07297082990407944
        total_loss: -0.07056383788585663
        vf_explained_var: 0.9797903299331665
        vf_loss: 2.72641955234576e-05
    load_time_ms: 1.0
    num_steps_sampled: 165150
    num_steps_trained: 165150
    sample_time_ms: 1651.265
    update_time_ms: 3.84
  iterations_since_restore: 734
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.6
    ram_util_percent: 78.6
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.692269304338344
    mean_inference_ms: 0.7591681335571053
    mean_processing_ms: 0.5353724749064223
  time_since_restore: 1235.538412809372
  time_this_iter_s: 1.5855674743652344
  time_total_s: 1235.538412809372
  timestamp: 1744207463
  timesteps_since_restore: 165150
  timesteps_this_iter: 225
  timesteps_total: 165150
  training_iteration: 734
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    734 |          1235.54 |      165150 | 0.127875 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-04-29
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.13708707331138326
  episode_reward_mean: 0.12654973938247646
  episode_reward_min: 0.10826149191949597
  episodes_this_iter: 5
  episodes_total: 3690
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 96.815
    learner:
      default_policy:
        cur_kl_coeff: 0.08687422424554825
        cur_lr: 4.999999873689376e-05
        entropy: 12.077848434448242
        entropy_coeff: 0.0
        kl: 0.024323228746652603
        policy_loss: -0.08257819712162018
        total_loss: -0.08044417947530746
        vf_explained_var: 0.9837916493415833
        vf_loss: 2.0956917069270276e-05
    load_time_ms: 1.024
    num_steps_sampled: 166050
    num_steps_trained: 166050
    sample_time_ms: 1590.469
    update_time_ms: 4.042
  iterations_since_restore: 738
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.299999999999997
    ram_util_percent: 78.35
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.692511252550352
    mean_inference_ms: 0.7592217246439623
    mean_processing_ms: 0.5355792460515832
  time_since_restore: 1241.7143306732178
  time_this_iter_s: 1.5724966526031494
  time_total_s: 1241.7143306732178
  timestamp: 1744207469
  timesteps_since_restore: 166050
  timesteps_this_iter: 225
  timesteps_total: 166050
  training_iteration: 738
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    738 |          1241.71 |      166050 |  0.12655 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-04-34
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.13708707331138326
  episode_reward_mean: 0.12598550108677592
  episode_reward_min: 0.10826149191949597
  episodes_this_iter: 5
  episodes_total: 3705
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 97.913
    learner:
      default_policy:
        cur_kl_coeff: 0.08687422424554825
        cur_lr: 4.999999873689376e-05
        entropy: 11.07383918762207
        entropy_coeff: 0.0
        kl: 0.034779272973537445
        policy_loss: -0.07808021456003189
        total_loss: -0.07503290474414825
        vf_explained_var: 0.9804755449295044
        vf_loss: 2.5879062377498485e-05
    load_time_ms: 1.057
    num_steps_sampled: 166725
    num_steps_trained: 166725
    sample_time_ms: 1620.158
    update_time_ms: 3.96
  iterations_since_restore: 741
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.63333333333333
    ram_util_percent: 78.4
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.692781422990784
    mean_inference_ms: 0.7592926572259994
    mean_processing_ms: 0.5357282098667624
  time_since_restore: 1247.0129432678223
  time_this_iter_s: 1.9891951084136963
  time_total_s: 1247.0129432678223
  timestamp: 1744207474
  timesteps_since_restore: 166725
  timesteps_this_iter: 225
  timesteps_total: 166725
  training_iteration: 741
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    741 |          1247.01 |      166725 | 0.125986 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-04-40
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.13708707331138326
  episode_reward_mean: 0.1253289135640472
  episode_reward_min: 0.10826149191949597
  episodes_this_iter: 5
  episodes_total: 3725
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.981
    learner:
      default_policy:
        cur_kl_coeff: 0.08687422424554825
        cur_lr: 4.999999873689376e-05
        entropy: 11.883715629577637
        entropy_coeff: 0.0
        kl: 0.044582549482584
        policy_loss: -0.06859447062015533
        total_loss: -0.06469825655221939
        vf_explained_var: 0.9820639491081238
        vf_loss: 2.3134438379202038e-05
    load_time_ms: 0.988
    num_steps_sampled: 167625
    num_steps_trained: 167625
    sample_time_ms: 1531.637
    update_time_ms: 3.802
  iterations_since_restore: 745
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.45
    ram_util_percent: 78.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.69273097513787
    mean_inference_ms: 0.7593267569590203
    mean_processing_ms: 0.5358716186852662
  time_since_restore: 1253.3117020130157
  time_this_iter_s: 1.5907864570617676
  time_total_s: 1253.3117020130157
  timestamp: 1744207480
  timesteps_since_restore: 167625
  timesteps_this_iter: 225
  timesteps_total: 167625
  training_iteration: 745
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    745 |          1253.31 |      167625 | 0.125329 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-04-46
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.13708707331138326
  episode_reward_mean: 0.12464067053571096
  episode_reward_min: 0.10826149191949597
  episodes_this_iter: 5
  episodes_total: 3740
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 93.229
    learner:
      default_policy:
        cur_kl_coeff: 0.13031134009361267
        cur_lr: 4.999999873689376e-05
        entropy: 11.414250373840332
        entropy_coeff: 0.0
        kl: 0.019917916506528854
        policy_loss: -0.06300410628318787
        total_loss: -0.06038729101419449
        vf_explained_var: 0.9833895564079285
        vf_loss: 2.130614848283585e-05
    load_time_ms: 0.972
    num_steps_sampled: 168300
    num_steps_trained: 168300
    sample_time_ms: 1616.3
    update_time_ms: 3.769
  iterations_since_restore: 748
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.566666666666666
    ram_util_percent: 79.0
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.692889540952437
    mean_inference_ms: 0.7593981210724579
    mean_processing_ms: 0.5360171246496215
  time_since_restore: 1258.891232252121
  time_this_iter_s: 1.6451530456542969
  time_total_s: 1258.891232252121
  timestamp: 1744207486
  timesteps_since_restore: 168300
  timesteps_this_iter: 225
  timesteps_total: 168300
  training_iteration: 748
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    748 |          1258.89 |      168300 | 0.124641 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-04-51
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.13380268420597377
  episode_reward_mean: 0.12295550552236124
  episode_reward_min: 0.10789044867135095
  episodes_this_iter: 5
  episodes_total: 3755
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 93.799
    learner:
      default_policy:
        cur_kl_coeff: 0.13031134009361267
        cur_lr: 4.999999873689376e-05
        entropy: 11.159622192382812
        entropy_coeff: 0.0
        kl: 0.031204164028167725
        policy_loss: -0.07560334354639053
        total_loss: -0.07151393592357635
        vf_explained_var: 0.9804583787918091
        vf_loss: 2.315844176337123e-05
    load_time_ms: 0.997
    num_steps_sampled: 168975
    num_steps_trained: 168975
    sample_time_ms: 1589.167
    update_time_ms: 3.746
  iterations_since_restore: 751
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.5
    ram_util_percent: 78.5
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.693198085322339
    mean_inference_ms: 0.7594897563246772
    mean_processing_ms: 0.5361644666216796
  time_since_restore: 1263.924364566803
  time_this_iter_s: 1.6106667518615723
  time_total_s: 1263.924364566803
  timestamp: 1744207491
  timesteps_since_restore: 168975
  timesteps_this_iter: 225
  timesteps_total: 168975
  training_iteration: 751
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    751 |          1263.92 |      168975 | 0.122956 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-04-56
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.13380268420597377
  episode_reward_mean: 0.12141688004148704
  episode_reward_min: 0.10612219709783284
  episodes_this_iter: 5
  episodes_total: 3770
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 94.763
    learner:
      default_policy:
        cur_kl_coeff: 0.13031134009361267
        cur_lr: 4.999999873689376e-05
        entropy: 11.081787109375
        entropy_coeff: 0.0
        kl: 0.039235807955265045
        policy_loss: -0.0753241628408432
        total_loss: -0.0701671615242958
        vf_explained_var: 0.9603480100631714
        vf_loss: 4.4131138565717265e-05
    load_time_ms: 0.991
    num_steps_sampled: 169650
    num_steps_trained: 169650
    sample_time_ms: 1649.509
    update_time_ms: 3.686
  iterations_since_restore: 754
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.96666666666667
    ram_util_percent: 78.43333333333334
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.693068796131629
    mean_inference_ms: 0.7595114962352583
    mean_processing_ms: 0.5362180275064228
  time_since_restore: 1269.243976354599
  time_this_iter_s: 1.9550507068634033
  time_total_s: 1269.243976354599
  timestamp: 1744207496
  timesteps_since_restore: 169650
  timesteps_this_iter: 225
  timesteps_total: 169650
  training_iteration: 754
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    754 |          1269.24 |      169650 | 0.121417 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-05-02
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.13380268420597377
  episode_reward_mean: 0.12059467033327571
  episode_reward_min: 0.10612219709783284
  episodes_this_iter: 5
  episodes_total: 3785
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 94.741
    learner:
      default_policy:
        cur_kl_coeff: 0.1954669952392578
        cur_lr: 4.999999873689376e-05
        entropy: 11.226102828979492
        entropy_coeff: 0.0
        kl: 0.03428920730948448
        policy_loss: -0.07818222790956497
        total_loss: -0.07145263999700546
        vf_explained_var: 0.9764850735664368
        vf_loss: 2.7186868464923464e-05
    load_time_ms: 0.955
    num_steps_sampled: 170325
    num_steps_trained: 170325
    sample_time_ms: 1640.734
    update_time_ms: 3.686
  iterations_since_restore: 757
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.7
    ram_util_percent: 78.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.69361684389008
    mean_inference_ms: 0.7596201400355767
    mean_processing_ms: 0.5363470913231658
  time_since_restore: 1274.6802382469177
  time_this_iter_s: 1.5936651229858398
  time_total_s: 1274.6802382469177
  timestamp: 1744207502
  timesteps_since_restore: 170325
  timesteps_this_iter: 225
  timesteps_total: 170325
  training_iteration: 757
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    757 |          1274.68 |      170325 | 0.120595 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-05-08
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.13380268420597377
  episode_reward_mean: 0.11816451193591491
  episode_reward_min: 0.10184613349524795
  episodes_this_iter: 5
  episodes_total: 3805
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.109
    learner:
      default_policy:
        cur_kl_coeff: 0.1954669952392578
        cur_lr: 4.999999873689376e-05
        entropy: 11.147464752197266
        entropy_coeff: 0.0
        kl: 0.030963608995079994
        policy_loss: -0.07386164367198944
        total_loss: -0.06778736412525177
        vf_explained_var: 0.9797442555427551
        vf_loss: 2.19221710722195e-05
    load_time_ms: 0.88
    num_steps_sampled: 171225
    num_steps_trained: 171225
    sample_time_ms: 1612.152
    update_time_ms: 3.589
  iterations_since_restore: 761
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.23333333333333
    ram_util_percent: 78.33333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.694179136948618
    mean_inference_ms: 0.7597177840607884
    mean_processing_ms: 0.5364935940782538
  time_since_restore: 1281.02321434021
  time_this_iter_s: 1.7947077751159668
  time_total_s: 1281.02321434021
  timestamp: 1744207508
  timesteps_since_restore: 171225
  timesteps_this_iter: 225
  timesteps_total: 171225
  training_iteration: 761
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    761 |          1281.02 |      171225 | 0.118165 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-05-13
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.13380268420597377
  episode_reward_mean: 0.11685648634076719
  episode_reward_min: 0.10184613349524795
  episodes_this_iter: 5
  episodes_total: 3820
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 88.116
    learner:
      default_policy:
        cur_kl_coeff: 0.1954669952392578
        cur_lr: 4.999999873689376e-05
        entropy: 11.687336921691895
        entropy_coeff: 0.0
        kl: 0.025449758395552635
        policy_loss: -0.07381945848464966
        total_loss: -0.06882183253765106
        vf_explained_var: 0.9798578023910522
        vf_loss: 2.303661676705815e-05
    load_time_ms: 0.839
    num_steps_sampled: 171900
    num_steps_trained: 171900
    sample_time_ms: 1592.509
    update_time_ms: 3.81
  iterations_since_restore: 764
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.799999999999997
    ram_util_percent: 78.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.694694115268572
    mean_inference_ms: 0.7598066793836017
    mean_processing_ms: 0.5365829643437228
  time_since_restore: 1286.1301510334015
  time_this_iter_s: 1.6035265922546387
  time_total_s: 1286.1301510334015
  timestamp: 1744207513
  timesteps_since_restore: 171900
  timesteps_this_iter: 225
  timesteps_total: 171900
  training_iteration: 764
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.2/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    764 |          1286.13 |      171900 | 0.116856 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-05-19
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.12715562381023557
  episode_reward_mean: 0.1156775464393396
  episode_reward_min: 0.10184613349524795
  episodes_this_iter: 5
  episodes_total: 3835
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 88.255
    learner:
      default_policy:
        cur_kl_coeff: 0.1954669952392578
        cur_lr: 4.999999873689376e-05
        entropy: 11.053964614868164
        entropy_coeff: 0.0
        kl: 0.028025537729263306
        policy_loss: -0.07796872407197952
        total_loss: -0.07246287912130356
        vf_explained_var: 0.9740859866142273
        vf_loss: 2.7781055905506946e-05
    load_time_ms: 0.871
    num_steps_sampled: 172575
    num_steps_trained: 172575
    sample_time_ms: 1607.398
    update_time_ms: 3.804
  iterations_since_restore: 767
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.900000000000002
    ram_util_percent: 78.63333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.695458854977167
    mean_inference_ms: 0.7599086732324645
    mean_processing_ms: 0.5366526586289927
  time_since_restore: 1291.7176687717438
  time_this_iter_s: 1.7102832794189453
  time_total_s: 1291.7176687717438
  timestamp: 1744207519
  timesteps_since_restore: 172575
  timesteps_this_iter: 225
  timesteps_total: 172575
  training_iteration: 767
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    767 |          1291.72 |      172575 | 0.115678 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-05-24
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.12715562381023557
  episode_reward_mean: 0.11450136344556182
  episode_reward_min: 0.09866720658283334
  episodes_this_iter: 5
  episodes_total: 3850
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 88.73
    learner:
      default_policy:
        cur_kl_coeff: 0.1954669952392578
        cur_lr: 4.999999873689376e-05
        entropy: 11.217921257019043
        entropy_coeff: 0.0
        kl: 0.025686439126729965
        policy_loss: -0.08084592968225479
        total_loss: -0.07578380405902863
        vf_explained_var: 0.9603425860404968
        vf_loss: 4.1275219700764865e-05
    load_time_ms: 0.926
    num_steps_sampled: 173250
    num_steps_trained: 173250
    sample_time_ms: 1681.612
    update_time_ms: 3.784
  iterations_since_restore: 770
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.75
    ram_util_percent: 78.5
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.696291772148204
    mean_inference_ms: 0.7600296409436305
    mean_processing_ms: 0.5367192156854834
  time_since_restore: 1297.0139384269714
  time_this_iter_s: 1.6653063297271729
  time_total_s: 1297.0139384269714
  timestamp: 1744207524
  timesteps_since_restore: 173250
  timesteps_this_iter: 225
  timesteps_total: 173250
  training_iteration: 770
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    770 |          1297.01 |      173250 | 0.114501 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-05-30
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.12715562381023557
  episode_reward_mean: 0.11390475818054142
  episode_reward_min: 0.09866720658283334
  episodes_this_iter: 5
  episodes_total: 3865
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 86.797
    learner:
      default_policy:
        cur_kl_coeff: 0.1954669952392578
        cur_lr: 4.999999873689376e-05
        entropy: 11.329656600952148
        entropy_coeff: 0.0
        kl: 0.028145577758550644
        policy_loss: -0.08150191605091095
        total_loss: -0.07597038149833679
        vf_explained_var: 0.9717987179756165
        vf_loss: 2.9993756470503286e-05
    load_time_ms: 0.98
    num_steps_sampled: 173925
    num_steps_trained: 173925
    sample_time_ms: 1690.289
    update_time_ms: 3.617
  iterations_since_restore: 773
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.1
    ram_util_percent: 78.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.697357999040633
    mean_inference_ms: 0.7601841008486181
    mean_processing_ms: 0.5367974571078133
  time_since_restore: 1302.3759760856628
  time_this_iter_s: 1.6975619792938232
  time_total_s: 1302.3759760856628
  timestamp: 1744207530
  timesteps_since_restore: 173925
  timesteps_this_iter: 225
  timesteps_total: 173925
  training_iteration: 773
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    773 |          1302.38 |      173925 | 0.113905 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-05-35
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.12715562381023557
  episode_reward_mean: 0.1127929973152395
  episode_reward_min: 0.09866720658283334
  episodes_this_iter: 5
  episodes_total: 3880
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 86.231
    learner:
      default_policy:
        cur_kl_coeff: 0.1954669952392578
        cur_lr: 4.999999873689376e-05
        entropy: 11.768310546875
        entropy_coeff: 0.0
        kl: 0.017102885991334915
        policy_loss: -0.05698303133249283
        total_loss: -0.053616832941770554
        vf_explained_var: 0.9777925610542297
        vf_loss: 2.3147693354985677e-05
    load_time_ms: 1.02
    num_steps_sampled: 174600
    num_steps_trained: 174600
    sample_time_ms: 1680.548
    update_time_ms: 3.687
  iterations_since_restore: 776
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.3
    ram_util_percent: 78.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.69828420485493
    mean_inference_ms: 0.7603199237224504
    mean_processing_ms: 0.536859855095127
  time_since_restore: 1307.7543106079102
  time_this_iter_s: 1.6857068538665771
  time_total_s: 1307.7543106079102
  timestamp: 1744207535
  timesteps_since_restore: 174600
  timesteps_this_iter: 225
  timesteps_total: 174600
  training_iteration: 776
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    776 |          1307.75 |      174600 | 0.112793 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-05-40
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.12479847685409924
  episode_reward_mean: 0.11159727062291941
  episode_reward_min: 0.09712824754133866
  episodes_this_iter: 5
  episodes_total: 3895
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 85.845
    learner:
      default_policy:
        cur_kl_coeff: 0.1954669952392578
        cur_lr: 4.999999873689376e-05
        entropy: 11.248833656311035
        entropy_coeff: 0.0
        kl: 0.021929407492280006
        policy_loss: -0.07018381357192993
        total_loss: -0.06587814539670944
        vf_explained_var: 0.9792779684066772
        vf_loss: 1.919155147334095e-05
    load_time_ms: 1.0
    num_steps_sampled: 175275
    num_steps_trained: 175275
    sample_time_ms: 1654.662
    update_time_ms: 3.74
  iterations_since_restore: 779
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.7
    ram_util_percent: 78.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.699441007267557
    mean_inference_ms: 0.7604914017434834
    mean_processing_ms: 0.5369274727047507
  time_since_restore: 1312.8324325084686
  time_this_iter_s: 1.666489601135254
  time_total_s: 1312.8324325084686
  timestamp: 1744207540
  timesteps_since_restore: 175275
  timesteps_this_iter: 225
  timesteps_total: 175275
  training_iteration: 779
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    779 |          1312.83 |      175275 | 0.111597 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-05-46
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.12479847685409924
  episode_reward_mean: 0.11016964442729929
  episode_reward_min: 0.08888600688674955
  episodes_this_iter: 5
  episodes_total: 3910
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 85.498
    learner:
      default_policy:
        cur_kl_coeff: 0.1954669952392578
        cur_lr: 4.999999873689376e-05
        entropy: 11.567492485046387
        entropy_coeff: 0.0
        kl: 0.024601537734270096
        policy_loss: -0.06776037067174911
        total_loss: -0.0629291981458664
        vf_explained_var: 0.9756549000740051
        vf_loss: 2.2384450858226046e-05
    load_time_ms: 0.99
    num_steps_sampled: 175950
    num_steps_trained: 175950
    sample_time_ms: 1656.289
    update_time_ms: 3.868
  iterations_since_restore: 782
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.5
    ram_util_percent: 77.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.700960450804161
    mean_inference_ms: 0.760658212224055
    mean_processing_ms: 0.5370295062518609
  time_since_restore: 1318.176739692688
  time_this_iter_s: 1.5955216884613037
  time_total_s: 1318.176739692688
  timestamp: 1744207546
  timesteps_since_restore: 175950
  timesteps_this_iter: 225
  timesteps_total: 175950
  training_iteration: 782
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    782 |          1318.18 |      175950 |  0.11017 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-05-51
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.12479847685409924
  episode_reward_mean: 0.10918041497313
  episode_reward_min: 0.08888600688674955
  episodes_this_iter: 5
  episodes_total: 3925
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 97.912
    learner:
      default_policy:
        cur_kl_coeff: 0.1954669952392578
        cur_lr: 4.999999873689376e-05
        entropy: 11.808423042297363
        entropy_coeff: 0.0
        kl: 0.016402296721935272
        policy_loss: -0.05118675157427788
        total_loss: -0.047959621995687485
        vf_explained_var: 0.9787241220474243
        vf_loss: 2.103101542161312e-05
    load_time_ms: 0.92
    num_steps_sampled: 176625
    num_steps_trained: 176625
    sample_time_ms: 1609.133
    update_time_ms: 4.368
  iterations_since_restore: 785
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.833333333333332
    ram_util_percent: 77.93333333333334
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.702175370504342
    mean_inference_ms: 0.7607553713504254
    mean_processing_ms: 0.5371311760881681
  time_since_restore: 1323.2248365879059
  time_this_iter_s: 1.764293909072876
  time_total_s: 1323.2248365879059
  timestamp: 1744207551
  timesteps_since_restore: 176625
  timesteps_this_iter: 225
  timesteps_total: 176625
  training_iteration: 785
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    785 |          1323.22 |      176625 |  0.10918 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-05-57
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.1220779468282907
  episode_reward_mean: 0.10839430114510744
  episode_reward_min: 0.08888600688674955
  episodes_this_iter: 5
  episodes_total: 3945
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 96.8
    learner:
      default_policy:
        cur_kl_coeff: 0.1954669952392578
        cur_lr: 4.999999873689376e-05
        entropy: 10.848848342895508
        entropy_coeff: 0.0
        kl: 0.021421918645501137
        policy_loss: -0.06695105880498886
        total_loss: -0.06273414194583893
        vf_explained_var: 0.9720679521560669
        vf_loss: 2.9634073143824935e-05
    load_time_ms: 0.878
    num_steps_sampled: 177525
    num_steps_trained: 177525
    sample_time_ms: 1584.502
    update_time_ms: 4.372
  iterations_since_restore: 789
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.1
    ram_util_percent: 77.85
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.7032784381691295
    mean_inference_ms: 0.7607749796883095
    mean_processing_ms: 0.5372054856770745
  time_since_restore: 1329.7311210632324
  time_this_iter_s: 1.625016450881958
  time_total_s: 1329.7311210632324
  timestamp: 1744207557
  timesteps_since_restore: 177525
  timesteps_this_iter: 225
  timesteps_total: 177525
  training_iteration: 789
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    789 |          1329.73 |      177525 | 0.108394 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-06-03
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.12038851648763746
  episode_reward_mean: 0.10831793797970062
  episode_reward_min: 0.08888600688674955
  episodes_this_iter: 5
  episodes_total: 3960
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 106.44
    learner:
      default_policy:
        cur_kl_coeff: 0.1954669952392578
        cur_lr: 4.999999873689376e-05
        entropy: 11.479019165039062
        entropy_coeff: 0.0
        kl: 0.02773703634738922
        policy_loss: -0.07448115944862366
        total_loss: -0.06903272867202759
        vf_explained_var: 0.9726773500442505
        vf_loss: 2.6763784262584522e-05
    load_time_ms: 0.929
    num_steps_sampled: 178200
    num_steps_trained: 178200
    sample_time_ms: 1656.014
    update_time_ms: 4.332
  iterations_since_restore: 792
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.7
    ram_util_percent: 78.7
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.7044767416712014
    mean_inference_ms: 0.760812764860347
    mean_processing_ms: 0.5372913209753469
  time_since_restore: 1335.8881933689117
  time_this_iter_s: 1.837308645248413
  time_total_s: 1335.8881933689117
  timestamp: 1744207563
  timesteps_since_restore: 178200
  timesteps_this_iter: 225
  timesteps_total: 178200
  training_iteration: 792
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    792 |          1335.89 |      178200 | 0.108318 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-06-09
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.12038851648763746
  episode_reward_mean: 0.10846281938661263
  episode_reward_min: 0.08888600688674955
  episodes_this_iter: 5
  episodes_total: 3975
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 98.236
    learner:
      default_policy:
        cur_kl_coeff: 0.1954669952392578
        cur_lr: 4.999999873689376e-05
        entropy: 11.14492416381836
        entropy_coeff: 0.0
        kl: 0.02775680087506771
        policy_loss: -0.07370950281620026
        total_loss: -0.06826276332139969
        vf_explained_var: 0.9795987010002136
        vf_loss: 2.120845419995021e-05
    load_time_ms: 0.95
    num_steps_sampled: 178875
    num_steps_trained: 178875
    sample_time_ms: 1728.263
    update_time_ms: 3.902
  iterations_since_restore: 795
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.833333333333332
    ram_util_percent: 78.73333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.705759551937454
    mean_inference_ms: 0.7608584271031235
    mean_processing_ms: 0.537388620142282
  time_since_restore: 1341.5720636844635
  time_this_iter_s: 2.119987964630127
  time_total_s: 1341.5720636844635
  timestamp: 1744207569
  timesteps_since_restore: 178875
  timesteps_this_iter: 225
  timesteps_total: 178875
  training_iteration: 795
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    795 |          1341.57 |      178875 | 0.108463 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-06-15
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.12038851648763746
  episode_reward_mean: 0.10857930371437768
  episode_reward_min: 0.08888600688674955
  episodes_this_iter: 5
  episodes_total: 3990
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 105.262
    learner:
      default_policy:
        cur_kl_coeff: 0.1954669952392578
        cur_lr: 4.999999873689376e-05
        entropy: 11.890337944030762
        entropy_coeff: 0.0
        kl: 0.028648624196648598
        policy_loss: -0.07108837366104126
        total_loss: -0.06544473022222519
        vf_explained_var: 0.9553444981575012
        vf_loss: 4.377682489575818e-05
    load_time_ms: 0.957
    num_steps_sampled: 179550
    num_steps_trained: 179550
    sample_time_ms: 1804.532
    update_time_ms: 4.034
  iterations_since_restore: 798
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.200000000000003
    ram_util_percent: 78.95
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.70727003378266
    mean_inference_ms: 0.7609552270413523
    mean_processing_ms: 0.5375179746031403
  time_since_restore: 1347.2895231246948
  time_this_iter_s: 1.8564870357513428
  time_total_s: 1347.2895231246948
  timestamp: 1744207575
  timesteps_since_restore: 179550
  timesteps_this_iter: 225
  timesteps_total: 179550
  training_iteration: 798
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    798 |          1347.29 |      179550 | 0.108579 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-06-21
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.12038851648763746
  episode_reward_mean: 0.10912447163767101
  episode_reward_min: 0.09418682620097345
  episodes_this_iter: 5
  episodes_total: 4005
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 100.577
    learner:
      default_policy:
        cur_kl_coeff: 0.1954669952392578
        cur_lr: 4.999999873689376e-05
        entropy: 11.85533618927002
        entropy_coeff: 0.0
        kl: 0.022514479234814644
        policy_loss: -0.08073347061872482
        total_loss: -0.07629790157079697
        vf_explained_var: 0.9636788368225098
        vf_loss: 3.4710577892838046e-05
    load_time_ms: 1.04
    num_steps_sampled: 180225
    num_steps_trained: 180225
    sample_time_ms: 1785.097
    update_time_ms: 3.915
  iterations_since_restore: 801
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.233333333333334
    ram_util_percent: 78.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.709116067898692
    mean_inference_ms: 0.7611563247958654
    mean_processing_ms: 0.5376950269522157
  time_since_restore: 1352.9923791885376
  time_this_iter_s: 1.7018179893493652
  time_total_s: 1352.9923791885376
  timestamp: 1744207581
  timesteps_since_restore: 180225
  timesteps_this_iter: 225
  timesteps_total: 180225
  training_iteration: 801
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    801 |          1352.99 |      180225 | 0.109124 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-06-26
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.12038851648763746
  episode_reward_mean: 0.10861889571232256
  episode_reward_min: 0.09418682620097345
  episodes_this_iter: 5
  episodes_total: 4020
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 99.097
    learner:
      default_policy:
        cur_kl_coeff: 0.1954669952392578
        cur_lr: 4.999999873689376e-05
        entropy: 11.256065368652344
        entropy_coeff: 0.0
        kl: 0.02272810973227024
        policy_loss: -0.0626598447561264
        total_loss: -0.05818657949566841
        vf_explained_var: 0.9666826128959656
        vf_loss: 3.0671031709061936e-05
    load_time_ms: 1.054
    num_steps_sampled: 180900
    num_steps_trained: 180900
    sample_time_ms: 1778.068
    update_time_ms: 3.887
  iterations_since_restore: 804
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.6
    ram_util_percent: 78.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.7111744542629514
    mean_inference_ms: 0.7614154479448938
    mean_processing_ms: 0.537896273660372
  time_since_restore: 1358.30957198143
  time_this_iter_s: 1.623398780822754
  time_total_s: 1358.30957198143
  timestamp: 1744207586
  timesteps_since_restore: 180900
  timesteps_this_iter: 225
  timesteps_total: 180900
  training_iteration: 804
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    804 |          1358.31 |      180900 | 0.108619 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-06-31
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.12038851648763746
  episode_reward_mean: 0.10821075801753635
  episode_reward_min: 0.09225427392625518
  episodes_this_iter: 5
  episodes_total: 4035
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 92.422
    learner:
      default_policy:
        cur_kl_coeff: 0.1954669952392578
        cur_lr: 4.999999873689376e-05
        entropy: 11.181031227111816
        entropy_coeff: 0.0
        kl: 0.01589902490377426
        policy_loss: -0.05854509025812149
        total_loss: -0.05540371686220169
        vf_explained_var: 0.9631136655807495
        vf_loss: 3.36391749442555e-05
    load_time_ms: 1.021
    num_steps_sampled: 181575
    num_steps_trained: 181575
    sample_time_ms: 1696.249
    update_time_ms: 3.764
  iterations_since_restore: 807
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.833333333333332
    ram_util_percent: 78.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.713237822832742
    mean_inference_ms: 0.7616759313835334
    mean_processing_ms: 0.5380914798087766
  time_since_restore: 1363.4022538661957
  time_this_iter_s: 1.741363525390625
  time_total_s: 1363.4022538661957
  timestamp: 1744207591
  timesteps_since_restore: 181575
  timesteps_this_iter: 225
  timesteps_total: 181575
  training_iteration: 807
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    807 |           1363.4 |      181575 | 0.108211 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-06-36
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.11777163783080191
  episode_reward_mean: 0.1077554209184128
  episode_reward_min: 0.09225427392625518
  episodes_this_iter: 5
  episodes_total: 4050
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 88.709
    learner:
      default_policy:
        cur_kl_coeff: 0.1954669952392578
        cur_lr: 4.999999873689376e-05
        entropy: 11.844511032104492
        entropy_coeff: 0.0
        kl: 0.02711608074605465
        policy_loss: -0.06956468522548676
        total_loss: -0.06422962248325348
        vf_explained_var: 0.9602144956588745
        vf_loss: 3.477211794233881e-05
    load_time_ms: 0.93
    num_steps_sampled: 182250
    num_steps_trained: 182250
    sample_time_ms: 1625.635
    update_time_ms: 3.708
  iterations_since_restore: 810
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.1
    ram_util_percent: 78.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.715360693250068
    mean_inference_ms: 0.7619375827104939
    mean_processing_ms: 0.5383106459397651
  time_since_restore: 1368.5140042304993
  time_this_iter_s: 1.5999503135681152
  time_total_s: 1368.5140042304993
  timestamp: 1744207596
  timesteps_since_restore: 182250
  timesteps_this_iter: 225
  timesteps_total: 182250
  training_iteration: 810
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    810 |          1368.51 |      182250 | 0.107755 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-06-42
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.11660030182260663
  episode_reward_mean: 0.10682545623780688
  episode_reward_min: 0.09225427392625518
  episodes_this_iter: 5
  episodes_total: 4065
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.553
    learner:
      default_policy:
        cur_kl_coeff: 0.1954669952392578
        cur_lr: 4.999999873689376e-05
        entropy: 11.350168228149414
        entropy_coeff: 0.0
        kl: 0.036631856113672256
        policy_loss: -0.0760703906416893
        total_loss: -0.06887988746166229
        vf_explained_var: 0.9667264223098755
        vf_loss: 3.0193728889571503e-05
    load_time_ms: 0.923
    num_steps_sampled: 182925
    num_steps_trained: 182925
    sample_time_ms: 1622.377
    update_time_ms: 3.757
  iterations_since_restore: 813
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.26666666666667
    ram_util_percent: 78.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.717092272182701
    mean_inference_ms: 0.7621361155691728
    mean_processing_ms: 0.5384773886707045
  time_since_restore: 1373.895676612854
  time_this_iter_s: 1.7349395751953125
  time_total_s: 1373.895676612854
  timestamp: 1744207602
  timesteps_since_restore: 182925
  timesteps_this_iter: 225
  timesteps_total: 182925
  training_iteration: 813
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    813 |           1373.9 |      182925 | 0.106825 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-06-47
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.11541933483380319
  episode_reward_mean: 0.10604828194951986
  episode_reward_min: 0.09225427392625518
  episodes_this_iter: 5
  episodes_total: 4080
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 93.45
    learner:
      default_policy:
        cur_kl_coeff: 0.2932004928588867
        cur_lr: 4.999999873689376e-05
        entropy: 11.0222749710083
        entropy_coeff: 0.0
        kl: 0.01885896734893322
        policy_loss: -0.06746706366539001
        total_loss: -0.06191746145486832
        vf_explained_var: 0.977429211139679
        vf_loss: 2.0149916963418946e-05
    load_time_ms: 0.981
    num_steps_sampled: 183600
    num_steps_trained: 183600
    sample_time_ms: 1628.339
    update_time_ms: 3.81
  iterations_since_restore: 816
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.950000000000003
    ram_util_percent: 78.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.718514486105658
    mean_inference_ms: 0.7622796520205637
    mean_processing_ms: 0.5386219697669113
  time_since_restore: 1378.9603896141052
  time_this_iter_s: 1.5898370742797852
  time_total_s: 1378.9603896141052
  timestamp: 1744207607
  timesteps_since_restore: 183600
  timesteps_this_iter: 225
  timesteps_total: 183600
  training_iteration: 816
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    816 |          1378.96 |      183600 | 0.106048 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-06-52
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.11541933483380319
  episode_reward_mean: 0.10535316015136051
  episode_reward_min: 0.09225427392625518
  episodes_this_iter: 5
  episodes_total: 4095
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 94.861
    learner:
      default_policy:
        cur_kl_coeff: 0.2932004928588867
        cur_lr: 4.999999873689376e-05
        entropy: 10.99702262878418
        entropy_coeff: 0.0
        kl: 0.028501074761152267
        policy_loss: -0.0719010978937149
        total_loss: -0.0635189637541771
        vf_explained_var: 0.9700833559036255
        vf_loss: 2.5601122615626082e-05
    load_time_ms: 1.022
    num_steps_sampled: 184275
    num_steps_trained: 184275
    sample_time_ms: 1619.314
    update_time_ms: 3.825
  iterations_since_restore: 819
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.75
    ram_util_percent: 78.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.719407739118563
    mean_inference_ms: 0.7623131622553249
    mean_processing_ms: 0.5387197316130744
  time_since_restore: 1384.1381084918976
  time_this_iter_s: 1.7034475803375244
  time_total_s: 1384.1381084918976
  timestamp: 1744207612
  timesteps_since_restore: 184275
  timesteps_this_iter: 225
  timesteps_total: 184275
  training_iteration: 819
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    819 |          1384.14 |      184275 | 0.105353 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-06-57
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.11541933483380319
  episode_reward_mean: 0.10485247051539762
  episode_reward_min: 0.09225427392625518
  episodes_this_iter: 5
  episodes_total: 4110
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 94.589
    learner:
      default_policy:
        cur_kl_coeff: 0.2932004928588867
        cur_lr: 4.999999873689376e-05
        entropy: 10.667628288269043
        entropy_coeff: 0.0
        kl: 0.04166632145643234
        policy_loss: -0.09175100922584534
        total_loss: -0.07951044291257858
        vf_explained_var: 0.9745896458625793
        vf_loss: 2.3979921024874784e-05
    load_time_ms: 1.044
    num_steps_sampled: 184950
    num_steps_trained: 184950
    sample_time_ms: 1649.484
    update_time_ms: 3.884
  iterations_since_restore: 822
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.4
    ram_util_percent: 78.05
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.720205432371738
    mean_inference_ms: 0.7623169323500689
    mean_processing_ms: 0.5388104648209507
  time_since_restore: 1389.6848106384277
  time_this_iter_s: 1.8672776222229004
  time_total_s: 1389.6848106384277
  timestamp: 1744207617
  timesteps_since_restore: 184950
  timesteps_this_iter: 225
  timesteps_total: 184950
  training_iteration: 822
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    822 |          1389.68 |      184950 | 0.104852 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-07-03
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.11477604674840848
  episode_reward_mean: 0.10425588799905038
  episode_reward_min: 0.09225427392625518
  episodes_this_iter: 5
  episodes_total: 4125
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 92.798
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 10.778951644897461
        entropy_coeff: 0.0
        kl: 0.02255631610751152
        policy_loss: -0.06917144358158112
        total_loss: -0.059227727353572845
        vf_explained_var: 0.9734317064285278
        vf_loss: 2.342237530683633e-05
    load_time_ms: 1.078
    num_steps_sampled: 185625
    num_steps_trained: 185625
    sample_time_ms: 1652.156
    update_time_ms: 3.917
  iterations_since_restore: 825
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.53333333333333
    ram_util_percent: 78.03333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.721020092035975
    mean_inference_ms: 0.7623295417378583
    mean_processing_ms: 0.5389035597063115
  time_since_restore: 1394.9025671482086
  time_this_iter_s: 1.6773204803466797
  time_total_s: 1394.9025671482086
  timestamp: 1744207623
  timesteps_since_restore: 185625
  timesteps_this_iter: 225
  timesteps_total: 185625
  training_iteration: 825
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    825 |           1394.9 |      185625 | 0.104256 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-07-08
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.11389818408472877
  episode_reward_mean: 0.10355748060521501
  episode_reward_min: 0.08692227144809046
  episodes_this_iter: 5
  episodes_total: 4140
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 94.603
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 10.204334259033203
        entropy_coeff: 0.0
        kl: 0.019633889198303223
        policy_loss: -0.06843292713165283
        total_loss: -0.0597720742225647
        vf_explained_var: 0.970714271068573
        vf_loss: 2.5856115826172754e-05
    load_time_ms: 1.086
    num_steps_sampled: 186300
    num_steps_trained: 186300
    sample_time_ms: 1679.349
    update_time_ms: 3.865
  iterations_since_restore: 828
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.5
    ram_util_percent: 78.1
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.721938539737988
    mean_inference_ms: 0.7623518004833909
    mean_processing_ms: 0.5390177377998454
  time_since_restore: 1400.2577714920044
  time_this_iter_s: 1.7377829551696777
  time_total_s: 1400.2577714920044
  timestamp: 1744207628
  timesteps_since_restore: 186300
  timesteps_this_iter: 225
  timesteps_total: 186300
  training_iteration: 828
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    828 |          1400.26 |      186300 | 0.103557 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-07-15
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.11389818408472877
  episode_reward_mean: 0.10277791818210825
  episode_reward_min: 0.08692227144809046
  episodes_this_iter: 5
  episodes_total: 4160
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 92.697
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 10.956289291381836
        entropy_coeff: 0.0
        kl: 0.017635401338338852
        policy_loss: -0.07436838001012802
        total_loss: -0.06657688319683075
        vf_explained_var: 0.9557448625564575
        vf_loss: 3.5432425647741184e-05
    load_time_ms: 1.047
    num_steps_sampled: 187200
    num_steps_trained: 187200
    sample_time_ms: 1603.878
    update_time_ms: 3.728
  iterations_since_restore: 832
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.233333333333334
    ram_util_percent: 78.16666666666667
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.722872160441735
    mean_inference_ms: 0.762370296699533
    mean_processing_ms: 0.5391629939854858
  time_since_restore: 1406.73282456398
  time_this_iter_s: 1.6908609867095947
  time_total_s: 1406.73282456398
  timestamp: 1744207635
  timesteps_since_restore: 187200
  timesteps_this_iter: 225
  timesteps_total: 187200
  training_iteration: 832
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    832 |          1406.73 |      187200 | 0.102778 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-07-20
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.11284940953766874
  episode_reward_mean: 0.10187502341469763
  episode_reward_min: 0.08692227144809046
  episodes_this_iter: 5
  episodes_total: 4175
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.386
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 9.843896865844727
        entropy_coeff: 0.0
        kl: 0.024074072018265724
        policy_loss: -0.0782628282904625
        total_loss: -0.06766240298748016
        vf_explained_var: 0.9857565760612488
        vf_loss: 1.2644051821553148e-05
    load_time_ms: 1.03
    num_steps_sampled: 187875
    num_steps_trained: 187875
    sample_time_ms: 1590.683
    update_time_ms: 3.619
  iterations_since_restore: 835
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.5
    ram_util_percent: 77.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.7234604929565736
    mean_inference_ms: 0.7623696825480875
    mean_processing_ms: 0.5392818743664941
  time_since_restore: 1411.8040509223938
  time_this_iter_s: 1.544100046157837
  time_total_s: 1411.8040509223938
  timestamp: 1744207640
  timesteps_since_restore: 187875
  timesteps_this_iter: 225
  timesteps_total: 187875
  training_iteration: 835
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    835 |           1411.8 |      187875 | 0.101875 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-07-26
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.11167643969122505
  episode_reward_mean: 0.10098660857833104
  episode_reward_min: 0.08692227144809046
  episodes_this_iter: 5
  episodes_total: 4195
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 85.471
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 10.262492179870605
        entropy_coeff: 0.0
        kl: 0.02037632465362549
        policy_loss: -0.07287940382957458
        total_loss: -0.06389652192592621
        vf_explained_var: 0.9734934568405151
        vf_loss: 2.1359297534218058e-05
    load_time_ms: 0.971
    num_steps_sampled: 188775
    num_steps_trained: 188775
    sample_time_ms: 1566.692
    update_time_ms: 3.445
  iterations_since_restore: 839
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.05
    ram_util_percent: 77.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.724064107582798
    mean_inference_ms: 0.7623350266958984
    mean_processing_ms: 0.5393985961275464
  time_since_restore: 1418.4355773925781
  time_this_iter_s: 1.7725138664245605
  time_total_s: 1418.4355773925781
  timestamp: 1744207646
  timesteps_since_restore: 188775
  timesteps_this_iter: 225
  timesteps_total: 188775
  training_iteration: 839
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    839 |          1418.44 |      188775 | 0.100987 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-07-31
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.11083446698485058
  episode_reward_mean: 0.10045610168879895
  episode_reward_min: 0.08692227144809046
  episodes_this_iter: 5
  episodes_total: 4210
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 85.858
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 10.652363777160645
        entropy_coeff: 0.0
        kl: 0.025157000869512558
        policy_loss: -0.08766025304794312
        total_loss: -0.07657445967197418
        vf_explained_var: 0.9742552042007446
        vf_loss: 2.172156746382825e-05
    load_time_ms: 0.915
    num_steps_sampled: 189450
    num_steps_trained: 189450
    sample_time_ms: 1593.064
    update_time_ms: 3.486
  iterations_since_restore: 842
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.799999999999997
    ram_util_percent: 77.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.724363786140596
    mean_inference_ms: 0.7622272819503157
    mean_processing_ms: 0.5394638134608846
  time_since_restore: 1423.5969545841217
  time_this_iter_s: 1.5221209526062012
  time_total_s: 1423.5969545841217
  timestamp: 1744207651
  timesteps_since_restore: 189450
  timesteps_this_iter: 225
  timesteps_total: 189450
  training_iteration: 842
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    842 |           1423.6 |      189450 | 0.100456 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-07-37
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.11150034827711511
  episode_reward_mean: 0.10040240662942461
  episode_reward_min: 0.08692227144809046
  episodes_this_iter: 5
  episodes_total: 4225
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 85.94
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 10.454058647155762
        entropy_coeff: 0.0
        kl: 0.02917255088686943
        policy_loss: -0.10119035094976425
        total_loss: -0.0883328914642334
        vf_explained_var: 0.9657676815986633
        vf_loss: 2.7331774617778137e-05
    load_time_ms: 0.888
    num_steps_sampled: 190125
    num_steps_trained: 190125
    sample_time_ms: 1597.44
    update_time_ms: 3.421
  iterations_since_restore: 845
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.65
    ram_util_percent: 77.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.7246934335193576
    mean_inference_ms: 0.7621001090311361
    mean_processing_ms: 0.5395319325652117
  time_since_restore: 1428.7116386890411
  time_this_iter_s: 1.5521810054779053
  time_total_s: 1428.7116386890411
  timestamp: 1744207657
  timesteps_since_restore: 190125
  timesteps_this_iter: 225
  timesteps_total: 190125
  training_iteration: 845
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    845 |          1428.71 |      190125 | 0.100402 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-07-43
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.11150034827711511
  episode_reward_mean: 0.10066867461811872
  episode_reward_min: 0.08923930478083845
  episodes_this_iter: 5
  episodes_total: 4245
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 87.031
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 9.747608184814453
        entropy_coeff: 0.0
        kl: 0.02090974524617195
        policy_loss: -0.06860911846160889
        total_loss: -0.05938608571887016
        vf_explained_var: 0.9678533673286438
        vf_loss: 2.69150532403728e-05
    load_time_ms: 0.969
    num_steps_sampled: 191025
    num_steps_trained: 191025
    sample_time_ms: 1554.751
    update_time_ms: 3.59
  iterations_since_restore: 849
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.799999999999997
    ram_util_percent: 77.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.724535142945578
    mean_inference_ms: 0.7618443677637255
    mean_processing_ms: 0.53954696292951
  time_since_restore: 1434.929913520813
  time_this_iter_s: 1.6127707958221436
  time_total_s: 1434.929913520813
  timestamp: 1744207663
  timesteps_since_restore: 191025
  timesteps_this_iter: 225
  timesteps_total: 191025
  training_iteration: 849
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    849 |          1434.93 |      191025 | 0.100669 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-07-48
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.11150034827711511
  episode_reward_mean: 0.10040070014902858
  episode_reward_min: 0.08849605743690306
  episodes_this_iter: 5
  episodes_total: 4260
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 86.899
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 10.141912460327148
        entropy_coeff: 0.0
        kl: 0.022445445880293846
        policy_loss: -0.07794132083654404
        total_loss: -0.06804574280977249
        vf_explained_var: 0.9706947207450867
        vf_loss: 2.4049604689935222e-05
    load_time_ms: 0.976
    num_steps_sampled: 191700
    num_steps_trained: 191700
    sample_time_ms: 1542.163
    update_time_ms: 3.701
  iterations_since_restore: 852
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.2
    ram_util_percent: 77.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.724429894688578
    mean_inference_ms: 0.7616368692582065
    mean_processing_ms: 0.5395296028290996
  time_since_restore: 1439.966163635254
  time_this_iter_s: 1.5759303569793701
  time_total_s: 1439.966163635254
  timestamp: 1744207668
  timesteps_since_restore: 191700
  timesteps_this_iter: 225
  timesteps_total: 191700
  training_iteration: 852
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    852 |          1439.97 |      191700 | 0.100401 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-07-54
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.11150034827711511
  episode_reward_mean: 0.10053942653165698
  episode_reward_min: 0.08849605743690306
  episodes_this_iter: 5
  episodes_total: 4275
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.646
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 10.277446746826172
        entropy_coeff: 0.0
        kl: 0.015412201173603535
        policy_loss: -0.06147276237607002
        total_loss: -0.05467245727777481
        vf_explained_var: 0.9734300374984741
        vf_loss: 2.2008644009474665e-05
    load_time_ms: 0.948
    num_steps_sampled: 192375
    num_steps_trained: 192375
    sample_time_ms: 1591.157
    update_time_ms: 3.784
  iterations_since_restore: 855
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.833333333333332
    ram_util_percent: 78.23333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.724487399402071
    mean_inference_ms: 0.761430913221099
    mean_processing_ms: 0.5395038676840533
  time_since_restore: 1445.6102213859558
  time_this_iter_s: 2.076643228530884
  time_total_s: 1445.6102213859558
  timestamp: 1744207674
  timesteps_since_restore: 192375
  timesteps_this_iter: 225
  timesteps_total: 192375
  training_iteration: 855
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    855 |          1445.61 |      192375 | 0.100539 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-08-00
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.11150034827711511
  episode_reward_mean: 0.10029303354147036
  episode_reward_min: 0.08849605743690306
  episodes_this_iter: 5
  episodes_total: 4290
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 95.26
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 10.604985237121582
        entropy_coeff: 0.0
        kl: 0.02098998799920082
        policy_loss: -0.07895858585834503
        total_loss: -0.06971241533756256
        vf_explained_var: 0.9819877743721008
        vf_loss: 1.4759466466784943e-05
    load_time_ms: 0.975
    num_steps_sampled: 193050
    num_steps_trained: 193050
    sample_time_ms: 1715.961
    update_time_ms: 4.025
  iterations_since_restore: 858
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.633333333333336
    ram_util_percent: 78.2
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.725324441077434
    mean_inference_ms: 0.7613443338652602
    mean_processing_ms: 0.5395636489354221
  time_since_restore: 1451.5140261650085
  time_this_iter_s: 1.7998325824737549
  time_total_s: 1451.5140261650085
  timestamp: 1744207680
  timesteps_since_restore: 193050
  timesteps_this_iter: 225
  timesteps_total: 193050
  training_iteration: 858
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    858 |          1451.51 |      193050 | 0.100293 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-08-06
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.11150034827711511
  episode_reward_mean: 0.10024759809893247
  episode_reward_min: 0.08849605743690306
  episodes_this_iter: 5
  episodes_total: 4305
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 107.896
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 9.585975646972656
        entropy_coeff: 0.0
        kl: 0.023643286898732185
        policy_loss: -0.07773852348327637
        total_loss: -0.06732065975666046
        vf_explained_var: 0.9752527475357056
        vf_loss: 1.9532779333530925e-05
    load_time_ms: 1.034
    num_steps_sampled: 193725
    num_steps_trained: 193725
    sample_time_ms: 1801.479
    update_time_ms: 4.287
  iterations_since_restore: 861
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 38.625
    ram_util_percent: 78.25
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.726327284205456
    mean_inference_ms: 0.7613282664351948
    mean_processing_ms: 0.5396422596040482
  time_since_restore: 1457.574999332428
  time_this_iter_s: 2.450430393218994
  time_total_s: 1457.574999332428
  timestamp: 1744207686
  timesteps_since_restore: 193725
  timesteps_this_iter: 225
  timesteps_total: 193725
  training_iteration: 861
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    861 |          1457.57 |      193725 | 0.100248 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-08-12
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.11141114829429209
  episode_reward_mean: 0.10009954590472475
  episode_reward_min: 0.08849605743690306
  episodes_this_iter: 5
  episodes_total: 4320
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 107.828
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 9.236505508422852
        entropy_coeff: 0.0
        kl: 0.023227935656905174
        policy_loss: -0.07289648056030273
        total_loss: -0.06266681104898453
        vf_explained_var: 0.9836888313293457
        vf_loss: 1.3998183021612931e-05
    load_time_ms: 1.115
    num_steps_sampled: 194400
    num_steps_trained: 194400
    sample_time_ms: 1900.325
    update_time_ms: 4.399
  iterations_since_restore: 864
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.1
    ram_util_percent: 78.6
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.727904274532903
    mean_inference_ms: 0.761429126599873
    mean_processing_ms: 0.5397980141571692
  time_since_restore: 1463.7083411216736
  time_this_iter_s: 1.7002387046813965
  time_total_s: 1463.7083411216736
  timestamp: 1744207692
  timesteps_since_restore: 194400
  timesteps_this_iter: 225
  timesteps_total: 194400
  training_iteration: 864
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    864 |          1463.71 |      194400 |   0.1001 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-08-17
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.11121133287442149
  episode_reward_mean: 0.09947139351179252
  episode_reward_min: 0.08849605743690306
  episodes_this_iter: 5
  episodes_total: 4335
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 100.101
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 9.49034309387207
        entropy_coeff: 0.0
        kl: 0.020897570997476578
        policy_loss: -0.07683201134204865
        total_loss: -0.06762738525867462
        vf_explained_var: 0.9822540283203125
        vf_loss: 1.385010818921728e-05
    load_time_ms: 1.086
    num_steps_sampled: 195075
    num_steps_trained: 195075
    sample_time_ms: 1846.027
    update_time_ms: 4.153
  iterations_since_restore: 867
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.799999999999997
    ram_util_percent: 78.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.730156108448166
    mean_inference_ms: 0.7616330499937576
    mean_processing_ms: 0.5400396999008313
  time_since_restore: 1469.2648375034332
  time_this_iter_s: 1.5929841995239258
  time_total_s: 1469.2648375034332
  timestamp: 1744207697
  timesteps_since_restore: 195075
  timesteps_this_iter: 225
  timesteps_total: 195075
  training_iteration: 867
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    867 |          1469.26 |      195075 | 0.0994714 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-08-22
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.10668435880671233
  episode_reward_mean: 0.09871838076326485
  episode_reward_min: 0.084145809028405
  episodes_this_iter: 5
  episodes_total: 4350
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 93.399
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 9.65444564819336
        entropy_coeff: 0.0
        kl: 0.020884357392787933
        policy_loss: -0.0736270472407341
        total_loss: -0.06442157924175262
        vf_explained_var: 0.9736881256103516
        vf_loss: 2.0528294044197537e-05
    load_time_ms: 1.083
    num_steps_sampled: 195750
    num_steps_trained: 195750
    sample_time_ms: 1816.808
    update_time_ms: 4.033
  iterations_since_restore: 870
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.3
    ram_util_percent: 78.8
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.732696296020139
    mean_inference_ms: 0.7618643862939452
    mean_processing_ms: 0.5403076468208322
  time_since_restore: 1474.3123137950897
  time_this_iter_s: 1.6119022369384766
  time_total_s: 1474.3123137950897
  timestamp: 1744207702
  timesteps_since_restore: 195750
  timesteps_this_iter: 225
  timesteps_total: 195750
  training_iteration: 870
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    870 |          1474.31 |      195750 | 0.0987184 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-08-29
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.10612975771443352
  episode_reward_mean: 0.09756603044873582
  episode_reward_min: 0.084145809028405
  episodes_this_iter: 5
  episodes_total: 4370
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 85.845
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 9.475318908691406
        entropy_coeff: 0.0
        kl: 0.02866864763200283
        policy_loss: -0.0843442976474762
        total_loss: -0.0717141181230545
        vf_explained_var: 0.9707172513008118
        vf_loss: 2.167790626117494e-05
    load_time_ms: 0.943
    num_steps_sampled: 196650
    num_steps_trained: 196650
    sample_time_ms: 1611.431
    update_time_ms: 3.909
  iterations_since_restore: 874
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.033333333333335
    ram_util_percent: 78.76666666666667
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.735664931663303
    mean_inference_ms: 0.7621474283111479
    mean_processing_ms: 0.5406487897704748
  time_since_restore: 1480.7624530792236
  time_this_iter_s: 1.781972885131836
  time_total_s: 1480.7624530792236
  timestamp: 1744207709
  timesteps_since_restore: 196650
  timesteps_this_iter: 225
  timesteps_total: 196650
  training_iteration: 874
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    874 |          1480.76 |      196650 | 0.097566 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-08-34
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.10612975771443352
  episode_reward_mean: 0.09631876790120458
  episode_reward_min: 0.08370843327964252
  episodes_this_iter: 5
  episodes_total: 4385
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 87.219
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 8.50706672668457
        entropy_coeff: 0.0
        kl: 0.02013218402862549
        policy_loss: -0.0783545970916748
        total_loss: -0.06948301941156387
        vf_explained_var: 0.9762774705886841
        vf_loss: 1.743649954732973e-05
    load_time_ms: 0.942
    num_steps_sampled: 197325
    num_steps_trained: 197325
    sample_time_ms: 1564.153
    update_time_ms: 3.766
  iterations_since_restore: 877
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.25
    ram_util_percent: 78.8
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.737322719612255
    mean_inference_ms: 0.762262585569799
    mean_processing_ms: 0.5408345436270593
  time_since_restore: 1485.8587975502014
  time_this_iter_s: 1.7364702224731445
  time_total_s: 1485.8587975502014
  timestamp: 1744207714
  timesteps_since_restore: 197325
  timesteps_this_iter: 225
  timesteps_total: 197325
  training_iteration: 877
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    877 |          1485.86 |      197325 | 0.0963188 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-08-40
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.10612975771443352
  episode_reward_mean: 0.09597925645095444
  episode_reward_min: 0.08370843327964252
  episodes_this_iter: 5
  episodes_total: 4400
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 88.018
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 9.760628700256348
        entropy_coeff: 0.0
        kl: 0.017267290502786636
        policy_loss: -0.061515532433986664
        total_loss: -0.05390208959579468
        vf_explained_var: 0.9729524850845337
        vf_loss: 1.9271663404651918e-05
    load_time_ms: 0.91
    num_steps_sampled: 198000
    num_steps_trained: 198000
    sample_time_ms: 1651.809
    update_time_ms: 3.684
  iterations_since_restore: 880
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.900000000000002
    ram_util_percent: 78.8
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.739109702125326
    mean_inference_ms: 0.762413725285735
    mean_processing_ms: 0.541034761015004
  time_since_restore: 1491.7892973423004
  time_this_iter_s: 1.8483788967132568
  time_total_s: 1491.7892973423004
  timestamp: 1744207720
  timesteps_since_restore: 198000
  timesteps_this_iter: 225
  timesteps_total: 198000
  training_iteration: 880
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    880 |          1491.79 |      198000 | 0.0959793 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-08-46
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.10612975771443352
  episode_reward_mean: 0.09508285276067154
  episode_reward_min: 0.08370843327964252
  episodes_this_iter: 5
  episodes_total: 4415
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.72
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 9.090193748474121
        entropy_coeff: 0.0
        kl: 0.019641870632767677
        policy_loss: -0.07238583266735077
        total_loss: -0.06370918452739716
        vf_explained_var: 0.9482693672180176
        vf_loss: 3.813636794802733e-05
    load_time_ms: 0.958
    num_steps_sampled: 198675
    num_steps_trained: 198675
    sample_time_ms: 1750.867
    update_time_ms: 3.816
  iterations_since_restore: 883
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.099999999999998
    ram_util_percent: 78.8
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.740522566282068
    mean_inference_ms: 0.76249996429731
    mean_processing_ms: 0.5411855275247286
  time_since_restore: 1497.4668500423431
  time_this_iter_s: 1.9165470600128174
  time_total_s: 1497.4668500423431
  timestamp: 1744207726
  timesteps_since_restore: 198675
  timesteps_this_iter: 225
  timesteps_total: 198675
  training_iteration: 883
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    883 |          1497.47 |      198675 | 0.0950829 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-08-51
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.10542460702622022
  episode_reward_mean: 0.09417477864367664
  episode_reward_min: 0.08342655369319565
  episodes_this_iter: 5
  episodes_total: 4430
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.402
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 9.252171516418457
        entropy_coeff: 0.0
        kl: 0.027147527784109116
        policy_loss: -0.09235857427120209
        total_loss: -0.08039918541908264
        vf_explained_var: 0.9719395637512207
        vf_loss: 1.9880526451743208e-05
    load_time_ms: 1.003
    num_steps_sampled: 199350
    num_steps_trained: 199350
    sample_time_ms: 1795.466
    update_time_ms: 4.054
  iterations_since_restore: 886
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.833333333333332
    ram_util_percent: 78.76666666666667
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.741570519610659
    mean_inference_ms: 0.7625445624277686
    mean_processing_ms: 0.5412848206499661
  time_since_restore: 1503.0553543567657
  time_this_iter_s: 2.084421157836914
  time_total_s: 1503.0553543567657
  timestamp: 1744207731
  timesteps_since_restore: 199350
  timesteps_this_iter: 225
  timesteps_total: 199350
  training_iteration: 886
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    886 |          1503.06 |      199350 | 0.0941748 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-08-57
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.10542460702622022
  episode_reward_mean: 0.0935316074693268
  episode_reward_min: 0.08342655369319565
  episodes_this_iter: 5
  episodes_total: 4445
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 94.379
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 9.21568489074707
        entropy_coeff: 0.0
        kl: 0.019723843783140182
        policy_loss: -0.07335273921489716
        total_loss: -0.06466086953878403
        vf_explained_var: 0.9764809608459473
        vf_loss: 1.730943040456623e-05
    load_time_ms: 1.082
    num_steps_sampled: 200025
    num_steps_trained: 200025
    sample_time_ms: 1798.876
    update_time_ms: 4.278
  iterations_since_restore: 889
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.45
    ram_util_percent: 78.8
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.743076395906221
    mean_inference_ms: 0.7626729947135353
    mean_processing_ms: 0.5414367330109121
  time_since_restore: 1508.9633343219757
  time_this_iter_s: 1.6904361248016357
  time_total_s: 1508.9633343219757
  timestamp: 1744207737
  timesteps_since_restore: 200025
  timesteps_this_iter: 225
  timesteps_total: 200025
  training_iteration: 889
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    889 |          1508.96 |      200025 | 0.0935316 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-09-03
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.10542460702622022
  episode_reward_mean: 0.09321944011607214
  episode_reward_min: 0.08342655369319565
  episodes_this_iter: 5
  episodes_total: 4460
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 97.947
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 8.724993705749512
        entropy_coeff: 0.0
        kl: 0.025649016723036766
        policy_loss: -0.08961185067892075
        total_loss: -0.07830958068370819
        vf_explained_var: 0.966147780418396
        vf_loss: 2.1820005713379942e-05
    load_time_ms: 1.06
    num_steps_sampled: 200700
    num_steps_trained: 200700
    sample_time_ms: 1795.018
    update_time_ms: 4.341
  iterations_since_restore: 892
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.45
    ram_util_percent: 78.85
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.744956657909966
    mean_inference_ms: 0.762866374616451
    mean_processing_ms: 0.5416265072605548
  time_since_restore: 1514.5699870586395
  time_this_iter_s: 1.7761363983154297
  time_total_s: 1514.5699870586395
  timestamp: 1744207743
  timesteps_since_restore: 200700
  timesteps_this_iter: 225
  timesteps_total: 200700
  training_iteration: 892
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    892 |          1514.57 |      200700 | 0.0932194 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-09-09
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.10542460702622022
  episode_reward_mean: 0.09251759920916015
  episode_reward_min: 0.08197383033304388
  episodes_this_iter: 5
  episodes_total: 4475
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 99.719
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 8.972105979919434
        entropy_coeff: 0.0
        kl: 0.022392164915800095
        policy_loss: -0.07923517376184464
        total_loss: -0.0693625882267952
        vf_explained_var: 0.9651015400886536
        vf_loss: 2.44891743932385e-05
    load_time_ms: 0.995
    num_steps_sampled: 201375
    num_steps_trained: 201375
    sample_time_ms: 1831.439
    update_time_ms: 4.467
  iterations_since_restore: 895
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.35
    ram_util_percent: 78.95
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.74737195471174
    mean_inference_ms: 0.7631544910409067
    mean_processing_ms: 0.5418902212082856
  time_since_restore: 1520.3724670410156
  time_this_iter_s: 1.74118971824646
  time_total_s: 1520.3724670410156
  timestamp: 1744207749
  timesteps_since_restore: 201375
  timesteps_this_iter: 225
  timesteps_total: 201375
  training_iteration: 895
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    895 |          1520.37 |      201375 | 0.0925176 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-09-14
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.10542460702622022
  episode_reward_mean: 0.09252637418107375
  episode_reward_min: 0.08163829705738754
  episodes_this_iter: 5
  episodes_total: 4490
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 95.76
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 8.549494743347168
        entropy_coeff: 0.0
        kl: 0.024949800223112106
        policy_loss: -0.08083164691925049
        total_loss: -0.06983251869678497
        vf_explained_var: 0.9632978439331055
        vf_loss: 2.616983874759171e-05
    load_time_ms: 1.006
    num_steps_sampled: 202050
    num_steps_trained: 202050
    sample_time_ms: 1743.302
    update_time_ms: 4.421
  iterations_since_restore: 898
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.0
    ram_util_percent: 79.23333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.749741498005185
    mean_inference_ms: 0.7634407190518527
    mean_processing_ms: 0.5421567386793167
  time_since_restore: 1525.7526953220367
  time_this_iter_s: 2.232999801635742
  time_total_s: 1525.7526953220367
  timestamp: 1744207754
  timesteps_since_restore: 202050
  timesteps_this_iter: 225
  timesteps_total: 202050
  training_iteration: 898
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.2/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    898 |          1525.75 |      202050 | 0.0925264 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-09-21
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.10542460702622022
  episode_reward_mean: 0.09126828109911593
  episode_reward_min: 0.08163829705738754
  episodes_this_iter: 5
  episodes_total: 4505
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 103.53
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 8.287939071655273
        entropy_coeff: 0.0
        kl: 0.021710220724344254
        policy_loss: -0.0689006894826889
        total_loss: -0.05933515354990959
        vf_explained_var: 0.9744507670402527
        vf_loss: 1.735646219458431e-05
    load_time_ms: 1.056
    num_steps_sampled: 202725
    num_steps_trained: 202725
    sample_time_ms: 1858.963
    update_time_ms: 4.182
  iterations_since_restore: 901
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.866666666666664
    ram_util_percent: 78.93333333333334
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.752531300066494
    mean_inference_ms: 0.7637885888286422
    mean_processing_ms: 0.5424618009004625
  time_since_restore: 1532.5072915554047
  time_this_iter_s: 2.108119010925293
  time_total_s: 1532.5072915554047
  timestamp: 1744207761
  timesteps_since_restore: 202725
  timesteps_this_iter: 225
  timesteps_total: 202725
  training_iteration: 901
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    901 |          1532.51 |      202725 | 0.0912683 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-09-26
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.10071346017842069
  episode_reward_mean: 0.09037416433406585
  episode_reward_min: 0.07852578329303839
  episodes_this_iter: 5
  episodes_total: 4520
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 101.211
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 8.291986465454102
        entropy_coeff: 0.0
        kl: 0.023586886003613472
        policy_loss: -0.07472677528858185
        total_loss: -0.06433633714914322
        vf_explained_var: 0.9745460748672485
        vf_loss: 1.6917221728363074e-05
    load_time_ms: 1.076
    num_steps_sampled: 203400
    num_steps_trained: 203400
    sample_time_ms: 1826.762
    update_time_ms: 4.054
  iterations_since_restore: 904
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.833333333333332
    ram_util_percent: 78.8
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.755375558165191
    mean_inference_ms: 0.7641649131734739
    mean_processing_ms: 0.5427748123056971
  time_since_restore: 1537.9986219406128
  time_this_iter_s: 1.7485830783843994
  time_total_s: 1537.9986219406128
  timestamp: 1744207766
  timesteps_since_restore: 203400
  timesteps_this_iter: 225
  timesteps_total: 203400
  training_iteration: 904
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    904 |             1538 |      203400 | 0.0903742 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-09-33
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.10091398401916556
  episode_reward_mean: 0.09025459235038755
  episode_reward_min: 0.07852578329303839
  episodes_this_iter: 5
  episodes_total: 4540
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 98.319
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 9.115299224853516
        entropy_coeff: 0.0
        kl: 0.021250855177640915
        policy_loss: -0.07328610122203827
        total_loss: -0.06391282379627228
        vf_explained_var: 0.9597147107124329
        vf_loss: 2.7128440706292167e-05
    load_time_ms: 0.975
    num_steps_sampled: 204300
    num_steps_trained: 204300
    sample_time_ms: 1737.057
    update_time_ms: 3.92
  iterations_since_restore: 908
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.566666666666666
    ram_util_percent: 78.6
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.758326942927601
    mean_inference_ms: 0.764538932543339
    mean_processing_ms: 0.5431029130083654
  time_since_restore: 1544.1899383068085
  time_this_iter_s: 1.5277783870697021
  time_total_s: 1544.1899383068085
  timestamp: 1744207773
  timesteps_since_restore: 204300
  timesteps_this_iter: 225
  timesteps_total: 204300
  training_iteration: 908
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    908 |          1544.19 |      204300 | 0.0902546 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-09-38
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.10091398401916556
  episode_reward_mean: 0.08925208371913985
  episode_reward_min: 0.07852578329303839
  episodes_this_iter: 5
  episodes_total: 4555
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 87.209
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 8.440458297729492
        entropy_coeff: 0.0
        kl: 0.019833678379654884
        policy_loss: -0.0641627162694931
        total_loss: -0.05542489141225815
        vf_explained_var: 0.9768775701522827
        vf_loss: 1.4946240298741031e-05
    load_time_ms: 0.909
    num_steps_sampled: 204975
    num_steps_trained: 204975
    sample_time_ms: 1595.039
    update_time_ms: 3.672
  iterations_since_restore: 911
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.099999999999998
    ram_util_percent: 78.66666666666667
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.75998276142297
    mean_inference_ms: 0.7647295302586202
    mean_processing_ms: 0.543278020323202
  time_since_restore: 1549.4083199501038
  time_this_iter_s: 1.9172496795654297
  time_total_s: 1549.4083199501038
  timestamp: 1744207778
  timesteps_since_restore: 204975
  timesteps_this_iter: 225
  timesteps_total: 204975
  training_iteration: 911
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    911 |          1549.41 |      204975 | 0.0892521 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-09-43
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.10091398401916556
  episode_reward_mean: 0.08854672941645043
  episode_reward_min: 0.07852578329303839
  episodes_this_iter: 5
  episodes_total: 4570
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 85.652
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 8.287111282348633
        entropy_coeff: 0.0
        kl: 0.0239186380058527
        policy_loss: -0.07652544975280762
        total_loss: -0.06598974019289017
        vf_explained_var: 0.9747593998908997
        vf_loss: 1.6274907466140576e-05
    load_time_ms: 0.91
    num_steps_sampled: 205650
    num_steps_trained: 205650
    sample_time_ms: 1581.375
    update_time_ms: 3.602
  iterations_since_restore: 914
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 16.9
    ram_util_percent: 78.6
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.761511720045073
    mean_inference_ms: 0.7648953025957296
    mean_processing_ms: 0.5434282423187146
  time_since_restore: 1554.7460322380066
  time_this_iter_s: 1.5706303119659424
  time_total_s: 1554.7460322380066
  timestamp: 1744207783
  timesteps_since_restore: 205650
  timesteps_this_iter: 225
  timesteps_total: 205650
  training_iteration: 914
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    914 |          1554.75 |      205650 | 0.0885467 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-09-50
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.10091398401916556
  episode_reward_mean: 0.08790854056848742
  episode_reward_min: 0.07813863183162462
  episodes_this_iter: 5
  episodes_total: 4585
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 93.616
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 8.402729988098145
        entropy_coeff: 0.0
        kl: 0.026113729923963547
        policy_loss: -0.08716027438640594
        total_loss: -0.07566241174936295
        vf_explained_var: 0.9791930317878723
        vf_loss: 1.3030772606725805e-05
    load_time_ms: 0.989
    num_steps_sampled: 206325
    num_steps_trained: 206325
    sample_time_ms: 1767.552
    update_time_ms: 3.916
  iterations_since_restore: 917
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.049999999999997
    ram_util_percent: 79.15
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.763593243208493
    mean_inference_ms: 0.7651495308327105
    mean_processing_ms: 0.5436266981699626
  time_since_restore: 1561.3581387996674
  time_this_iter_s: 1.7740304470062256
  time_total_s: 1561.3581387996674
  timestamp: 1744207790
  timesteps_since_restore: 206325
  timesteps_this_iter: 225
  timesteps_total: 206325
  training_iteration: 917
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.2/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    917 |          1561.36 |      206325 | 0.0879085 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-09-56
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.10091398401916556
  episode_reward_mean: 0.0873820043915974
  episode_reward_min: 0.07633709602437237
  episodes_this_iter: 5
  episodes_total: 4600
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 99.979
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 8.325885772705078
        entropy_coeff: 0.0
        kl: 0.02664368227124214
        policy_loss: -0.0841321349143982
        total_loss: -0.0724012479186058
        vf_explained_var: 0.9789344668388367
        vf_loss: 1.2988306480110623e-05
    load_time_ms: 1.126
    num_steps_sampled: 207000
    num_steps_trained: 207000
    sample_time_ms: 1884.706
    update_time_ms: 4.084
  iterations_since_restore: 920
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.7
    ram_util_percent: 78.93333333333334
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.765530360350713
    mean_inference_ms: 0.765389404706616
    mean_processing_ms: 0.5438188004268794
  time_since_restore: 1567.4267313480377
  time_this_iter_s: 1.9646942615509033
  time_total_s: 1567.4267313480377
  timestamp: 1744207796
  timesteps_since_restore: 207000
  timesteps_this_iter: 225
  timesteps_total: 207000
  training_iteration: 920
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    920 |          1567.43 |      207000 | 0.087382 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-10-02
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.10091398401916556
  episode_reward_mean: 0.08736828063765145
  episode_reward_min: 0.07633709602437237
  episodes_this_iter: 5
  episodes_total: 4615
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 106.872
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 7.738527774810791
        entropy_coeff: 0.0
        kl: 0.030738115310668945
        policy_loss: -0.0846642479300499
        total_loss: -0.07113175839185715
        vf_explained_var: 0.9777972102165222
        vf_loss: 1.3836312973580789e-05
    load_time_ms: 1.13
    num_steps_sampled: 207675
    num_steps_trained: 207675
    sample_time_ms: 1949.013
    update_time_ms: 4.319
  iterations_since_restore: 923
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.433333333333334
    ram_util_percent: 78.93333333333334
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.767541767243221
    mean_inference_ms: 0.7656306196927986
    mean_processing_ms: 0.5440241412942173
  time_since_restore: 1573.828248500824
  time_this_iter_s: 2.16506290435791
  time_total_s: 1573.828248500824
  timestamp: 1744207802
  timesteps_since_restore: 207675
  timesteps_this_iter: 225
  timesteps_total: 207675
  training_iteration: 923
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    923 |          1573.83 |      207675 | 0.0873683 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-10-09
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.10091398401916556
  episode_reward_mean: 0.08624140588902823
  episode_reward_min: 0.07579961780957144
  episodes_this_iter: 5
  episodes_total: 4630
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 105.802
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 8.007015228271484
        entropy_coeff: 0.0
        kl: 0.024464040994644165
        policy_loss: -0.07470961660146713
        total_loss: -0.06393183022737503
        vf_explained_var: 0.9670793414115906
        vf_loss: 1.848292777140159e-05
    load_time_ms: 1.151
    num_steps_sampled: 208350
    num_steps_trained: 208350
    sample_time_ms: 1931.226
    update_time_ms: 4.498
  iterations_since_restore: 926
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.3
    ram_util_percent: 78.86666666666666
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.770022445010121
    mean_inference_ms: 0.7659341265035099
    mean_processing_ms: 0.5442817697788819
  time_since_restore: 1580.050019979477
  time_this_iter_s: 2.189954996109009
  time_total_s: 1580.050019979477
  timestamp: 1744207809
  timesteps_since_restore: 208350
  timesteps_this_iter: 225
  timesteps_total: 208350
  training_iteration: 926
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    926 |          1580.05 |      208350 | 0.0862414 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-10-15
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.09766495934836047
  episode_reward_mean: 0.08514377233979495
  episode_reward_min: 0.07463205137980147
  episodes_this_iter: 5
  episodes_total: 4645
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 105.436
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 7.991829872131348
        entropy_coeff: 0.0
        kl: 0.01652645505964756
        policy_loss: -0.05845842882990837
        total_loss: -0.05117768794298172
        vf_explained_var: 0.9777719378471375
        vf_loss: 1.2393933502607979e-05
    load_time_ms: 1.083
    num_steps_sampled: 209025
    num_steps_trained: 209025
    sample_time_ms: 1944.87
    update_time_ms: 4.562
  iterations_since_restore: 929
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.2
    ram_util_percent: 78.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.7732386181527895
    mean_inference_ms: 0.7663579447127387
    mean_processing_ms: 0.544656089962784
  time_since_restore: 1586.0613496303558
  time_this_iter_s: 2.205171585083008
  time_total_s: 1586.0613496303558
  timestamp: 1744207815
  timesteps_since_restore: 209025
  timesteps_this_iter: 225
  timesteps_total: 209025
  training_iteration: 929
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    929 |          1586.06 |      209025 | 0.0851438 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-10-21
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.09744610868122713
  episode_reward_mean: 0.08469624801677296
  episode_reward_min: 0.07463205137980147
  episodes_this_iter: 5
  episodes_total: 4660
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 109.637
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 8.653374671936035
        entropy_coeff: 0.0
        kl: 0.026198893785476685
        policy_loss: -0.07765989005565643
        total_loss: -0.06612294167280197
        vf_explained_var: 0.9753267168998718
        vf_loss: 1.4665405615232885e-05
    load_time_ms: 1.184
    num_steps_sampled: 209700
    num_steps_trained: 209700
    sample_time_ms: 1993.012
    update_time_ms: 4.788
  iterations_since_restore: 932
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.833333333333332
    ram_util_percent: 78.73333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.777200677974145
    mean_inference_ms: 0.7669162386121272
    mean_processing_ms: 0.5451175497524378
  time_since_restore: 1592.7901282310486
  time_this_iter_s: 2.1964902877807617
  time_total_s: 1592.7901282310486
  timestamp: 1744207821
  timesteps_since_restore: 209700
  timesteps_this_iter: 225
  timesteps_total: 209700
  training_iteration: 932
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    932 |          1592.79 |      209700 | 0.0846962 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-10-28
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.09467160927574118
  episode_reward_mean: 0.08440463195859786
  episode_reward_min: 0.07463205137980147
  episodes_this_iter: 5
  episodes_total: 4675
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 104.913
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 7.298458099365234
        entropy_coeff: 0.0
        kl: 0.02933548018336296
        policy_loss: -0.08688439428806305
        total_loss: -0.07397089898586273
        vf_explained_var: 0.9801632165908813
        vf_loss: 1.174348835775163e-05
    load_time_ms: 1.109
    num_steps_sampled: 210375
    num_steps_trained: 210375
    sample_time_ms: 1986.481
    update_time_ms: 4.797
  iterations_since_restore: 935
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.3
    ram_util_percent: 78.75
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.781515561554024
    mean_inference_ms: 0.7675450929227857
    mean_processing_ms: 0.5456453277149312
  time_since_restore: 1598.8708283901215
  time_this_iter_s: 1.7475850582122803
  time_total_s: 1598.8708283901215
  timestamp: 1744207828
  timesteps_since_restore: 210375
  timesteps_this_iter: 225
  timesteps_total: 210375
  training_iteration: 935
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    935 |          1598.87 |      210375 | 0.0844046 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-10-34
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.09467160927574118
  episode_reward_mean: 0.08387014762892814
  episode_reward_min: 0.07463205137980147
  episodes_this_iter: 5
  episodes_total: 4690
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 104.324
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 7.305377006530762
        entropy_coeff: 0.0
        kl: 0.026365801692008972
        policy_loss: -0.07060809433460236
        total_loss: -0.059001415967941284
        vf_explained_var: 0.9811900854110718
        vf_loss: 1.0979418220813386e-05
    load_time_ms: 1.107
    num_steps_sampled: 211050
    num_steps_trained: 211050
    sample_time_ms: 1984.853
    update_time_ms: 4.601
  iterations_since_restore: 938
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.833333333333332
    ram_util_percent: 78.6
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.785569193965809
    mean_inference_ms: 0.7681198134929678
    mean_processing_ms: 0.5461253440942322
  time_since_restore: 1604.843213558197
  time_this_iter_s: 2.008683204650879
  time_total_s: 1604.843213558197
  timestamp: 1744207834
  timesteps_since_restore: 211050
  timesteps_this_iter: 225
  timesteps_total: 211050
  training_iteration: 938
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    938 |          1604.84 |      211050 | 0.0838701 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-10-39
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.09519029047130824
  episode_reward_mean: 0.083878159213041
  episode_reward_min: 0.07463205137980147
  episodes_this_iter: 5
  episodes_total: 4705
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 100.645
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 7.4612627029418945
        entropy_coeff: 0.0
        kl: 0.018459569662809372
        policy_loss: -0.06816213577985764
        total_loss: -0.06001700833439827
        vf_explained_var: 0.9555729031562805
        vf_loss: 2.66002316493541e-05
    load_time_ms: 1.025
    num_steps_sampled: 211725
    num_steps_trained: 211725
    sample_time_ms: 1893.108
    update_time_ms: 4.37
  iterations_since_restore: 941
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.86666666666667
    ram_util_percent: 78.63333333333334
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.78943591198823
    mean_inference_ms: 0.7686574784224592
    mean_processing_ms: 0.5465896753914369
  time_since_restore: 1610.6216080188751
  time_this_iter_s: 1.8302857875823975
  time_total_s: 1610.6216080188751
  timestamp: 1744207839
  timesteps_since_restore: 211725
  timesteps_this_iter: 225
  timesteps_total: 211725
  training_iteration: 941
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    941 |          1610.62 |      211725 | 0.0838782 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-10-46
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.09655138552910394
  episode_reward_mean: 0.08348886118418611
  episode_reward_min: 0.07463205137980147
  episodes_this_iter: 5
  episodes_total: 4720
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 100.395
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 7.271130561828613
        entropy_coeff: 0.0
        kl: 0.023027677088975906
        policy_loss: -0.06672130525112152
        total_loss: -0.05657685920596123
        vf_explained_var: 0.9691723585128784
        vf_loss: 1.6857109585544094e-05
    load_time_ms: 0.954
    num_steps_sampled: 212400
    num_steps_trained: 212400
    sample_time_ms: 1869.2
    update_time_ms: 4.192
  iterations_since_restore: 944
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.53333333333333
    ram_util_percent: 78.9
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.793180455438619
    mean_inference_ms: 0.7691921613597776
    mean_processing_ms: 0.547048860965983
  time_since_restore: 1616.9068999290466
  time_this_iter_s: 2.321390151977539
  time_total_s: 1616.9068999290466
  timestamp: 1744207846
  timesteps_since_restore: 212400
  timesteps_this_iter: 225
  timesteps_total: 212400
  training_iteration: 944
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    944 |          1616.91 |      212400 | 0.0834889 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-10-53
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.09655138552910394
  episode_reward_mean: 0.08316595274062175
  episode_reward_min: 0.07428070258377611
  episodes_this_iter: 5
  episodes_total: 4735
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 110.431
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 7.501925468444824
        entropy_coeff: 0.0
        kl: 0.026048127561807632
        policy_loss: -0.07873430103063583
        total_loss: -0.06726368516683578
        vf_explained_var: 0.9735657572746277
        vf_loss: 1.4639282198913861e-05
    load_time_ms: 1.074
    num_steps_sampled: 213075
    num_steps_trained: 213075
    sample_time_ms: 2000.213
    update_time_ms: 4.658
  iterations_since_restore: 947
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.266666666666666
    ram_util_percent: 79.03333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.7973296631580595
    mean_inference_ms: 0.7697892004730721
    mean_processing_ms: 0.5475106539549242
  time_since_restore: 1624.0378375053406
  time_this_iter_s: 2.34199595451355
  time_total_s: 1624.0378375053406
  timestamp: 1744207853
  timesteps_since_restore: 213075
  timesteps_this_iter: 225
  timesteps_total: 213075
  training_iteration: 947
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    947 |          1624.04 |      213075 | 0.083166 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-11-00
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.09655138552910394
  episode_reward_mean: 0.08348983358157393
  episode_reward_min: 0.07428070258377611
  episodes_this_iter: 5
  episodes_total: 4750
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 111.775
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 7.581689357757568
        entropy_coeff: 0.0
        kl: 0.02053644135594368
        policy_loss: -0.060564350336790085
        total_loss: -0.05150969699025154
        vf_explained_var: 0.9609383344650269
        vf_loss: 2.271868106618058e-05
    load_time_ms: 1.159
    num_steps_sampled: 213750
    num_steps_trained: 213750
    sample_time_ms: 2084.169
    update_time_ms: 4.873
  iterations_since_restore: 950
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.33333333333334
    ram_util_percent: 79.06666666666666
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.801845574611902
    mean_inference_ms: 0.7704534318427382
    mean_processing_ms: 0.5479994839996829
  time_since_restore: 1630.8508868217468
  time_this_iter_s: 2.244457244873047
  time_total_s: 1630.8508868217468
  timestamp: 1744207860
  timesteps_since_restore: 213750
  timesteps_this_iter: 225
  timesteps_total: 213750
  training_iteration: 950
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.2/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    950 |          1630.85 |      213750 | 0.0834898 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-11-05
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.09655138552910394
  episode_reward_mean: 0.08333503065808426
  episode_reward_min: 0.07282684640725537
  episodes_this_iter: 5
  episodes_total: 4765
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 107.997
    learner:
      default_policy:
        cur_kl_coeff: 0.4398007392883301
        cur_lr: 4.999999873689376e-05
        entropy: 7.482178688049316
        entropy_coeff: 0.0
        kl: 0.05101923272013664
        policy_loss: -0.11543415486812592
        total_loss: -0.09298297017812729
        vf_explained_var: 0.977383017539978
        vf_loss: 1.29015998027171e-05
    load_time_ms: 1.147
    num_steps_sampled: 214425
    num_steps_trained: 214425
    sample_time_ms: 2049.38
    update_time_ms: 4.747
  iterations_since_restore: 953
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.433333333333334
    ram_util_percent: 79.1
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.805971997461623
    mean_inference_ms: 0.7710526702936974
    mean_processing_ms: 0.5484414260527097
  time_since_restore: 1636.2561042308807
  time_this_iter_s: 1.5956027507781982
  time_total_s: 1636.2561042308807
  timestamp: 1744207865
  timesteps_since_restore: 214425
  timesteps_this_iter: 225
  timesteps_total: 214425
  training_iteration: 953
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.2/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    953 |          1636.26 |      214425 | 0.083335 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-11-11
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.09655138552910394
  episode_reward_mean: 0.08290253183380715
  episode_reward_min: 0.07282684640725537
  episodes_this_iter: 5
  episodes_total: 4780
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 101.564
    learner:
      default_policy:
        cur_kl_coeff: 0.6597011089324951
        cur_lr: 4.999999873689376e-05
        entropy: 7.309442043304443
        entropy_coeff: 0.0
        kl: 0.019801869988441467
        policy_loss: -0.07087363302707672
        total_loss: -0.057800035923719406
        vf_explained_var: 0.9816610217094421
        vf_loss: 1.027498183248099e-05
    load_time_ms: 1.136
    num_steps_sampled: 215100
    num_steps_trained: 215100
    sample_time_ms: 1892.989
    update_time_ms: 4.3
  iterations_since_restore: 956
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.75
    ram_util_percent: 78.6
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.809760824912155
    mean_inference_ms: 0.7715792245078495
    mean_processing_ms: 0.5488073880298769
  time_since_restore: 1641.7315185070038
  time_this_iter_s: 1.6877164840698242
  time_total_s: 1641.7315185070038
  timestamp: 1744207871
  timesteps_since_restore: 215100
  timesteps_this_iter: 225
  timesteps_total: 215100
  training_iteration: 956
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    956 |          1641.73 |      215100 | 0.0829025 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-11-16
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.09655138552910394
  episode_reward_mean: 0.0828542867475195
  episode_reward_min: 0.07030696142197003
  episodes_this_iter: 5
  episodes_total: 4795
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 88.991
    learner:
      default_policy:
        cur_kl_coeff: 0.6597011089324951
        cur_lr: 4.999999873689376e-05
        entropy: 7.035433769226074
        entropy_coeff: 0.0
        kl: 0.021585017442703247
        policy_loss: -0.073790043592453
        total_loss: -0.05953258275985718
        vf_explained_var: 0.9668601155281067
        vf_loss: 1.779523881850764e-05
    load_time_ms: 0.914
    num_steps_sampled: 215775
    num_steps_trained: 215775
    sample_time_ms: 1714.893
    update_time_ms: 3.84
  iterations_since_restore: 959
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.933333333333334
    ram_util_percent: 78.5
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.8130808189161085
    mean_inference_ms: 0.7720446546431025
    mean_processing_ms: 0.5491192991787136
  time_since_restore: 1646.7257273197174
  time_this_iter_s: 1.6092534065246582
  time_total_s: 1646.7257273197174
  timestamp: 1744207876
  timesteps_since_restore: 215775
  timesteps_this_iter: 225
  timesteps_total: 215775
  training_iteration: 959
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    959 |          1646.73 |      215775 | 0.0828543 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-11-21
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.09515017992556991
  episode_reward_mean: 0.08295148995542638
  episode_reward_min: 0.07030696142197003
  episodes_this_iter: 5
  episodes_total: 4810
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.814
    learner:
      default_policy:
        cur_kl_coeff: 0.6597011089324951
        cur_lr: 4.999999873689376e-05
        entropy: 7.34731388092041
        entropy_coeff: 0.0
        kl: 0.022513803094625473
        policy_loss: -0.09435848891735077
        total_loss: -0.0794917494058609
        vf_explained_var: 0.9765089750289917
        vf_loss: 1.4375284081324935e-05
    load_time_ms: 0.953
    num_steps_sampled: 216450
    num_steps_trained: 216450
    sample_time_ms: 1640.54
    update_time_ms: 3.774
  iterations_since_restore: 962
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.049999999999997
    ram_util_percent: 78.5
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.816111699852837
    mean_inference_ms: 0.7724594301533142
    mean_processing_ms: 0.549392167103573
  time_since_restore: 1652.044757604599
  time_this_iter_s: 1.6620283126831055
  time_total_s: 1652.044757604599
  timestamp: 1744207881
  timesteps_since_restore: 216450
  timesteps_this_iter: 225
  timesteps_total: 216450
  training_iteration: 962
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    962 |          1652.04 |      216450 | 0.0829515 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-11-26
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.09515017992556991
  episode_reward_mean: 0.08253645798026749
  episode_reward_min: 0.07030696142197003
  episodes_this_iter: 5
  episodes_total: 4825
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.062
    learner:
      default_policy:
        cur_kl_coeff: 0.6597011089324951
        cur_lr: 4.999999873689376e-05
        entropy: 7.696949005126953
        entropy_coeff: 0.0
        kl: 0.014928947202861309
        policy_loss: -0.06521815061569214
        total_loss: -0.055356092751026154
        vf_explained_var: 0.975335955619812
        vf_loss: 1.3413249689619988e-05
    load_time_ms: 0.898
    num_steps_sampled: 217125
    num_steps_trained: 217125
    sample_time_ms: 1635.616
    update_time_ms: 3.724
  iterations_since_restore: 965
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.76666666666667
    ram_util_percent: 78.56666666666666
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.818606126871934
    mean_inference_ms: 0.7727959034251236
    mean_processing_ms: 0.5496011534594314
  time_since_restore: 1657.3702189922333
  time_this_iter_s: 1.7643852233886719
  time_total_s: 1657.3702189922333
  timestamp: 1744207886
  timesteps_since_restore: 217125
  timesteps_this_iter: 225
  timesteps_total: 217125
  training_iteration: 965
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    965 |          1657.37 |      217125 | 0.0825365 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-11-33
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.0919644371931637
  episode_reward_mean: 0.082722346021016
  episode_reward_min: 0.07030696142197003
  episodes_this_iter: 5
  episodes_total: 4845
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 87.091
    learner:
      default_policy:
        cur_kl_coeff: 0.6597011089324951
        cur_lr: 4.999999873689376e-05
        entropy: 7.003864288330078
        entropy_coeff: 0.0
        kl: 0.02461305633187294
        policy_loss: -0.05884901434183121
        total_loss: -0.0425964780151844
        vf_explained_var: 0.9716838598251343
        vf_loss: 1.5268415154423565e-05
    load_time_ms: 0.891
    num_steps_sampled: 218025
    num_steps_trained: 218025
    sample_time_ms: 1643.73
    update_time_ms: 3.701
  iterations_since_restore: 969
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.633333333333333
    ram_util_percent: 78.5
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.820260288556816
    mean_inference_ms: 0.7729781927847611
    mean_processing_ms: 0.5497118353092458
  time_since_restore: 1664.1121871471405
  time_this_iter_s: 1.7900114059448242
  time_total_s: 1664.1121871471405
  timestamp: 1744207893
  timesteps_since_restore: 218025
  timesteps_this_iter: 225
  timesteps_total: 218025
  training_iteration: 969
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    969 |          1664.11 |      218025 | 0.0827223 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-11-40
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.0919644371931637
  episode_reward_mean: 0.08218244355285952
  episode_reward_min: 0.07030696142197003
  episodes_this_iter: 5
  episodes_total: 4865
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 85.072
    learner:
      default_policy:
        cur_kl_coeff: 0.6597011089324951
        cur_lr: 4.999999873689376e-05
        entropy: 7.320055961608887
        entropy_coeff: 0.0
        kl: 0.01909530721604824
        policy_loss: -0.07489363104104996
        total_loss: -0.062284864485263824
        vf_explained_var: 0.97846919298172
        vf_loss: 1.1585982065298595e-05
    load_time_ms: 0.924
    num_steps_sampled: 218925
    num_steps_trained: 218925
    sample_time_ms: 1581.821
    update_time_ms: 3.621
  iterations_since_restore: 973
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.950000000000003
    ram_util_percent: 78.4
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.820683879728787
    mean_inference_ms: 0.7729317010652358
    mean_processing_ms: 0.5496775322228136
  time_since_restore: 1670.6942582130432
  time_this_iter_s: 1.66656494140625
  time_total_s: 1670.6942582130432
  timestamp: 1744207900
  timesteps_since_restore: 218925
  timesteps_this_iter: 225
  timesteps_total: 218925
  training_iteration: 973
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    973 |          1670.69 |      218925 | 0.0821824 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-11-45
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.0919644371931637
  episode_reward_mean: 0.08237539991662182
  episode_reward_min: 0.07030696142197003
  episodes_this_iter: 5
  episodes_total: 4880
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 86.082
    learner:
      default_policy:
        cur_kl_coeff: 0.6597011089324951
        cur_lr: 4.999999873689376e-05
        entropy: 6.819860935211182
        entropy_coeff: 0.0
        kl: 0.024610387161374092
        policy_loss: -0.08929497748613358
        total_loss: -0.07304561138153076
        vf_explained_var: 0.976746678352356
        vf_loss: 1.3856512850907166e-05
    load_time_ms: 0.958
    num_steps_sampled: 219600
    num_steps_trained: 219600
    sample_time_ms: 1629.518
    update_time_ms: 3.7
  iterations_since_restore: 976
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.066666666666666
    ram_util_percent: 78.53333333333333
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.820924271321727
    mean_inference_ms: 0.7728981929320239
    mean_processing_ms: 0.5496556623115331
  time_since_restore: 1676.1991927623749
  time_this_iter_s: 1.6643664836883545
  time_total_s: 1676.1991927623749
  timestamp: 1744207905
  timesteps_since_restore: 219600
  timesteps_this_iter: 225
  timesteps_total: 219600
  training_iteration: 976
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    976 |           1676.2 |      219600 | 0.0823754 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-11-50
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.09221502035584095
  episode_reward_mean: 0.0821471145603385
  episode_reward_min: 0.07170501818994565
  episodes_this_iter: 5
  episodes_total: 4895
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 86.629
    learner:
      default_policy:
        cur_kl_coeff: 0.6597011089324951
        cur_lr: 4.999999873689376e-05
        entropy: 6.872377872467041
        entropy_coeff: 0.0
        kl: 0.020736129954457283
        policy_loss: -0.06632361561059952
        total_loss: -0.05262991786003113
        vf_explained_var: 0.9729673266410828
        vf_loss: 1.4047749573364854e-05
    load_time_ms: 0.984
    num_steps_sampled: 220275
    num_steps_trained: 220275
    sample_time_ms: 1620.32
    update_time_ms: 3.68
  iterations_since_restore: 979
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.549999999999997
    ram_util_percent: 78.45
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.82120512607837
    mean_inference_ms: 0.7728758461059235
    mean_processing_ms: 0.5496472766264938
  time_since_restore: 1681.2598161697388
  time_this_iter_s: 1.674710750579834
  time_total_s: 1681.2598161697388
  timestamp: 1744207910
  timesteps_since_restore: 220275
  timesteps_this_iter: 225
  timesteps_total: 220275
  training_iteration: 979
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    979 |          1681.26 |      220275 | 0.0821471 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-11-55
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.09221502035584095
  episode_reward_mean: 0.08171321583734248
  episode_reward_min: 0.07154998716501952
  episodes_this_iter: 5
  episodes_total: 4910
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 86.896
    learner:
      default_policy:
        cur_kl_coeff: 0.6597011089324951
        cur_lr: 4.999999873689376e-05
        entropy: 6.6009345054626465
        entropy_coeff: 0.0
        kl: 0.016766097396612167
        policy_loss: -0.0724247619509697
        total_loss: -0.06134209781885147
        vf_explained_var: 0.9603170156478882
        vf_loss: 2.207013312727213e-05
    load_time_ms: 0.97
    num_steps_sampled: 220950
    num_steps_trained: 220950
    sample_time_ms: 1638.407
    update_time_ms: 3.69
  iterations_since_restore: 982
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.15
    ram_util_percent: 78.4
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.821359089134087
    mean_inference_ms: 0.7728423746149501
    mean_processing_ms: 0.5496317141838805
  time_since_restore: 1686.3601751327515
  time_this_iter_s: 1.6735479831695557
  time_total_s: 1686.3601751327515
  timestamp: 1744207915
  timesteps_since_restore: 220950
  timesteps_this_iter: 225
  timesteps_total: 220950
  training_iteration: 982
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    982 |          1686.36 |      220950 | 0.0817132 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-12-02
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.09221502035584095
  episode_reward_mean: 0.08162053530266167
  episode_reward_min: 0.07154998716501952
  episodes_this_iter: 5
  episodes_total: 4930
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 86.473
    learner:
      default_policy:
        cur_kl_coeff: 0.6597011089324951
        cur_lr: 4.999999873689376e-05
        entropy: 6.722784519195557
        entropy_coeff: 0.0
        kl: 0.017865857109427452
        policy_loss: -0.05626761168241501
        total_loss: -0.04446589946746826
        vf_explained_var: 0.9687258005142212
        vf_loss: 1.5579938917653635e-05
    load_time_ms: 0.944
    num_steps_sampled: 221850
    num_steps_trained: 221850
    sample_time_ms: 1581.129
    update_time_ms: 3.761
  iterations_since_restore: 986
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.1
    ram_util_percent: 78.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.821369159164101
    mean_inference_ms: 0.7727580946921867
    mean_processing_ms: 0.5495785228580065
  time_since_restore: 1692.9557375907898
  time_this_iter_s: 1.631864070892334
  time_total_s: 1692.9557375907898
  timestamp: 1744207922
  timesteps_since_restore: 221850
  timesteps_this_iter: 225
  timesteps_total: 221850
  training_iteration: 986
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    986 |          1692.96 |      221850 | 0.0816205 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-12-07
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.09221502035584095
  episode_reward_mean: 0.08170399800368365
  episode_reward_min: 0.06916099299156207
  episodes_this_iter: 5
  episodes_total: 4945
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 87.008
    learner:
      default_policy:
        cur_kl_coeff: 0.6597011089324951
        cur_lr: 4.999999873689376e-05
        entropy: 6.645772457122803
        entropy_coeff: 0.0
        kl: 0.01608250103890896
        policy_loss: -0.0565522201359272
        total_loss: -0.04591464251279831
        vf_explained_var: 0.9538261294364929
        vf_loss: 2.791408587654587e-05
    load_time_ms: 0.977
    num_steps_sampled: 222525
    num_steps_trained: 222525
    sample_time_ms: 1597.293
    update_time_ms: 3.781
  iterations_since_restore: 989
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.85
    ram_util_percent: 78.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.821472447705037
    mean_inference_ms: 0.7727172627446524
    mean_processing_ms: 0.5495488491074147
  time_since_restore: 1698.1837990283966
  time_this_iter_s: 1.638941764831543
  time_total_s: 1698.1837990283966
  timestamp: 1744207927
  timesteps_since_restore: 222525
  timesteps_this_iter: 225
  timesteps_total: 222525
  training_iteration: 989
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    989 |          1698.18 |      222525 | 0.081704 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-12-12
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.09221502035584095
  episode_reward_mean: 0.08184665428850366
  episode_reward_min: 0.06916099299156207
  episodes_this_iter: 5
  episodes_total: 4960
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 86.788
    learner:
      default_policy:
        cur_kl_coeff: 0.6597011089324951
        cur_lr: 4.999999873689376e-05
        entropy: 6.714014530181885
        entropy_coeff: 0.0
        kl: 0.019696926698088646
        policy_loss: -0.08203040063381195
        total_loss: -0.06902269273996353
        vf_explained_var: 0.9764951467514038
        vf_loss: 1.3618586308439262e-05
    load_time_ms: 0.96
    num_steps_sampled: 223200
    num_steps_trained: 223200
    sample_time_ms: 1590.872
    update_time_ms: 3.713
  iterations_since_restore: 992
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.96666666666667
    ram_util_percent: 78.5
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.821574636508035
    mean_inference_ms: 0.7727044420348647
    mean_processing_ms: 0.5495250436715108
  time_since_restore: 1703.2167448997498
  time_this_iter_s: 1.5914506912231445
  time_total_s: 1703.2167448997498
  timestamp: 1744207932
  timesteps_since_restore: 223200
  timesteps_this_iter: 225
  timesteps_total: 223200
  training_iteration: 992
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    992 |          1703.22 |      223200 | 0.0818467 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-12-17
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.09221502035584095
  episode_reward_mean: 0.0817493437169349
  episode_reward_min: 0.06916099299156207
  episodes_this_iter: 5
  episodes_total: 4975
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 86.445
    learner:
      default_policy:
        cur_kl_coeff: 0.6597011089324951
        cur_lr: 4.999999873689376e-05
        entropy: 7.230161190032959
        entropy_coeff: 0.0
        kl: 0.013562353327870369
        policy_loss: -0.06091473251581192
        total_loss: -0.05195697396993637
        vf_explained_var: 0.9810706377029419
        vf_loss: 1.0651454431354068e-05
    load_time_ms: 0.921
    num_steps_sampled: 223875
    num_steps_trained: 223875
    sample_time_ms: 1601.986
    update_time_ms: 3.563
  iterations_since_restore: 995
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.733333333333334
    ram_util_percent: 78.5
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.821558596514575
    mean_inference_ms: 0.7726789013717876
    mean_processing_ms: 0.5495002536052703
  time_since_restore: 1708.2866218090057
  time_this_iter_s: 1.6294384002685547
  time_total_s: 1708.2866218090057
  timestamp: 1744207937
  timesteps_since_restore: 223875
  timesteps_this_iter: 225
  timesteps_total: 223875
  training_iteration: 995
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    995 |          1708.29 |      223875 | 0.0817493 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-12-23
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 0.09141334120736151
  episode_reward_mean: 0.08228508346623607
  episode_reward_min: 0.06916099299156207
  episodes_this_iter: 5
  episodes_total: 4990
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 86.585
    learner:
      default_policy:
        cur_kl_coeff: 0.6597011089324951
        cur_lr: 4.999999873689376e-05
        entropy: 7.123899936676025
        entropy_coeff: 0.0
        kl: 0.022083351388573647
        policy_loss: -0.09402884542942047
        total_loss: -0.07943334430456161
        vf_explained_var: 0.9533435106277466
        vf_loss: 2.7091324227512814e-05
    load_time_ms: 0.906
    num_steps_sampled: 224550
    num_steps_trained: 224550
    sample_time_ms: 1658.788
    update_time_ms: 3.609
  iterations_since_restore: 998
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.6
    ram_util_percent: 78.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.82173647685544
    mean_inference_ms: 0.7726871802026979
    mean_processing_ms: 0.5495119775468905
  time_since_restore: 1714.076581478119
  time_this_iter_s: 1.7851662635803223
  time_total_s: 1714.076581478119
  timestamp: 1744207943
  timesteps_since_restore: 224550
  timesteps_this_iter: 225
  timesteps_total: 224550
  training_iteration: 998
  trial_id: a1bff55e
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |    reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+-----------|
| PPO_FleetControlEnv-v0_a1bff55e | RUNNING  | 35.3.43.231:263755 |    998 |          1714.08 |      224550 | 0.0822851 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+-----------+


Result for PPO_FleetControlEnv-v0_a1bff55e:
  custom_metrics: {}
  date: 2025-04-09_10-12-27
  done: true
  episode_len_mean: 45.0
  episode_reward_max: 0.09141334120736151
  episode_reward_mean: 0.08240504160440172
  episode_reward_min: 0.06916099299156207
  episodes_this_iter: 5
  episodes_total: 5000
  experiment_id: 2c34f5476bf444e281a61d9379778b46
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 86.446
    learner:
      default_policy:
        cur_kl_coeff: 0.6597011089324951
        cur_lr: 4.999999873689376e-05
        entropy: 6.786576271057129
        entropy_coeff: 0.0
        kl: 0.024138595908880234
        policy_loss: -0.08554798364639282
        total_loss: -0.0696115493774414
        vf_explained_var: 0.979627251625061
        vf_loss: 1.2168450666649733e-05
    load_time_ms: 0.949
    num_steps_sampled: 225000
    num_steps_trained: 225000
    sample_time_ms: 1682.434
    update_time_ms: 3.827
  iterations_since_restore: 1000
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.3
    ram_util_percent: 78.3
  pid: 263755
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.821947606980278
    mean_inference_ms: 0.7727026547785906
    mean_processing_ms: 0.5495229731100416
  time_since_restore: 1717.717631816864
  time_this_iter_s: 1.835709810256958
  time_total_s: 1717.717631816864
  timestamp: 1744207947
  timesteps_since_restore: 225000
  timesteps_this_iter: 225
  timesteps_total: 225000
  training_iteration: 1000
  trial_id: a1bff55e
  
[2m[36m(pid=263754)[0m ./emissions_output/fleet_control_20250409-0943411744206221.6521943-0_emission.csv ./emissions_output
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/1.27 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 TERMINATED)
+---------------------------------+------------+-------+--------+------------------+-------------+----------+
| Trial name                      | status     | loc   |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+------------+-------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_a1bff55e | TERMINATED |       |   1000 |          1717.72 |      225000 | 0.082405 |
+---------------------------------+------------+-------+--------+------------------+-------------+----------+


