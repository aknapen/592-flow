flags Namespace(checkpoint_path=None, exp_config='flowagent', num_cpus=1, num_steps=100, rl_trainer='rllib', rollout_size=1000)
== Status ==
Memory usage on this node: 10.5/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.81 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+-------+
| Trial name                      | status   | loc   |
|---------------------------------+----------+-------|
| PPO_FleetControlEnv-v0_cd488956 | RUNNING  |       |
+---------------------------------+----------+-------+


[2m[36m(pid=235213)[0m 2025-04-08 20:08:47,138	INFO trainer.py:371 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution
[2m[36m(pid=235213)[0m 2025-04-08 20:08:47,370	INFO trainer.py:512 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=235213)[0m 2025-04-08 20:08:51,792	WARNING util.py:45 -- Install gputil for GPU system monitoring.
Result for PPO_FleetControlEnv-v0_cd488956:
  custom_metrics: {}
  date: 2025-04-08_20-08-54
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 324.7439910996573
  episode_reward_mean: 324.7439910996573
  episode_reward_min: 324.7439910996573
  episodes_this_iter: 1
  episodes_total: 1
  experiment_id: 8ef8f84684744e998abe8b78c6044f6b
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 293.971
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 21.284013748168945
        entropy_coeff: 0.0
        kl: 0.0007106569246388972
        policy_loss: -0.027537351474165916
        total_loss: 18397.40234375
        vf_explained_var: 5.501508712768555e-05
        vf_loss: 18397.4296875
    load_time_ms: 71.867
    num_steps_sampled: 45
    num_steps_trained: 45
    sample_time_ms: 1231.87
    update_time_ms: 951.726
  iterations_since_restore: 1
  node_ip: 192.168.0.24
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.725
    ram_util_percent: 72.4
  pid: 235213
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 4.844774370608122
    mean_inference_ms: 1.2942448906276538
    mean_processing_ms: 0.49970460974651837
  time_since_restore: 2.612921714782715
  time_this_iter_s: 2.612921714782715
  time_total_s: 2.612921714782715
  timestamp: 1744157334
  timesteps_since_restore: 45
  timesteps_this_iter: 45
  timesteps_total: 45
  training_iteration: 1
  trial_id: cd488956
  
== Status ==
Memory usage on this node: 11.2/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.81 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+---------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                 |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+---------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_cd488956 | RUNNING  | 192.168.0.24:235213 |      1 |          2.61292 |          45 |  324.744 |
+---------------------------------+----------+---------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_cd488956:
  custom_metrics: {}
  date: 2025-04-08_20-08-59
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 324.7439910996573
  episode_reward_mean: 53.701706820550534
  episode_reward_min: 15.299354311350243
  episodes_this_iter: 1
  episodes_total: 18
  experiment_id: 8ef8f84684744e998abe8b78c6044f6b
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 15.922
    learner:
      default_policy:
        cur_kl_coeff: 1.5258789289873675e-06
        cur_lr: 4.999999873689376e-05
        entropy: 21.434497833251953
        entropy_coeff: 0.0
        kl: 0.0005475865327753127
        policy_loss: -0.017948778346180916
        total_loss: 51.63070297241211
        vf_explained_var: 0.001971006393432617
        vf_loss: 51.64863967895508
    load_time_ms: 0.851
    num_steps_sampled: 810
    num_steps_trained: 810
    sample_time_ms: 285.154
    update_time_ms: 3.231
  iterations_since_restore: 18
  node_ip: 192.168.0.24
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.3
    ram_util_percent: 72.5
  pid: 235213
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 4.991388132589981
    mean_inference_ms: 0.7241398683545435
    mean_processing_ms: 0.428262018208206
  time_since_restore: 7.767015695571899
  time_this_iter_s: 0.32332372665405273
  time_total_s: 7.767015695571899
  timestamp: 1744157339
  timesteps_since_restore: 810
  timesteps_this_iter: 45
  timesteps_total: 810
  training_iteration: 18
  trial_id: cd488956
  
== Status ==
Memory usage on this node: 11.2/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.81 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+---------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                 |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+---------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_cd488956 | RUNNING  | 192.168.0.24:235213 |     18 |          7.76702 |         810 |  53.7017 |
+---------------------------------+----------+---------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_cd488956:
  custom_metrics: {}
  date: 2025-04-08_20-09-04
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 324.7439910996573
  episode_reward_mean: 32.41540521249727
  episode_reward_min: 5.862390923473583
  episodes_this_iter: 1
  episodes_total: 35
  experiment_id: 8ef8f84684744e998abe8b78c6044f6b
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 15.619
    learner:
      default_policy:
        cur_kl_coeff: 1.1641532356165829e-11
        cur_lr: 4.999999873689376e-05
        entropy: 21.56580352783203
        entropy_coeff: 0.0
        kl: 0.0003753364144358784
        policy_loss: -0.01682307757437229
        total_loss: 6.626874923706055
        vf_explained_var: 0.01167142391204834
        vf_loss: 6.643698692321777
    load_time_ms: 0.899
    num_steps_sampled: 1575
    num_steps_trained: 1575
    sample_time_ms: 273.725
    update_time_ms: 3.267
  iterations_since_restore: 35
  node_ip: 192.168.0.24
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf: {}
  pid: 235213
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.036625909358858
    mean_inference_ms: 0.6728294070155222
    mean_processing_ms: 0.42512853939544065
  time_since_restore: 12.76996374130249
  time_this_iter_s: 0.2922017574310303
  time_total_s: 12.76996374130249
  timestamp: 1744157344
  timesteps_since_restore: 1575
  timesteps_this_iter: 45
  timesteps_total: 1575
  training_iteration: 35
  trial_id: cd488956
  
== Status ==
Memory usage on this node: 11.2/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.81 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+---------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                 |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+---------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_cd488956 | RUNNING  | 192.168.0.24:235213 |     35 |            12.77 |        1575 |  32.4154 |
+---------------------------------+----------+---------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_cd488956:
  custom_metrics: {}
  date: 2025-04-08_20-09-09
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 324.7439910996573
  episode_reward_mean: 24.218665604446
  episode_reward_min: 4.66460669920432
  episodes_this_iter: 1
  episodes_total: 51
  experiment_id: 8ef8f84684744e998abe8b78c6044f6b
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 15.407
    learner:
      default_policy:
        cur_kl_coeff: 1.77635686587003e-16
        cur_lr: 4.999999873689376e-05
        entropy: 21.60082244873047
        entropy_coeff: 0.0
        kl: 0.00025075144367292523
        policy_loss: -0.01679212786257267
        total_loss: 4.702447414398193
        vf_explained_var: 0.07138758897781372
        vf_loss: 4.719240188598633
    load_time_ms: 0.859
    num_steps_sampled: 2295
    num_steps_trained: 2295
    sample_time_ms: 284.47
    update_time_ms: 3.274
  iterations_since_restore: 51
  node_ip: 192.168.0.24
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf: {}
  pid: 235213
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.059669781271679
    mean_inference_ms: 0.6556744127362039
    mean_processing_ms: 0.4229105292252842
  time_since_restore: 17.796258449554443
  time_this_iter_s: 0.3655579090118408
  time_total_s: 17.796258449554443
  timestamp: 1744157349
  timesteps_since_restore: 2295
  timesteps_this_iter: 45
  timesteps_total: 2295
  training_iteration: 51
  trial_id: cd488956
  
== Status ==
Memory usage on this node: 11.2/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.81 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+---------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                 |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+---------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_cd488956 | RUNNING  | 192.168.0.24:235213 |     51 |          17.7963 |        2295 |  24.2187 |
+---------------------------------+----------+---------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_cd488956:
  custom_metrics: {}
  date: 2025-04-08_20-09-15
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 324.7439910996573
  episode_reward_mean: 19.22428523455323
  episode_reward_min: 3.038061409561335
  episodes_this_iter: 1
  episodes_total: 68
  experiment_id: 8ef8f84684744e998abe8b78c6044f6b
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 15.833
    learner:
      default_policy:
        cur_kl_coeff: 1.3552527358017197e-21
        cur_lr: 4.999999873689376e-05
        entropy: 21.520910263061523
        entropy_coeff: 0.0
        kl: 0.00018455451936461031
        policy_loss: -0.009537034668028355
        total_loss: 2.5208630561828613
        vf_explained_var: 0.0495905876159668
        vf_loss: 2.530400037765503
    load_time_ms: 0.834
    num_steps_sampled: 3060
    num_steps_trained: 3060
    sample_time_ms: 271.747
    update_time_ms: 3.143
  iterations_since_restore: 68
  node_ip: 192.168.0.24
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.5
    ram_util_percent: 72.6
  pid: 235213
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.0820487954231375
    mean_inference_ms: 0.6450669278566524
    mean_processing_ms: 0.4229305489533748
  time_since_restore: 22.888517141342163
  time_this_iter_s: 0.29253149032592773
  time_total_s: 22.888517141342163
  timestamp: 1744157355
  timesteps_since_restore: 3060
  timesteps_this_iter: 45
  timesteps_total: 3060
  training_iteration: 68
  trial_id: cd488956
  
== Status ==
Memory usage on this node: 11.2/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.81 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+---------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                 |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+---------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_cd488956 | RUNNING  | 192.168.0.24:235213 |     68 |          22.8885 |        3060 |  19.2243 |
+---------------------------------+----------+---------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_cd488956:
  custom_metrics: {}
  date: 2025-04-08_20-09-20
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 324.7439910996573
  episode_reward_mean: 16.041512225637558
  episode_reward_min: 2.2783713217000954
  episodes_this_iter: 1
  episodes_total: 85
  experiment_id: 8ef8f84684744e998abe8b78c6044f6b
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 16.276
    learner:
      default_policy:
        cur_kl_coeff: 1.0339757810987241e-26
        cur_lr: 4.999999873689376e-05
        entropy: 21.604551315307617
        entropy_coeff: 0.0
        kl: 0.0004057341138832271
        policy_loss: -0.03462226688861847
        total_loss: 2.015608549118042
        vf_explained_var: 0.046544432640075684
        vf_loss: 2.0502309799194336
    load_time_ms: 0.844
    num_steps_sampled: 3825
    num_steps_trained: 3825
    sample_time_ms: 272.992
    update_time_ms: 3.431
  iterations_since_restore: 85
  node_ip: 192.168.0.24
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf: {}
  pid: 235213
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.086845566450312
    mean_inference_ms: 0.6375396756859376
    mean_processing_ms: 0.42302881508385487
  time_since_restore: 27.91541028022766
  time_this_iter_s: 0.3154745101928711
  time_total_s: 27.91541028022766
  timestamp: 1744157360
  timesteps_since_restore: 3825
  timesteps_this_iter: 45
  timesteps_total: 3825
  training_iteration: 85
  trial_id: cd488956
  
== Status ==
Memory usage on this node: 11.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.81 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+---------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                 |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+---------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_cd488956 | RUNNING  | 192.168.0.24:235213 |     85 |          27.9154 |        3825 |  16.0415 |
+---------------------------------+----------+---------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_cd488956:
  custom_metrics: {}
  date: 2025-04-08_20-09-24
  done: true
  episode_len_mean: 45.0
  episode_reward_max: 324.7439910996573
  episode_reward_mean: 14.035625741572964
  episode_reward_min: 1.942870187179576
  episodes_this_iter: 1
  episodes_total: 100
  experiment_id: 8ef8f84684744e998abe8b78c6044f6b
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 15.435
    learner:
      default_policy:
        cur_kl_coeff: 3.1554436679038213e-31
        cur_lr: 4.999999873689376e-05
        entropy: 21.60430335998535
        entropy_coeff: 0.0
        kl: 0.00029769472894258797
        policy_loss: -0.012603060342371464
        total_loss: 0.5070168972015381
        vf_explained_var: 0.0009215474128723145
        vf_loss: 0.5196199417114258
    load_time_ms: 0.809
    num_steps_sampled: 4500
    num_steps_trained: 4500
    sample_time_ms: 269.915
    update_time_ms: 3.121
  iterations_since_restore: 100
  node_ip: 192.168.0.24
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.5
    ram_util_percent: 72.3
  pid: 235213
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.088019621681952
    mean_inference_ms: 0.6326534658212127
    mean_processing_ms: 0.4235789903452863
  time_since_restore: 32.37438464164734
  time_this_iter_s: 0.29498910903930664
  time_total_s: 32.37438464164734
  timestamp: 1744157364
  timesteps_since_restore: 4500
  timesteps_this_iter: 45
  timesteps_total: 4500
  training_iteration: 100
  trial_id: cd488956
  
== Status ==
Memory usage on this node: 11.1/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/1.81 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 TERMINATED)
+---------------------------------+------------+-------+--------+------------------+-------------+----------+
| Trial name                      | status     | loc   |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+------------+-------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_cd488956 | TERMINATED |       |    100 |          32.3744 |        4500 |  14.0356 |
+---------------------------------+------------+-------+--------+------------------+-------------+----------+


[2m[36m(pid=235214)[0m ./emissions_output/fleet_control_20250408-2008511744157331.686696-0_emission.csv ./emissions_output
