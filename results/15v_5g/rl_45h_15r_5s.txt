flags Namespace(checkpoint_path=None, exp_config='flowagent', num_cpus=1, num_steps=5, rl_trainer='rllib', rollout_size=1000)
== Status ==
Memory usage on this node: 10.6/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.81 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+-------+
| Trial name                      | status   | loc   |
|---------------------------------+----------+-------|
| PPO_FleetControlEnv-v0_089fd21e | RUNNING  |       |
+---------------------------------+----------+-------+


[2m[36m(pid=248786)[0m 2025-04-08 21:00:33,775	INFO trainer.py:371 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution
[2m[36m(pid=248786)[0m 2025-04-08 21:00:34,029	INFO trainer.py:512 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=248786)[0m 2025-04-08 21:00:39,743	WARNING util.py:45 -- Install gputil for GPU system monitoring.
Result for PPO_FleetControlEnv-v0_089fd21e:
  custom_metrics: {}
  date: 2025-04-08_21-00-47
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 468.6534979510603
  episode_reward_mean: 72.81746455498157
  episode_reward_min: 10.679273636980533
  episodes_this_iter: 15
  episodes_total: 15
  experiment_id: d203ca0476e24a1e8591505f44877686
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 790.31
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 21.219799041748047
        entropy_coeff: 0.0
        kl: 0.012953399680554867
        policy_loss: -0.04024747386574745
        total_loss: 3098.170654296875
        vf_explained_var: 0.00011822779924841598
        vf_loss: 3098.208251953125
    load_time_ms: 77.977
    num_steps_sampled: 675
    num_steps_trained: 675
    sample_time_ms: 5973.082
    update_time_ms: 1076.504
  iterations_since_restore: 1
  node_ip: 192.168.0.24
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.933333333333334
    ram_util_percent: 73.24166666666666
  pid: 248786
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.085486101680958
    mean_inference_ms: 0.7892790630724301
    mean_processing_ms: 0.5548522317197903
  time_since_restore: 8.017215728759766
  time_this_iter_s: 8.017215728759766
  time_total_s: 8.017215728759766
  timestamp: 1744160447
  timesteps_since_restore: 675
  timesteps_this_iter: 675
  timesteps_total: 675
  training_iteration: 1
  trial_id: 089fd21e
  
== Status ==
Memory usage on this node: 11.3/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.81 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+---------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                 |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+---------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_089fd21e | RUNNING  | 192.168.0.24:248786 |      1 |          8.01722 |         675 |  72.8175 |
+---------------------------------+----------+---------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_089fd21e:
  custom_metrics: {}
  date: 2025-04-08_21-00-53
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 468.6534979510603
  episode_reward_mean: 42.3190700250918
  episode_reward_min: 7.852044218111107
  episodes_this_iter: 15
  episodes_total: 30
  experiment_id: d203ca0476e24a1e8591505f44877686
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 582.702
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 21.289356231689453
        entropy_coeff: 0.0
        kl: 0.010940205305814743
        policy_loss: -0.04285595566034317
        total_loss: 29.182048797607422
        vf_explained_var: 0.005901122000068426
        vf_loss: 29.22271728515625
    load_time_ms: 39.494
    num_steps_sampled: 1350
    num_steps_trained: 1350
    sample_time_ms: 5632.918
    update_time_ms: 541.053
  iterations_since_restore: 2
  node_ip: 192.168.0.24
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.9875
    ram_util_percent: 73.475
  pid: 248786
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.176178903715757
    mean_inference_ms: 0.7980813566857177
    mean_processing_ms: 0.5550003140935439
  time_since_restore: 13.695122480392456
  time_this_iter_s: 5.67790675163269
  time_total_s: 13.695122480392456
  timestamp: 1744160453
  timesteps_since_restore: 1350
  timesteps_this_iter: 675
  timesteps_total: 1350
  training_iteration: 2
  trial_id: 089fd21e
  
== Status ==
Memory usage on this node: 11.3/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.81 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+---------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                 |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+---------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_089fd21e | RUNNING  | 192.168.0.24:248786 |      2 |          13.6951 |        1350 |  42.3191 |
+---------------------------------+----------+---------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_089fd21e:
  custom_metrics: {}
  date: 2025-04-08_21-00-59
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 468.6534979510603
  episode_reward_mean: 30.741410222774004
  episode_reward_min: 5.500881891276171
  episodes_this_iter: 15
  episodes_total: 45
  experiment_id: d203ca0476e24a1e8591505f44877686
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 482.505
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 21.3134765625
        entropy_coeff: 0.0
        kl: 0.008078353479504585
        policy_loss: -0.03804699331521988
        total_loss: 11.19133186340332
        vf_explained_var: 0.01592215709388256
        vf_loss: 11.227763175964355
    load_time_ms: 26.678
    num_steps_sampled: 2025
    num_steps_trained: 2025
    sample_time_ms: 5590.127
    update_time_ms: 361.918
  iterations_since_restore: 3
  node_ip: 192.168.0.24
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.08888888888889
    ram_util_percent: 73.62222222222222
  pid: 248786
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.2522745658109455
    mean_inference_ms: 0.8050539843334062
    mean_processing_ms: 0.562103606304405
  time_since_restore: 19.489779472351074
  time_this_iter_s: 5.794656991958618
  time_total_s: 19.489779472351074
  timestamp: 1744160459
  timesteps_since_restore: 2025
  timesteps_this_iter: 675
  timesteps_total: 2025
  training_iteration: 3
  trial_id: 089fd21e
  
== Status ==
Memory usage on this node: 11.3/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.81 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+---------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                 |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+---------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_089fd21e | RUNNING  | 192.168.0.24:248786 |      3 |          19.4898 |        2025 |  30.7414 |
+---------------------------------+----------+---------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_089fd21e:
  custom_metrics: {}
  date: 2025-04-08_21-01-08
  done: true
  episode_len_mean: 45.0
  episode_reward_max: 468.6534979510603
  episode_reward_mean: 20.388067596781077
  episode_reward_min: 3.0658161654519764
  episodes_this_iter: 15
  episodes_total: 75
  experiment_id: d203ca0476e24a1e8591505f44877686
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 391.838
    learner:
      default_policy:
        cur_kl_coeff: 0.10000000149011612
        cur_lr: 4.999999873689376e-05
        entropy: 21.399728775024414
        entropy_coeff: 0.0
        kl: 0.010773754678666592
        policy_loss: -0.03859488293528557
        total_loss: 3.3106424808502197
        vf_explained_var: 0.024907009676098824
        vf_loss: 3.3481595516204834
    load_time_ms: 16.49
    num_steps_sampled: 3375
    num_steps_trained: 3375
    sample_time_ms: 5072.144
    update_time_ms: 218.652
  iterations_since_restore: 5
  node_ip: 192.168.0.24
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.214285714285715
    ram_util_percent: 73.47142857142856
  pid: 248786
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.174776405844034
    mean_inference_ms: 0.7878448292780494
    mean_processing_ms: 0.551956292091969
  time_since_restore: 28.60907483100891
  time_this_iter_s: 4.414830446243286
  time_total_s: 28.60907483100891
  timestamp: 1744160468
  timesteps_since_restore: 3375
  timesteps_this_iter: 675
  timesteps_total: 3375
  training_iteration: 5
  trial_id: 089fd21e
  
== Status ==
Memory usage on this node: 11.3/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/1.81 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 TERMINATED)
+---------------------------------+------------+-------+--------+------------------+-------------+----------+
| Trial name                      | status     | loc   |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+------------+-------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_089fd21e | TERMINATED |       |      5 |          28.6091 |        3375 |  20.3881 |
+---------------------------------+------------+-------+--------+------------------+-------------+----------+


== Status ==
Memory usage on this node: 11.3/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/1.81 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 TERMINATED)
+---------------------------------+------------+-------+--------+------------------+-------------+----------+
| Trial name                      | status     | loc   |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+------------+-------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_089fd21e | TERMINATED |       |      5 |          28.6091 |        3375 |  20.3881 |
+---------------------------------+------------+-------+--------+------------------+-------------+----------+


[2m[36m(pid=248787)[0m ./emissions_output/fleet_control_20250408-2100391744160439.569016-0_emission.csv ./emissions_output
