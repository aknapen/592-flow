flags Namespace(checkpoint_path=None, exp_config='flowagent', num_cpus=1, num_steps=50, rl_trainer='rllib', rollout_size=1000)
== Status ==
Memory usage on this node: 11.3/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.17 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+-------+
| Trial name                      | status   | loc   |
|---------------------------------+----------+-------|
| PPO_FleetControlEnv-v0_5c94fe90 | RUNNING  |       |
+---------------------------------+----------+-------+


[2m[36m(pid=280598)[0m 2025-04-09 10:38:57,574	INFO trainer.py:371 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution
[2m[36m(pid=280598)[0m 2025-04-09 10:38:57,904	INFO trainer.py:512 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=280598)[0m 2025-04-09 10:39:03,764	WARNING util.py:45 -- Install gputil for GPU system monitoring.
Result for PPO_FleetControlEnv-v0_5c94fe90:
  custom_metrics: {}
  date: 2025-04-09_10-39-08
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 425.820746645992
  episode_reward_mean: 161.88208905150856
  episode_reward_min: 44.78412360374343
  episodes_this_iter: 5
  episodes_total: 5
  experiment_id: 3ca26d47d03b4becbac533fd3b42208c
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 449.247
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 21.350706100463867
        entropy_coeff: 0.0
        kl: 0.0031463380437344313
        policy_loss: -0.027847077697515488
        total_loss: 323.3642578125
        vf_explained_var: 6.27517729299143e-05
        vf_loss: 323.3915100097656
    load_time_ms: 123.365
    num_steps_sampled: 225
    num_steps_trained: 225
    sample_time_ms: 2456.829
    update_time_ms: 1321.937
  iterations_since_restore: 1
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.08571428571429
    ram_util_percent: 77.62857142857142
  pid: 280598
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.791275159447595
    mean_inference_ms: 1.009288087355352
    mean_processing_ms: 0.7166261166597889
  time_since_restore: 4.421905279159546
  time_this_iter_s: 4.421905279159546
  time_total_s: 4.421905279159546
  timestamp: 1744209548
  timesteps_since_restore: 225
  timesteps_this_iter: 225
  timesteps_total: 225
  training_iteration: 1
  trial_id: 5c94fe90
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.17 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_5c94fe90 | RUNNING  | 35.3.43.231:280598 |      1 |          4.42191 |         225 |  161.882 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_5c94fe90:
  custom_metrics: {}
  date: 2025-04-09_10-39-14
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 425.820746645992
  episode_reward_mean: 50.61018994843882
  episode_reward_min: 11.021800955657456
  episodes_this_iter: 5
  episodes_total: 25
  experiment_id: 3ca26d47d03b4becbac533fd3b42208c
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 150.281
    learner:
      default_policy:
        cur_kl_coeff: 0.012500000186264515
        cur_lr: 4.999999873689376e-05
        entropy: 21.403850555419922
        entropy_coeff: 0.0
        kl: 0.0031015751883387566
        policy_loss: -0.029734324663877487
        total_loss: 1.121338129043579
        vf_explained_var: -0.014391588978469372
        vf_loss: 1.1510337591171265
    load_time_ms: 25.318
    num_steps_sampled: 1125
    num_steps_trained: 1125
    sample_time_ms: 1706.346
    update_time_ms: 267.238
  iterations_since_restore: 5
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.75
    ram_util_percent: 77.8
  pid: 280598
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.971595194511924
    mean_inference_ms: 0.8081496688835653
    mean_processing_ms: 0.5828221535754435
  time_since_restore: 10.827096462249756
  time_this_iter_s: 1.679032564163208
  time_total_s: 10.827096462249756
  timestamp: 1744209554
  timesteps_since_restore: 1125
  timesteps_this_iter: 225
  timesteps_total: 1125
  training_iteration: 5
  trial_id: 5c94fe90
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.17 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_5c94fe90 | RUNNING  | 35.3.43.231:280598 |      5 |          10.8271 |        1125 |  50.6102 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_5c94fe90:
  custom_metrics: {}
  date: 2025-04-09_10-39-20
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 425.820746645992
  episode_reward_mean: 34.82515268365356
  episode_reward_min: 5.45980450645773
  episodes_this_iter: 5
  episodes_total: 40
  experiment_id: 3ca26d47d03b4becbac533fd3b42208c
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 127.362
    learner:
      default_policy:
        cur_kl_coeff: 0.0015625000232830644
        cur_lr: 4.999999873689376e-05
        entropy: 21.43695068359375
        entropy_coeff: 0.0
        kl: 0.0029534357599914074
        policy_loss: -0.03831537812948227
        total_loss: 0.2477768361568451
        vf_explained_var: -0.001405954360961914
        vf_loss: 0.28608760237693787
    load_time_ms: 16.171
    num_steps_sampled: 1800
    num_steps_trained: 1800
    sample_time_ms: 1767.208
    update_time_ms: 168.356
  iterations_since_restore: 8
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.924999999999997
    ram_util_percent: 77.675
  pid: 280598
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.95605462040412
    mean_inference_ms: 0.7862105595245816
    mean_processing_ms: 0.5651402994552976
  time_since_restore: 16.723079442977905
  time_this_iter_s: 2.3692054748535156
  time_total_s: 16.723079442977905
  timestamp: 1744209560
  timesteps_since_restore: 1800
  timesteps_this_iter: 225
  timesteps_total: 1800
  training_iteration: 8
  trial_id: 5c94fe90
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.17 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_5c94fe90 | RUNNING  | 35.3.43.231:280598 |      8 |          16.7231 |        1800 |  34.8252 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_5c94fe90:
  custom_metrics: {}
  date: 2025-04-09_10-39-26
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 425.820746645992
  episode_reward_mean: 26.993132195460205
  episode_reward_min: 4.052886470874274
  episodes_this_iter: 5
  episodes_total: 55
  experiment_id: 3ca26d47d03b4becbac533fd3b42208c
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.58
    learner:
      default_policy:
        cur_kl_coeff: 0.00019531250291038305
        cur_lr: 4.999999873689376e-05
        entropy: 21.441314697265625
        entropy_coeff: 0.0
        kl: 0.005683251656591892
        policy_loss: -0.052737582474946976
        total_loss: 0.09609650075435638
        vf_explained_var: -0.05461101606488228
        vf_loss: 0.14883297681808472
    load_time_ms: 1.1
    num_steps_sampled: 2475
    num_steps_trained: 2475
    sample_time_ms: 1742.021
    update_time_ms: 3.827
  iterations_since_restore: 11
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.7
    ram_util_percent: 77.6
  pid: 280598
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.045179767906634
    mean_inference_ms: 0.7861755174171497
    mean_processing_ms: 0.5664930317168667
  time_since_restore: 22.828314781188965
  time_this_iter_s: 2.3207454681396484
  time_total_s: 22.828314781188965
  timestamp: 1744209566
  timesteps_since_restore: 2475
  timesteps_this_iter: 225
  timesteps_total: 2475
  training_iteration: 11
  trial_id: 5c94fe90
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.17 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_5c94fe90 | RUNNING  | 35.3.43.231:280598 |     11 |          22.8283 |        2475 |  26.9931 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_5c94fe90:
  custom_metrics: {}
  date: 2025-04-09_10-39-32
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 425.820746645992
  episode_reward_mean: 22.15428186627384
  episode_reward_min: 2.76733579119238
  episodes_this_iter: 5
  episodes_total: 70
  experiment_id: 3ca26d47d03b4becbac533fd3b42208c
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.635
    learner:
      default_policy:
        cur_kl_coeff: 2.441406286379788e-05
        cur_lr: 4.999999873689376e-05
        entropy: 21.45484161376953
        entropy_coeff: 0.0
        kl: 0.0027473585214465857
        policy_loss: -0.038623400032520294
        total_loss: 0.028284573927521706
        vf_explained_var: -0.015030408278107643
        vf_loss: 0.06690791249275208
    load_time_ms: 1.139
    num_steps_sampled: 3150
    num_steps_trained: 3150
    sample_time_ms: 1813.888
    update_time_ms: 3.903
  iterations_since_restore: 14
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.799999999999997
    ram_util_percent: 77.6
  pid: 280598
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.124878885906483
    mean_inference_ms: 0.7903671498770168
    mean_processing_ms: 0.5695474822589215
  time_since_restore: 28.287353992462158
  time_this_iter_s: 1.7295048236846924
  time_total_s: 28.287353992462158
  timestamp: 1744209572
  timesteps_since_restore: 3150
  timesteps_this_iter: 225
  timesteps_total: 3150
  training_iteration: 14
  trial_id: 5c94fe90
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.17 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_5c94fe90 | RUNNING  | 35.3.43.231:280598 |     14 |          28.2874 |        3150 |  22.1543 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_5c94fe90:
  custom_metrics: {}
  date: 2025-04-09_10-39-37
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 425.820746645992
  episode_reward_mean: 18.900730127267412
  episode_reward_min: 2.637064237556936
  episodes_this_iter: 5
  episodes_total: 85
  experiment_id: 3ca26d47d03b4becbac533fd3b42208c
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 95.146
    learner:
      default_policy:
        cur_kl_coeff: 3.051757857974735e-06
        cur_lr: 4.999999873689376e-05
        entropy: 21.35748863220215
        entropy_coeff: 0.0
        kl: 0.0025782587472349405
        policy_loss: -0.03111450746655464
        total_loss: 0.018549486994743347
        vf_explained_var: -0.042511485517024994
        vf_loss: 0.049663983285427094
    load_time_ms: 1.163
    num_steps_sampled: 3825
    num_steps_trained: 3825
    sample_time_ms: 1807.828
    update_time_ms: 4.102
  iterations_since_restore: 17
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.233333333333334
    ram_util_percent: 77.6
  pid: 280598
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.158172189123141
    mean_inference_ms: 0.7903918038088895
    mean_processing_ms: 0.5699345472491167
  time_since_restore: 33.470919609069824
  time_this_iter_s: 1.8659729957580566
  time_total_s: 33.470919609069824
  timestamp: 1744209577
  timesteps_since_restore: 3825
  timesteps_this_iter: 225
  timesteps_total: 3825
  training_iteration: 17
  trial_id: 5c94fe90
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.17 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_5c94fe90 | RUNNING  | 35.3.43.231:280598 |     17 |          33.4709 |        3825 |  18.9007 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_5c94fe90:
  custom_metrics: {}
  date: 2025-04-09_10-39-43
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 425.820746645992
  episode_reward_mean: 16.461681934471677
  episode_reward_min: 1.919716389942832
  episodes_this_iter: 5
  episodes_total: 100
  experiment_id: 3ca26d47d03b4becbac533fd3b42208c
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.714
    learner:
      default_policy:
        cur_kl_coeff: 3.814697322468419e-07
        cur_lr: 4.999999873689376e-05
        entropy: 21.371164321899414
        entropy_coeff: 0.0
        kl: 0.006922388914972544
        policy_loss: -0.04348887875676155
        total_loss: -0.031266339123249054
        vf_explained_var: -0.0027312636375427246
        vf_loss: 0.0122225321829319
    load_time_ms: 1.099
    num_steps_sampled: 4500
    num_steps_trained: 4500
    sample_time_ms: 1753.004
    update_time_ms: 3.76
  iterations_since_restore: 20
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.03333333333333
    ram_util_percent: 77.6
  pid: 280598
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.178694977985412
    mean_inference_ms: 0.7901308565852468
    mean_processing_ms: 0.569486332662275
  time_since_restore: 39.02656292915344
  time_this_iter_s: 1.8561160564422607
  time_total_s: 39.02656292915344
  timestamp: 1744209583
  timesteps_since_restore: 4500
  timesteps_this_iter: 225
  timesteps_total: 4500
  training_iteration: 20
  trial_id: 5c94fe90
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.17 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_5c94fe90 | RUNNING  | 35.3.43.231:280598 |     20 |          39.0266 |        4500 |  16.4617 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_5c94fe90:
  custom_metrics: {}
  date: 2025-04-09_10-39-48
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 20.341562030533307
  episode_reward_mean: 5.69550959191959
  episode_reward_min: 1.919716389942832
  episodes_this_iter: 5
  episodes_total: 115
  experiment_id: 3ca26d47d03b4becbac533fd3b42208c
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.484
    learner:
      default_policy:
        cur_kl_coeff: 9.536743306171047e-08
        cur_lr: 4.999999873689376e-05
        entropy: 21.23952293395996
        entropy_coeff: 0.0
        kl: 0.008402918465435505
        policy_loss: -0.04585700109601021
        total_loss: -0.03079560399055481
        vf_explained_var: -0.009700119495391846
        vf_loss: 0.015061411075294018
    load_time_ms: 1.037
    num_steps_sampled: 5175
    num_steps_trained: 5175
    sample_time_ms: 1669.389
    update_time_ms: 3.735
  iterations_since_restore: 23
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.3
    ram_util_percent: 77.65
  pid: 280598
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.209304816178771
    mean_inference_ms: 0.7809199932263247
    mean_processing_ms: 0.5620260229817126
  time_since_restore: 44.23639106750488
  time_this_iter_s: 1.7708466053009033
  time_total_s: 44.23639106750488
  timestamp: 1744209588
  timesteps_since_restore: 5175
  timesteps_this_iter: 225
  timesteps_total: 5175
  training_iteration: 23
  trial_id: 5c94fe90
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.17 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_5c94fe90 | RUNNING  | 35.3.43.231:280598 |     23 |          44.2364 |        5175 |  5.69551 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_5c94fe90:
  custom_metrics: {}
  date: 2025-04-09_10-39-54
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 8.791872799128182
  episode_reward_mean: 3.7248335007622213
  episode_reward_min: 1.4985919949471607
  episodes_this_iter: 5
  episodes_total: 135
  experiment_id: 3ca26d47d03b4becbac533fd3b42208c
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 82.24
    learner:
      default_policy:
        cur_kl_coeff: 2.3841858265427618e-08
        cur_lr: 4.999999873689376e-05
        entropy: 20.965551376342773
        entropy_coeff: 0.0
        kl: 0.00821346789598465
        policy_loss: -0.049380283802747726
        total_loss: -0.03812902420759201
        vf_explained_var: -0.02498689852654934
        vf_loss: 0.011251267977058887
    load_time_ms: 0.947
    num_steps_sampled: 6075
    num_steps_trained: 6075
    sample_time_ms: 1552.288
    update_time_ms: 3.633
  iterations_since_restore: 27
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.75
    ram_util_percent: 77.6
  pid: 280598
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.275453279095895
    mean_inference_ms: 0.7874244011691087
    mean_processing_ms: 0.5665924210860525
  time_since_restore: 49.89127516746521
  time_this_iter_s: 1.4457223415374756
  time_total_s: 49.89127516746521
  timestamp: 1744209594
  timesteps_since_restore: 6075
  timesteps_this_iter: 225
  timesteps_total: 6075
  training_iteration: 27
  trial_id: 5c94fe90
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.17 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_5c94fe90 | RUNNING  | 35.3.43.231:280598 |     27 |          49.8913 |        6075 |  3.72483 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_5c94fe90:
  custom_metrics: {}
  date: 2025-04-09_10-39-59
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 6.742758217435764
  episode_reward_mean: 2.8283071329308176
  episode_reward_min: 1.4063334434922856
  episodes_this_iter: 5
  episodes_total: 155
  experiment_id: 3ca26d47d03b4becbac533fd3b42208c
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 76.683
    learner:
      default_policy:
        cur_kl_coeff: 5.9604645663569045e-09
        cur_lr: 4.999999873689376e-05
        entropy: 20.930103302001953
        entropy_coeff: 0.0
        kl: 0.006602237932384014
        policy_loss: -0.04239664599299431
        total_loss: -0.032693661749362946
        vf_explained_var: -0.0016429662937298417
        vf_loss: 0.009702996350824833
    load_time_ms: 0.839
    num_steps_sampled: 6975
    num_steps_trained: 6975
    sample_time_ms: 1397.183
    update_time_ms: 3.178
  iterations_since_restore: 31
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.0
    ram_util_percent: 77.5
  pid: 280598
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.215958390127596
    mean_inference_ms: 0.7799000744231713
    mean_processing_ms: 0.5604106159978788
  time_since_restore: 55.58677864074707
  time_this_iter_s: 1.4964563846588135
  time_total_s: 55.58677864074707
  timestamp: 1744209599
  timesteps_since_restore: 6975
  timesteps_this_iter: 225
  timesteps_total: 6975
  training_iteration: 31
  trial_id: 5c94fe90
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.17 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_5c94fe90 | RUNNING  | 35.3.43.231:280598 |     31 |          55.5868 |        6975 |  2.82831 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_5c94fe90:
  custom_metrics: {}
  date: 2025-04-09_10-40-05
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 4.5697501348196505
  episode_reward_mean: 2.2918823286513232
  episode_reward_min: 1.2333611979439758
  episodes_this_iter: 5
  episodes_total: 175
  experiment_id: 3ca26d47d03b4becbac533fd3b42208c
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 73.802
    learner:
      default_policy:
        cur_kl_coeff: 1.4901161415892261e-09
        cur_lr: 4.999999873689376e-05
        entropy: 20.85529327392578
        entropy_coeff: 0.0
        kl: 0.010615228675305843
        policy_loss: -0.05852299928665161
        total_loss: -0.05079101398587227
        vf_explained_var: -0.07817316055297852
        vf_loss: 0.007731985300779343
    load_time_ms: 0.799
    num_steps_sampled: 7875
    num_steps_trained: 7875
    sample_time_ms: 1384.914
    update_time_ms: 3.294
  iterations_since_restore: 35
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.35
    ram_util_percent: 77.7
  pid: 280598
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.107908728421485
    mean_inference_ms: 0.7653044796923751
    mean_processing_ms: 0.5496642484747296
  time_since_restore: 61.68076014518738
  time_this_iter_s: 1.6636855602264404
  time_total_s: 61.68076014518738
  timestamp: 1744209605
  timesteps_since_restore: 7875
  timesteps_this_iter: 225
  timesteps_total: 7875
  training_iteration: 35
  trial_id: 5c94fe90
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.17 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_5c94fe90 | RUNNING  | 35.3.43.231:280598 |     35 |          61.6808 |        7875 |  2.29188 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_5c94fe90:
  custom_metrics: {}
  date: 2025-04-09_10-40-12
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 3.759841572782569
  episode_reward_mean: 1.931309191705454
  episode_reward_min: 1.0480018371676116
  episodes_this_iter: 5
  episodes_total: 195
  experiment_id: 3ca26d47d03b4becbac533fd3b42208c
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 73.642
    learner:
      default_policy:
        cur_kl_coeff: 1.8626451769865326e-10
        cur_lr: 4.999999873689376e-05
        entropy: 20.974668502807617
        entropy_coeff: 0.0
        kl: 0.006570346653461456
        policy_loss: -0.04418521746993065
        total_loss: -0.0380631759762764
        vf_explained_var: 0.04543589428067207
        vf_loss: 0.006122038699686527
    load_time_ms: 0.827
    num_steps_sampled: 8775
    num_steps_trained: 8775
    sample_time_ms: 1476.08
    update_time_ms: 3.159
  iterations_since_restore: 39
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.433333333333334
    ram_util_percent: 77.76666666666667
  pid: 280598
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 6.013292354286363
    mean_inference_ms: 0.7522302045932707
    mean_processing_ms: 0.5411337588408854
  time_since_restore: 68.29061818122864
  time_this_iter_s: 2.0556771755218506
  time_total_s: 68.29061818122864
  timestamp: 1744209612
  timesteps_since_restore: 8775
  timesteps_this_iter: 225
  timesteps_total: 8775
  training_iteration: 39
  trial_id: 5c94fe90
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.17 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_5c94fe90 | RUNNING  | 35.3.43.231:280598 |     39 |          68.2906 |        8775 |  1.93131 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_5c94fe90:
  custom_metrics: {}
  date: 2025-04-09_10-40-17
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 2.8755888851345293
  episode_reward_mean: 1.742057524767681
  episode_reward_min: 1.0480018371676116
  episodes_this_iter: 5
  episodes_total: 210
  experiment_id: 3ca26d47d03b4becbac533fd3b42208c
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 78.46
    learner:
      default_policy:
        cur_kl_coeff: 2.3283064712331658e-11
        cur_lr: 4.999999873689376e-05
        entropy: 21.09817123413086
        entropy_coeff: 0.0
        kl: 0.009981866925954819
        policy_loss: -0.04817330092191696
        total_loss: -0.043326668441295624
        vf_explained_var: 0.065107561647892
        vf_loss: 0.004846630152314901
    load_time_ms: 0.872
    num_steps_sampled: 9450
    num_steps_trained: 9450
    sample_time_ms: 1554.796
    update_time_ms: 3.267
  iterations_since_restore: 42
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.65
    ram_util_percent: 77.7
  pid: 280598
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.9442793298188334
    mean_inference_ms: 0.7421170797143759
    mean_processing_ms: 0.5353205756615361
  time_since_restore: 73.39339756965637
  time_this_iter_s: 1.61580228805542
  time_total_s: 73.39339756965637
  timestamp: 1744209617
  timesteps_since_restore: 9450
  timesteps_this_iter: 225
  timesteps_total: 9450
  training_iteration: 42
  trial_id: 5c94fe90
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.17 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_5c94fe90 | RUNNING  | 35.3.43.231:280598 |     42 |          73.3934 |        9450 |  1.74206 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_5c94fe90:
  custom_metrics: {}
  date: 2025-04-09_10-40-24
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 2.4551536157140132
  episode_reward_mean: 1.5650941840026436
  episode_reward_min: 0.8811032765093181
  episodes_this_iter: 5
  episodes_total: 225
  experiment_id: 3ca26d47d03b4becbac533fd3b42208c
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.644
    learner:
      default_policy:
        cur_kl_coeff: 2.9103830890414573e-12
        cur_lr: 4.999999873689376e-05
        entropy: 20.86797523498535
        entropy_coeff: 0.0
        kl: 0.013397055678069592
        policy_loss: -0.07072566449642181
        total_loss: -0.06686579436063766
        vf_explained_var: 0.16110515594482422
        vf_loss: 0.0038598752580583096
    load_time_ms: 0.921
    num_steps_sampled: 10125
    num_steps_trained: 10125
    sample_time_ms: 1733.169
    update_time_ms: 3.628
  iterations_since_restore: 45
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.45
    ram_util_percent: 77.9
  pid: 280598
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.898537491759243
    mean_inference_ms: 0.7348566224597362
    mean_processing_ms: 0.5315361497569672
  time_since_restore: 79.99215722084045
  time_this_iter_s: 1.9908320903778076
  time_total_s: 79.99215722084045
  timestamp: 1744209624
  timesteps_since_restore: 10125
  timesteps_this_iter: 225
  timesteps_total: 10125
  training_iteration: 45
  trial_id: 5c94fe90
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.17 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_5c94fe90 | RUNNING  | 35.3.43.231:280598 |     45 |          79.9922 |       10125 |  1.56509 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_5c94fe90:
  custom_metrics: {}
  date: 2025-04-09_10-40-30
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 2.393323941784747
  episode_reward_mean: 1.4534817316596849
  episode_reward_min: 0.8811032765093181
  episodes_this_iter: 5
  episodes_total: 240
  experiment_id: 3ca26d47d03b4becbac533fd3b42208c
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 96.9
    learner:
      default_policy:
        cur_kl_coeff: 2.9103830890414573e-12
        cur_lr: 4.999999873689376e-05
        entropy: 20.684558868408203
        entropy_coeff: 0.0
        kl: 0.008733931928873062
        policy_loss: -0.047976285219192505
        total_loss: -0.04453190416097641
        vf_explained_var: 0.15726660192012787
        vf_loss: 0.003444376867264509
    load_time_ms: 0.977
    num_steps_sampled: 10800
    num_steps_trained: 10800
    sample_time_ms: 1893.9
    update_time_ms: 3.874
  iterations_since_restore: 48
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.05
    ram_util_percent: 78.0
  pid: 280598
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.889425104064863
    mean_inference_ms: 0.7327608866524217
    mean_processing_ms: 0.5315839547252295
  time_since_restore: 86.23213601112366
  time_this_iter_s: 1.8742930889129639
  time_total_s: 86.23213601112366
  timestamp: 1744209630
  timesteps_since_restore: 10800
  timesteps_this_iter: 225
  timesteps_total: 10800
  training_iteration: 48
  trial_id: 5c94fe90
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.17 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_5c94fe90 | RUNNING  | 35.3.43.231:280598 |     48 |          86.2321 |       10800 |  1.45348 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_5c94fe90:
  custom_metrics: {}
  date: 2025-04-09_10-40-33
  done: true
  episode_len_mean: 45.0
  episode_reward_max: 1.9379171370639328
  episode_reward_mean: 1.3866660604799688
  episode_reward_min: 0.8811032765093181
  episodes_this_iter: 5
  episodes_total: 250
  experiment_id: 3ca26d47d03b4becbac533fd3b42208c
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 95.675
    learner:
      default_policy:
        cur_kl_coeff: 1.4551915445207286e-12
        cur_lr: 4.999999873689376e-05
        entropy: 20.764026641845703
        entropy_coeff: 0.0
        kl: 0.010353345423936844
        policy_loss: -0.048179805278778076
        total_loss: -0.04528183862566948
        vf_explained_var: 0.19540292024612427
        vf_loss: 0.0028979552444070578
    load_time_ms: 0.961
    num_steps_sampled: 11250
    num_steps_trained: 11250
    sample_time_ms: 1839.084
    update_time_ms: 3.961
  iterations_since_restore: 50
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.25
    ram_util_percent: 77.85
  pid: 280598
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.8941400881747015
    mean_inference_ms: 0.7329158336786215
    mean_processing_ms: 0.5327162559556505
  time_since_restore: 89.51903963088989
  time_this_iter_s: 1.6901185512542725
  time_total_s: 89.51903963088989
  timestamp: 1744209633
  timesteps_since_restore: 11250
  timesteps_this_iter: 225
  timesteps_total: 11250
  training_iteration: 50
  trial_id: 5c94fe90
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/1.17 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 TERMINATED)
+---------------------------------+------------+-------+--------+------------------+-------------+----------+
| Trial name                      | status     | loc   |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+------------+-------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_5c94fe90 | TERMINATED |       |     50 |           89.519 |       11250 |  1.38667 |
+---------------------------------+------------+-------+--------+------------------+-------------+----------+


[2m[36m(pid=280597)[0m ./emissions_output/fleet_control_20250409-1039031744209543.4000492-0_emission.csv ./emissions_output
