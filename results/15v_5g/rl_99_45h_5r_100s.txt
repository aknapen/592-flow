flags Namespace(checkpoint_path=None, exp_config='flowagent', num_cpus=1, num_steps=100, rl_trainer='rllib', rollout_size=1000)
== Status ==
Memory usage on this node: 11.2/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+-------+
| Trial name                      | status   | loc   |
|---------------------------------+----------+-------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  |       |
+---------------------------------+----------+-------+


[2m[36m(pid=291596)[0m 2025-04-09 12:25:36,440	INFO trainer.py:371 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution
[2m[36m(pid=291596)[0m 2025-04-09 12:25:36,663	INFO trainer.py:512 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=291596)[0m 2025-04-09 12:25:41,221	WARNING util.py:45 -- Install gputil for GPU system monitoring.
Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-25-45
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 438.06901011301204
  episode_reward_mean: 150.63407838169465
  episode_reward_min: 47.94625862026528
  episodes_this_iter: 5
  episodes_total: 5
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 567.449
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 21.3892765045166
        entropy_coeff: 0.0
        kl: 0.0028017410077154636
        policy_loss: -0.028224075213074684
        total_loss: 6240.9931640625
        vf_explained_var: 6.23822197667323e-05
        vf_loss: 6241.0205078125
    load_time_ms: 82.687
    num_steps_sampled: 225
    num_steps_trained: 225
    sample_time_ms: 2419.112
    update_time_ms: 902.43
  iterations_since_restore: 1
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.916666666666668
    ram_util_percent: 77.11666666666666
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.018668892109289
    mean_inference_ms: 0.7766073783942028
    mean_processing_ms: 0.4402420162099653
  time_since_restore: 4.067303657531738
  time_this_iter_s: 4.067303657531738
  time_total_s: 4.067303657531738
  timestamp: 1744215945
  timesteps_since_restore: 225
  timesteps_this_iter: 225
  timesteps_total: 225
  training_iteration: 1
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |      1 |           4.0673 |         225 |  150.634 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-25-50
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 438.06901011301204
  episode_reward_mean: 55.09217500133436
  episode_reward_min: 11.475064597944355
  episodes_this_iter: 5
  episodes_total: 20
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 225.076
    learner:
      default_policy:
        cur_kl_coeff: 0.02500000037252903
        cur_lr: 4.999999873689376e-05
        entropy: 21.621082305908203
        entropy_coeff: 0.0
        kl: 0.004248355515301228
        policy_loss: -0.04215792566537857
        total_loss: 44.05690002441406
        vf_explained_var: 0.000992941902950406
        vf_loss: 44.09894943237305
    load_time_ms: 21.464
    num_steps_sampled: 900
    num_steps_trained: 900
    sample_time_ms: 1783.92
    update_time_ms: 228.83
  iterations_since_restore: 4
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.266666666666666
    ram_util_percent: 77.73333333333333
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.479275707214692
    mean_inference_ms: 0.7616314525318023
    mean_processing_ms: 0.4982816819778135
  time_since_restore: 9.143579244613647
  time_this_iter_s: 1.6051537990570068
  time_total_s: 9.143579244613647
  timestamp: 1744215950
  timesteps_since_restore: 900
  timesteps_this_iter: 225
  timesteps_total: 900
  training_iteration: 4
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |      4 |          9.14358 |         900 |  55.0922 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-25-55
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 438.06901011301204
  episode_reward_mean: 36.2198963495301
  episode_reward_min: 8.591275756142412
  episodes_this_iter: 5
  episodes_total: 35
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 165.612
    learner:
      default_policy:
        cur_kl_coeff: 0.0031250000465661287
        cur_lr: 4.999999873689376e-05
        entropy: 21.52842140197754
        entropy_coeff: 0.0
        kl: 0.0041750529780983925
        policy_loss: -0.03590736165642738
        total_loss: 13.61363410949707
        vf_explained_var: 0.006739520933479071
        vf_loss: 13.649526596069336
    load_time_ms: 12.679
    num_steps_sampled: 1575
    num_steps_trained: 1575
    sample_time_ms: 1727.061
    update_time_ms: 132.219
  iterations_since_restore: 7
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.3
    ram_util_percent: 77.7
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.57449009212304
    mean_inference_ms: 0.7542058257726434
    mean_processing_ms: 0.5101141655822028
  time_since_restore: 14.378607988357544
  time_this_iter_s: 1.6505539417266846
  time_total_s: 14.378607988357544
  timestamp: 1744215955
  timesteps_since_restore: 1575
  timesteps_this_iter: 225
  timesteps_total: 1575
  training_iteration: 7
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |      7 |          14.3786 |        1575 |  36.2199 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-26-01
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 438.06901011301204
  episode_reward_mean: 27.33106900346329
  episode_reward_min: 4.573688981899163
  episodes_this_iter: 5
  episodes_total: 50
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 143.015
    learner:
      default_policy:
        cur_kl_coeff: 0.0003906250058207661
        cur_lr: 4.999999873689376e-05
        entropy: 21.456987380981445
        entropy_coeff: 0.0
        kl: 0.0036098721902817488
        policy_loss: -0.037205152213573456
        total_loss: 4.718785762786865
        vf_explained_var: 0.0011146903270855546
        vf_loss: 4.755990028381348
    load_time_ms: 9.165
    num_steps_sampled: 2250
    num_steps_trained: 2250
    sample_time_ms: 1716.208
    update_time_ms: 93.64
  iterations_since_restore: 10
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.899999999999995
    ram_util_percent: 77.4
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.652816998665519
    mean_inference_ms: 0.7500186097031658
    mean_processing_ms: 0.5195174364656991
  time_since_restore: 19.745300769805908
  time_this_iter_s: 1.769057273864746
  time_total_s: 19.745300769805908
  timestamp: 1744215961
  timesteps_since_restore: 2250
  timesteps_this_iter: 225
  timesteps_total: 2250
  training_iteration: 10
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     10 |          19.7453 |        2250 |  27.3311 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-26-06
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 438.06901011301204
  episode_reward_mean: 22.228842090454123
  episode_reward_min: 3.2989707143147626
  episodes_this_iter: 5
  episodes_total: 65
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 94.254
    learner:
      default_policy:
        cur_kl_coeff: 4.882812572759576e-05
        cur_lr: 4.999999873689376e-05
        entropy: 21.559738159179688
        entropy_coeff: 0.0
        kl: 0.005418017040938139
        policy_loss: -0.05535934120416641
        total_loss: 3.062593936920166
        vf_explained_var: 0.017856299877166748
        vf_loss: 3.117952823638916
    load_time_ms: 1.026
    num_steps_sampled: 2925
    num_steps_trained: 2925
    sample_time_ms: 1628.942
    update_time_ms: 3.637
  iterations_since_restore: 13
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.0
    ram_util_percent: 77.45
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.704223942440544
    mean_inference_ms: 0.7482139066622284
    mean_processing_ms: 0.5256267502224733
  time_since_restore: 24.849851608276367
  time_this_iter_s: 1.6272368431091309
  time_total_s: 24.849851608276367
  timestamp: 1744215966
  timesteps_since_restore: 2925
  timesteps_this_iter: 225
  timesteps_total: 2925
  training_iteration: 13
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     13 |          24.8499 |        2925 |  22.2288 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-26-12
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 438.06901011301204
  episode_reward_mean: 17.993605332479127
  episode_reward_min: 3.1708126745132637
  episodes_this_iter: 5
  episodes_total: 85
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 86.782
    learner:
      default_policy:
        cur_kl_coeff: 3.051757857974735e-06
        cur_lr: 4.999999873689376e-05
        entropy: 21.66165542602539
        entropy_coeff: 0.0
        kl: 0.005855927709490061
        policy_loss: -0.054354287683963776
        total_loss: 2.065495491027832
        vf_explained_var: 0.03053579293191433
        vf_loss: 2.119849681854248
    load_time_ms: 1.035
    num_steps_sampled: 3825
    num_steps_trained: 3825
    sample_time_ms: 1620.99
    update_time_ms: 3.616
  iterations_since_restore: 17
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.566666666666663
    ram_util_percent: 77.43333333333334
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.738241352083712
    mean_inference_ms: 0.7450489508920521
    mean_processing_ms: 0.5277661336119911
  time_since_restore: 31.534173011779785
  time_this_iter_s: 1.7631611824035645
  time_total_s: 31.534173011779785
  timestamp: 1744215972
  timesteps_since_restore: 3825
  timesteps_this_iter: 225
  timesteps_total: 3825
  training_iteration: 17
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     17 |          31.5342 |        3825 |  17.9936 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-26-18
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 438.06901011301204
  episode_reward_mean: 15.854507890207078
  episode_reward_min: 2.9772910251697295
  episodes_this_iter: 5
  episodes_total: 100
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 88.06
    learner:
      default_policy:
        cur_kl_coeff: 3.814697322468419e-07
        cur_lr: 4.999999873689376e-05
        entropy: 21.581958770751953
        entropy_coeff: 0.0
        kl: 0.006451403256505728
        policy_loss: -0.050110239535570145
        total_loss: 1.735687017440796
        vf_explained_var: 0.04457513242959976
        vf_loss: 1.785797119140625
    load_time_ms: 1.106
    num_steps_sampled: 4500
    num_steps_trained: 4500
    sample_time_ms: 1673.435
    update_time_ms: 3.701
  iterations_since_restore: 20
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.55
    ram_util_percent: 77.55
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.769359596281509
    mean_inference_ms: 0.7454980657681748
    mean_processing_ms: 0.529281441448248
  time_since_restore: 37.44115686416626
  time_this_iter_s: 1.8454699516296387
  time_total_s: 37.44115686416626
  timestamp: 1744215978
  timesteps_since_restore: 4500
  timesteps_this_iter: 225
  timesteps_total: 4500
  training_iteration: 20
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     20 |          37.4412 |        4500 |  15.8545 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-26-25
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 15.970020109201442
  episode_reward_mean: 5.484283954410077
  episode_reward_min: 2.4937790045301145
  episodes_this_iter: 5
  episodes_total: 120
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 86.502
    learner:
      default_policy:
        cur_kl_coeff: 2.3841858265427618e-08
        cur_lr: 4.999999873689376e-05
        entropy: 21.617420196533203
        entropy_coeff: 0.0
        kl: 0.004309090785682201
        policy_loss: -0.045323219150304794
        total_loss: 0.9216479063034058
        vf_explained_var: 0.05661644786596298
        vf_loss: 0.9669710397720337
    load_time_ms: 1.056
    num_steps_sampled: 5400
    num_steps_trained: 5400
    sample_time_ms: 1641.346
    update_time_ms: 3.634
  iterations_since_restore: 24
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.85
    ram_util_percent: 77.5
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.860927210296622
    mean_inference_ms: 0.7430510855926307
    mean_processing_ms: 0.5363666565909376
  time_since_restore: 43.80459022521973
  time_this_iter_s: 1.614466905593872
  time_total_s: 43.80459022521973
  timestamp: 1744215985
  timesteps_since_restore: 5400
  timesteps_this_iter: 225
  timesteps_total: 5400
  training_iteration: 24
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     24 |          43.8046 |        5400 |  5.48428 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-26-32
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 8.165653696310006
  episode_reward_mean: 4.089686494805291
  episode_reward_min: 2.276760405806038
  episodes_this_iter: 5
  episodes_total: 140
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 85.422
    learner:
      default_policy:
        cur_kl_coeff: 1.4901161415892261e-09
        cur_lr: 4.999999873689376e-05
        entropy: 21.83614730834961
        entropy_coeff: 0.0
        kl: 0.006845306605100632
        policy_loss: -0.05872419476509094
        total_loss: 0.6908204555511475
        vf_explained_var: 0.06187625974416733
        vf_loss: 0.7495446801185608
    load_time_ms: 1.026
    num_steps_sampled: 6300
    num_steps_trained: 6300
    sample_time_ms: 1627.548
    update_time_ms: 3.646
  iterations_since_restore: 28
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.400000000000002
    ram_util_percent: 77.26666666666667
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.8920408747166695
    mean_inference_ms: 0.7430557907637569
    mean_processing_ms: 0.5366805145932585
  time_since_restore: 50.61896896362305
  time_this_iter_s: 1.9502489566802979
  time_total_s: 50.61896896362305
  timestamp: 1744215992
  timesteps_since_restore: 6300
  timesteps_this_iter: 225
  timesteps_total: 6300
  training_iteration: 28
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     28 |           50.619 |        6300 |  4.08969 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-26-37
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 6.562416545214343
  episode_reward_mean: 3.5896393337590764
  episode_reward_min: 2.1398557856898437
  episodes_this_iter: 5
  episodes_total: 155
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 85.839
    learner:
      default_policy:
        cur_kl_coeff: 1.8626451769865326e-10
        cur_lr: 4.999999873689376e-05
        entropy: 21.769763946533203
        entropy_coeff: 0.0
        kl: 0.008666137233376503
        policy_loss: -0.05783308297395706
        total_loss: 0.47989463806152344
        vf_explained_var: 0.09137459844350815
        vf_loss: 0.5377277135848999
    load_time_ms: 1.041
    num_steps_sampled: 6975
    num_steps_trained: 6975
    sample_time_ms: 1559.395
    update_time_ms: 3.558
  iterations_since_restore: 31
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.9
    ram_util_percent: 77.9
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.894467607817116
    mean_inference_ms: 0.74323601987139
    mean_processing_ms: 0.5348012469557744
  time_since_restore: 55.6711905002594
  time_this_iter_s: 1.7598755359649658
  time_total_s: 55.6711905002594
  timestamp: 1744215997
  timesteps_since_restore: 6975
  timesteps_this_iter: 225
  timesteps_total: 6975
  training_iteration: 31
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     31 |          55.6712 |        6975 |  3.58964 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-26-43
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 5.17479221690506
  episode_reward_mean: 3.154792745418376
  episode_reward_min: 1.8621798021518983
  episodes_this_iter: 5
  episodes_total: 175
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 88.178
    learner:
      default_policy:
        cur_kl_coeff: 1.1641532356165829e-11
        cur_lr: 4.999999873689376e-05
        entropy: 22.112192153930664
        entropy_coeff: 0.0
        kl: 0.006600899156183004
        policy_loss: -0.04636745527386665
        total_loss: 0.35480302572250366
        vf_explained_var: 0.07875096797943115
        vf_loss: 0.4011704921722412
    load_time_ms: 1.066
    num_steps_sampled: 7875
    num_steps_trained: 7875
    sample_time_ms: 1582.688
    update_time_ms: 3.912
  iterations_since_restore: 35
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.5
    ram_util_percent: 77.1
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.890163227208402
    mean_inference_ms: 0.7433274400543743
    mean_processing_ms: 0.5331909201966449
  time_since_restore: 62.169700622558594
  time_this_iter_s: 1.8721084594726562
  time_total_s: 62.169700622558594
  timestamp: 1744216003
  timesteps_since_restore: 7875
  timesteps_this_iter: 225
  timesteps_total: 7875
  training_iteration: 35
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     35 |          62.1697 |        7875 |  3.15479 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


[2m[36m(pid=291595)[0m Warning: Vehicle 'rl_9' performs emergency braking on lane 'left1_4_0' with decel=9.54, wished=4.50, severity=1.12, time=8905.00.
Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-26-50
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 4.779935739659266
  episode_reward_mean: 2.8351830105836746
  episode_reward_min: 1.8378286865286124
  episodes_this_iter: 5
  episodes_total: 195
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 92.917
    learner:
      default_policy:
        cur_kl_coeff: 7.275957722603643e-13
        cur_lr: 4.999999873689376e-05
        entropy: 22.097497940063477
        entropy_coeff: 0.0
        kl: 0.010228066705167294
        policy_loss: -0.06887587159872055
        total_loss: 0.13105161488056183
        vf_explained_var: 0.0711214691400528
        vf_loss: 0.19992749392986298
    load_time_ms: 0.987
    num_steps_sampled: 8775
    num_steps_trained: 8775
    sample_time_ms: 1556.736
    update_time_ms: 3.903
  iterations_since_restore: 39
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.65
    ram_util_percent: 77.7
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.878349579066607
    mean_inference_ms: 0.7430506259476957
    mean_processing_ms: 0.5330426121229124
  time_since_restore: 68.82810258865356
  time_this_iter_s: 1.708554744720459
  time_total_s: 68.82810258865356
  timestamp: 1744216010
  timesteps_since_restore: 8775
  timesteps_this_iter: 225
  timesteps_total: 8775
  training_iteration: 39
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     39 |          68.8281 |        8775 |  2.83518 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-26-55
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 3.706501762531051
  episode_reward_mean: 2.6223637377639584
  episode_reward_min: 1.8378286865286124
  episodes_this_iter: 5
  episodes_total: 210
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 93.061
    learner:
      default_policy:
        cur_kl_coeff: 1.8189894306509108e-13
        cur_lr: 4.999999873689376e-05
        entropy: 22.15785026550293
        entropy_coeff: 0.0
        kl: 0.0072046793065965176
        policy_loss: -0.05613389611244202
        total_loss: 0.12958426773548126
        vf_explained_var: 0.13405464589595795
        vf_loss: 0.18571817874908447
    load_time_ms: 0.934
    num_steps_sampled: 9450
    num_steps_trained: 9450
    sample_time_ms: 1601.91
    update_time_ms: 3.952
  iterations_since_restore: 42
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 38.43333333333333
    ram_util_percent: 77.86666666666666
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.858019300970214
    mean_inference_ms: 0.741247669377845
    mean_processing_ms: 0.532720093604147
  time_since_restore: 74.33029842376709
  time_this_iter_s: 1.9914116859436035
  time_total_s: 74.33029842376709
  timestamp: 1744216015
  timesteps_since_restore: 9450
  timesteps_this_iter: 225
  timesteps_total: 9450
  training_iteration: 42
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     42 |          74.3303 |        9450 |  2.62236 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-27-01
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 3.706501762531051
  episode_reward_mean: 2.4785970155733237
  episode_reward_min: 1.614738318146071
  episodes_this_iter: 5
  episodes_total: 225
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 99.798
    learner:
      default_policy:
        cur_kl_coeff: 2.2737367883136385e-14
        cur_lr: 4.999999873689376e-05
        entropy: 22.30562400817871
        entropy_coeff: 0.0
        kl: 0.007053027860820293
        policy_loss: -0.05882219597697258
        total_loss: 0.11971546709537506
        vf_explained_var: 0.10151264816522598
        vf_loss: 0.17853763699531555
    load_time_ms: 0.992
    num_steps_sampled: 10125
    num_steps_trained: 10125
    sample_time_ms: 1625.922
    update_time_ms: 4.087
  iterations_since_restore: 45
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.53333333333333
    ram_util_percent: 78.0
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.8491510964697975
    mean_inference_ms: 0.7412459312231686
    mean_processing_ms: 0.533892022665608
  time_since_restore: 79.5164201259613
  time_this_iter_s: 1.8381719589233398
  time_total_s: 79.5164201259613
  timestamp: 1744216021
  timesteps_since_restore: 10125
  timesteps_this_iter: 225
  timesteps_total: 10125
  training_iteration: 45
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     45 |          79.5164 |       10125 |   2.4786 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-27-07
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 3.4389345251749526
  episode_reward_mean: 2.2618710720480752
  episode_reward_min: 1.476016872136148
  episodes_this_iter: 5
  episodes_total: 245
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 96.612
    learner:
      default_policy:
        cur_kl_coeff: 1.421085492696024e-15
        cur_lr: 4.999999873689376e-05
        entropy: 22.380634307861328
        entropy_coeff: 0.0
        kl: 0.005601119250059128
        policy_loss: -0.04211398959159851
        total_loss: 0.0903826579451561
        vf_explained_var: 0.3412105441093445
        vf_loss: 0.132496640086174
    load_time_ms: 1.0
    num_steps_sampled: 11025
    num_steps_trained: 11025
    sample_time_ms: 1635.093
    update_time_ms: 4.144
  iterations_since_restore: 49
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.3
    ram_util_percent: 77.85
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.839945572891688
    mean_inference_ms: 0.7416098370231516
    mean_processing_ms: 0.5352214827176707
  time_since_restore: 86.2325086593628
  time_this_iter_s: 1.7755331993103027
  time_total_s: 86.2325086593628
  timestamp: 1744216027
  timesteps_since_restore: 11025
  timesteps_this_iter: 225
  timesteps_total: 11025
  training_iteration: 49
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     49 |          86.2325 |       11025 |  2.26187 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-27-14
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 3.4389345251749526
  episode_reward_mean: 2.0673248299144396
  episode_reward_min: 1.4758822181787077
  episodes_this_iter: 5
  episodes_total: 265
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.299
    learner:
      default_policy:
        cur_kl_coeff: 1.77635686587003e-16
        cur_lr: 4.999999873689376e-05
        entropy: 22.344493865966797
        entropy_coeff: 0.0
        kl: 0.006288467440754175
        policy_loss: -0.057100336998701096
        total_loss: 0.027083581313490868
        vf_explained_var: 0.3875804841518402
        vf_loss: 0.08418390899896622
    load_time_ms: 1.014
    num_steps_sampled: 11925
    num_steps_trained: 11925
    sample_time_ms: 1584.076
    update_time_ms: 5.236
  iterations_since_restore: 53
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.199999999999996
    ram_util_percent: 77.3
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.829778272236178
    mean_inference_ms: 0.7418384701451484
    mean_processing_ms: 0.5353918997801157
  time_since_restore: 92.81834435462952
  time_this_iter_s: 1.9186196327209473
  time_total_s: 92.81834435462952
  timestamp: 1744216034
  timesteps_since_restore: 11925
  timesteps_this_iter: 225
  timesteps_total: 11925
  training_iteration: 53
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     53 |          92.8183 |       11925 |  2.06732 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-27-21
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 2.6235182925559872
  episode_reward_mean: 1.8977972328170623
  episode_reward_min: 1.424035531775669
  episodes_this_iter: 5
  episodes_total: 285
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.118
    learner:
      default_policy:
        cur_kl_coeff: 1.1102230411687688e-17
        cur_lr: 4.999999873689376e-05
        entropy: 22.317358016967773
        entropy_coeff: 0.0
        kl: 0.006025766022503376
        policy_loss: -0.04938003420829773
        total_loss: 0.004573115613311529
        vf_explained_var: 0.5544452667236328
        vf_loss: 0.053953152149915695
    load_time_ms: 1.052
    num_steps_sampled: 12825
    num_steps_trained: 12825
    sample_time_ms: 1566.948
    update_time_ms: 5.074
  iterations_since_restore: 57
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.85
    ram_util_percent: 77.2
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.826505030992783
    mean_inference_ms: 0.7430304266122622
    mean_processing_ms: 0.5354694125153994
  time_since_restore: 99.37296342849731
  time_this_iter_s: 1.6024069786071777
  time_total_s: 99.37296342849731
  timestamp: 1744216041
  timesteps_since_restore: 12825
  timesteps_this_iter: 225
  timesteps_total: 12825
  training_iteration: 57
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     57 |           99.373 |       12825 |   1.8978 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-27-26
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 2.424426549445263
  episode_reward_mean: 1.8002308626444914
  episode_reward_min: 1.424035531775669
  episodes_this_iter: 5
  episodes_total: 300
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.956
    learner:
      default_policy:
        cur_kl_coeff: 1.387778801460961e-18
        cur_lr: 4.999999873689376e-05
        entropy: 22.44009017944336
        entropy_coeff: 0.0
        kl: 0.009015417657792568
        policy_loss: -0.053174905478954315
        total_loss: -0.028569554910063744
        vf_explained_var: 0.7771366834640503
        vf_loss: 0.024605348706245422
    load_time_ms: 1.002
    num_steps_sampled: 13500
    num_steps_trained: 13500
    sample_time_ms: 1579.643
    update_time_ms: 4.942
  iterations_since_restore: 60
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.65
    ram_util_percent: 77.45
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.824648896048634
    mean_inference_ms: 0.7438260553997046
    mean_processing_ms: 0.5355645770847013
  time_since_restore: 104.53780317306519
  time_this_iter_s: 1.784127950668335
  time_total_s: 104.53780317306519
  timestamp: 1744216046
  timesteps_since_restore: 13500
  timesteps_this_iter: 225
  timesteps_total: 13500
  training_iteration: 60
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     60 |          104.538 |       13500 |  1.80023 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-27-32
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 2.2844311054414295
  episode_reward_mean: 1.6915507547286575
  episode_reward_min: 1.1909779401462859
  episodes_this_iter: 5
  episodes_total: 320
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 88.612
    learner:
      default_policy:
        cur_kl_coeff: 8.673617509131006e-20
        cur_lr: 4.999999873689376e-05
        entropy: 22.60535430908203
        entropy_coeff: 0.0
        kl: 0.005697264336049557
        policy_loss: -0.0425710566341877
        total_loss: -0.02031436190009117
        vf_explained_var: 0.7794491648674011
        vf_loss: 0.022256698459386826
    load_time_ms: 0.959
    num_steps_sampled: 14400
    num_steps_trained: 14400
    sample_time_ms: 1517.435
    update_time_ms: 3.756
  iterations_since_restore: 64
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.950000000000003
    ram_util_percent: 77.0
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.813542039591819
    mean_inference_ms: 0.7433379180295551
    mean_processing_ms: 0.5345595170880051
  time_since_restore: 110.58373689651489
  time_this_iter_s: 1.5948891639709473
  time_total_s: 110.58373689651489
  timestamp: 1744216052
  timesteps_since_restore: 14400
  timesteps_this_iter: 225
  timesteps_total: 14400
  training_iteration: 64
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     64 |          110.584 |       14400 |  1.69155 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-27-38
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 2.170262185972343
  episode_reward_mean: 1.5959030341866907
  episode_reward_min: 1.1909779401462859
  episodes_this_iter: 5
  episodes_total: 340
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 86.412
    learner:
      default_policy:
        cur_kl_coeff: 1.0842021886413758e-20
        cur_lr: 4.999999873689376e-05
        entropy: 22.462295532226562
        entropy_coeff: 0.0
        kl: 0.007426518015563488
        policy_loss: -0.05598432943224907
        total_loss: -0.038316790014505386
        vf_explained_var: 0.81822270154953
        vf_loss: 0.017667528241872787
    load_time_ms: 0.989
    num_steps_sampled: 15300
    num_steps_trained: 15300
    sample_time_ms: 1399.929
    update_time_ms: 3.671
  iterations_since_restore: 68
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.6
    ram_util_percent: 76.9
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.7925123025811835
    mean_inference_ms: 0.7408237368452939
    mean_processing_ms: 0.532279413263392
  time_since_restore: 116.18523740768433
  time_this_iter_s: 1.445800542831421
  time_total_s: 116.18523740768433
  timestamp: 1744216058
  timesteps_since_restore: 15300
  timesteps_this_iter: 225
  timesteps_total: 15300
  training_iteration: 68
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     68 |          116.185 |       15300 |   1.5959 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-27-43
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.953338999689474
  episode_reward_mean: 1.5293302544594503
  episode_reward_min: 1.1909779401462859
  episodes_this_iter: 5
  episodes_total: 355
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.573
    learner:
      default_policy:
        cur_kl_coeff: 1.3552527358017197e-21
        cur_lr: 4.999999873689376e-05
        entropy: 22.611862182617188
        entropy_coeff: 0.0
        kl: 0.007723984308540821
        policy_loss: -0.05173550173640251
        total_loss: -0.03177756816148758
        vf_explained_var: 0.7814088463783264
        vf_loss: 0.01995793916285038
    load_time_ms: 1.034
    num_steps_sampled: 15975
    num_steps_trained: 15975
    sample_time_ms: 1407.458
    update_time_ms: 3.737
  iterations_since_restore: 71
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.9
    ram_util_percent: 77.6
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.775045383634531
    mean_inference_ms: 0.7386718923640077
    mean_processing_ms: 0.5305939693799188
  time_since_restore: 121.27934837341309
  time_this_iter_s: 1.8335886001586914
  time_total_s: 121.27934837341309
  timestamp: 1744216063
  timesteps_since_restore: 15975
  timesteps_this_iter: 225
  timesteps_total: 15975
  training_iteration: 71
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     71 |          121.279 |       15975 |  1.52933 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-27-48
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.953338999689474
  episode_reward_mean: 1.4807300776285899
  episode_reward_min: 1.1401767005435057
  episodes_this_iter: 5
  episodes_total: 370
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 92.599
    learner:
      default_policy:
        cur_kl_coeff: 6.776263679008599e-22
        cur_lr: 4.999999873689376e-05
        entropy: 22.527042388916016
        entropy_coeff: 0.0
        kl: 0.006279523018747568
        policy_loss: -0.059428296983242035
        total_loss: -0.03808824345469475
        vf_explained_var: 0.752334475517273
        vf_loss: 0.02134004794061184
    load_time_ms: 1.084
    num_steps_sampled: 16650
    num_steps_trained: 16650
    sample_time_ms: 1512.934
    update_time_ms: 3.912
  iterations_since_restore: 74
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.25
    ram_util_percent: 77.5
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.762237545499795
    mean_inference_ms: 0.7369934817257946
    mean_processing_ms: 0.5292489988872281
  time_since_restore: 126.724196434021
  time_this_iter_s: 1.68857741355896
  time_total_s: 126.724196434021
  timestamp: 1744216068
  timesteps_since_restore: 16650
  timesteps_this_iter: 225
  timesteps_total: 16650
  training_iteration: 74
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     74 |          126.724 |       16650 |  1.48073 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-27-53
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.953338999689474
  episode_reward_mean: 1.4426860355010072
  episode_reward_min: 1.1401767005435057
  episodes_this_iter: 5
  episodes_total: 385
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 95.144
    learner:
      default_policy:
        cur_kl_coeff: 8.470329598760748e-23
        cur_lr: 4.999999873689376e-05
        entropy: 22.56258773803711
        entropy_coeff: 0.0
        kl: 0.006686031818389893
        policy_loss: -0.06284666806459427
        total_loss: -0.047099534422159195
        vf_explained_var: 0.8375824093818665
        vf_loss: 0.015747126191854477
    load_time_ms: 1.064
    num_steps_sampled: 17325
    num_steps_trained: 17325
    sample_time_ms: 1632.817
    update_time_ms: 3.996
  iterations_since_restore: 77
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.5
    ram_util_percent: 77.6
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.752014505523882
    mean_inference_ms: 0.735577968122831
    mean_processing_ms: 0.5285173067094558
  time_since_restore: 132.10523986816406
  time_this_iter_s: 1.7085506916046143
  time_total_s: 132.10523986816406
  timestamp: 1744216073
  timesteps_since_restore: 17325
  timesteps_this_iter: 225
  timesteps_total: 17325
  training_iteration: 77
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     77 |          132.105 |       17325 |  1.44269 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-27-59
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.953338999689474
  episode_reward_mean: 1.3945289965712433
  episode_reward_min: 1.1401767005435057
  episodes_this_iter: 5
  episodes_total: 400
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 92.923
    learner:
      default_policy:
        cur_kl_coeff: 1.0587911998450935e-23
        cur_lr: 4.999999873689376e-05
        entropy: 22.51336669921875
        entropy_coeff: 0.0
        kl: 0.008764326572418213
        policy_loss: -0.05644482374191284
        total_loss: -0.03939304128289223
        vf_explained_var: 0.8085848689079285
        vf_loss: 0.017051775008440018
    load_time_ms: 1.067
    num_steps_sampled: 18000
    num_steps_trained: 18000
    sample_time_ms: 1671.249
    update_time_ms: 4.062
  iterations_since_restore: 80
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.1
    ram_util_percent: 77.1
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.743715302743456
    mean_inference_ms: 0.7343839002203169
    mean_processing_ms: 0.527587069564109
  time_since_restore: 137.17378735542297
  time_this_iter_s: 1.4379501342773438
  time_total_s: 137.17378735542297
  timestamp: 1744216079
  timesteps_since_restore: 18000
  timesteps_this_iter: 225
  timesteps_total: 18000
  training_iteration: 80
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     80 |          137.174 |       18000 |  1.39453 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-28-04
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.674886348201104
  episode_reward_mean: 1.3420382569976395
  episode_reward_min: 1.0383036692513097
  episodes_this_iter: 5
  episodes_total: 420
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 89.56
    learner:
      default_policy:
        cur_kl_coeff: 6.617444999031835e-25
        cur_lr: 4.999999873689376e-05
        entropy: 22.2844295501709
        entropy_coeff: 0.0
        kl: 0.005020615644752979
        policy_loss: -0.04272203892469406
        total_loss: -0.028099048882722855
        vf_explained_var: 0.8132022619247437
        vf_loss: 0.014622977003455162
    load_time_ms: 0.93
    num_steps_sampled: 18900
    num_steps_trained: 18900
    sample_time_ms: 1534.057
    update_time_ms: 3.865
  iterations_since_restore: 84
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.75
    ram_util_percent: 76.9
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.7323878213065775
    mean_inference_ms: 0.7326897354380515
    mean_processing_ms: 0.5262322601311322
  time_since_restore: 143.04347395896912
  time_this_iter_s: 1.389164686203003
  time_total_s: 143.04347395896912
  timestamp: 1744216084
  timesteps_since_restore: 18900
  timesteps_this_iter: 225
  timesteps_total: 18900
  training_iteration: 84
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     84 |          143.043 |       18900 |  1.34204 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-28-10
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.6163155103539897
  episode_reward_mean: 1.2867489775696945
  episode_reward_min: 0.9772837393280442
  episodes_this_iter: 5
  episodes_total: 440
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 90.565
    learner:
      default_policy:
        cur_kl_coeff: 4.1359031243948966e-26
        cur_lr: 4.999999873689376e-05
        entropy: 22.188310623168945
        entropy_coeff: 0.0
        kl: 0.008659729734063148
        policy_loss: -0.047736745327711105
        total_loss: -0.03894859552383423
        vf_explained_var: 0.9081335067749023
        vf_loss: 0.008788151666522026
    load_time_ms: 1.029
    num_steps_sampled: 19800
    num_steps_trained: 19800
    sample_time_ms: 1398.171
    update_time_ms: 3.862
  iterations_since_restore: 88
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.2
    ram_util_percent: 76.85
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.7243091923533225
    mean_inference_ms: 0.7316387413766785
    mean_processing_ms: 0.5251232539082393
  time_since_restore: 148.862802028656
  time_this_iter_s: 1.5644469261169434
  time_total_s: 148.862802028656
  timestamp: 1744216090
  timesteps_since_restore: 19800
  timesteps_this_iter: 225
  timesteps_total: 19800
  training_iteration: 88
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 11.8/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     88 |          148.863 |       19800 |  1.28675 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-28-17
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.6163155103539897
  episode_reward_mean: 1.2483588041473026
  episode_reward_min: 0.9772837393280442
  episodes_this_iter: 5
  episodes_total: 460
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.769
    learner:
      default_policy:
        cur_kl_coeff: 2.5849394527468104e-27
        cur_lr: 4.999999873689376e-05
        entropy: 22.06844711303711
        entropy_coeff: 0.0
        kl: 0.006846977863460779
        policy_loss: -0.05654985457658768
        total_loss: -0.041517335921525955
        vf_explained_var: 0.7518649697303772
        vf_loss: 0.015032527968287468
    load_time_ms: 1.026
    num_steps_sampled: 20700
    num_steps_trained: 20700
    sample_time_ms: 1396.327
    update_time_ms: 4.101
  iterations_since_restore: 92
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.45
    ram_util_percent: 77.1
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.716266688362541
    mean_inference_ms: 0.7304015330284063
    mean_processing_ms: 0.5237644599766896
  time_since_restore: 155.0636978149414
  time_this_iter_s: 1.402857780456543
  time_total_s: 155.0636978149414
  timestamp: 1744216097
  timesteps_since_restore: 20700
  timesteps_this_iter: 225
  timesteps_total: 20700
  training_iteration: 92
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     92 |          155.064 |       20700 |  1.24836 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-28-23
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.5513905388173423
  episode_reward_mean: 1.202168658549806
  episode_reward_min: 0.9771502504210255
  episodes_this_iter: 5
  episodes_total: 480
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 93.041
    learner:
      default_policy:
        cur_kl_coeff: 3.231174315933513e-28
        cur_lr: 4.999999873689376e-05
        entropy: 21.989360809326172
        entropy_coeff: 0.0
        kl: 0.00508886156603694
        policy_loss: -0.05102879926562309
        total_loss: -0.03879164904356003
        vf_explained_var: 0.8025867342948914
        vf_loss: 0.012237134389579296
    load_time_ms: 1.06
    num_steps_sampled: 21600
    num_steps_trained: 21600
    sample_time_ms: 1442.833
    update_time_ms: 3.991
  iterations_since_restore: 96
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.03333333333333
    ram_util_percent: 77.26666666666667
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.698822524874365
    mean_inference_ms: 0.7279491713461685
    mean_processing_ms: 0.5213879234846827
  time_since_restore: 161.34740567207336
  time_this_iter_s: 1.9220175743103027
  time_total_s: 161.34740567207336
  timestamp: 1744216103
  timesteps_since_restore: 21600
  timesteps_this_iter: 225
  timesteps_total: 21600
  training_iteration: 96
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 12.0/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     96 |          161.347 |       21600 |  1.20217 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-28-28
  done: false
  episode_len_mean: 45.0
  episode_reward_max: 1.4732584191752818
  episode_reward_mean: 1.1694864517148695
  episode_reward_min: 0.9328515039303262
  episodes_this_iter: 5
  episodes_total: 495
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.441
    learner:
      default_policy:
        cur_kl_coeff: 8.077935789833782e-29
        cur_lr: 4.999999873689376e-05
        entropy: 22.054096221923828
        entropy_coeff: 0.0
        kl: 0.010146141052246094
        policy_loss: -0.07471176236867905
        total_loss: -0.05963115766644478
        vf_explained_var: 0.7397568225860596
        vf_loss: 0.015080605633556843
    load_time_ms: 0.999
    num_steps_sampled: 22275
    num_steps_trained: 22275
    sample_time_ms: 1489.481
    update_time_ms: 4.083
  iterations_since_restore: 99
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.6
    ram_util_percent: 77.5
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.68379269953599
    mean_inference_ms: 0.7259419496616815
    mean_processing_ms: 0.5193728361906185
  time_since_restore: 166.49652552604675
  time_this_iter_s: 1.7019238471984863
  time_total_s: 166.49652552604675
  timestamp: 1744216108
  timesteps_since_restore: 22275
  timesteps_this_iter: 225
  timesteps_total: 22275
  training_iteration: 99
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 RUNNING)
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+
| Trial name                      | status   | loc                |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+----------+--------------------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | RUNNING  | 35.3.43.231:291596 |     99 |          166.497 |       22275 |  1.16949 |
+---------------------------------+----------+--------------------+--------+------------------+-------------+----------+


Result for PPO_FleetControlEnv-v0_430d5224:
  custom_metrics: {}
  date: 2025-04-09_12-28-30
  done: true
  episode_len_mean: 45.0
  episode_reward_max: 1.4732584191752818
  episode_reward_mean: 1.166206709832905
  episode_reward_min: 0.9328515039303262
  episodes_this_iter: 5
  episodes_total: 500
  experiment_id: ff938c37fd554b338f47c5c519d57f75
  experiment_tag: '0'
  hostname: chiste
  info:
    grad_time_ms: 91.166
    learner:
      default_policy:
        cur_kl_coeff: 8.077935789833782e-29
        cur_lr: 4.999999873689376e-05
        entropy: 22.03168296813965
        entropy_coeff: 0.0
        kl: 0.009250564500689507
        policy_loss: -0.06808818876743317
        total_loss: -0.0605757050216198
        vf_explained_var: 0.8823738098144531
        vf_loss: 0.007512468844652176
    load_time_ms: 1.022
    num_steps_sampled: 22500
    num_steps_trained: 22500
    sample_time_ms: 1500.625
    update_time_ms: 4.033
  iterations_since_restore: 100
  node_ip: 35.3.43.231
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.3
    ram_util_percent: 77.45
  pid: 291596
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_env_wait_ms: 5.678904344612288
    mean_inference_ms: 0.7252935268149833
    mean_processing_ms: 0.5187717348621398
  time_since_restore: 168.07704639434814
  time_this_iter_s: 1.5805208683013916
  time_total_s: 168.07704639434814
  timestamp: 1744216110
  timesteps_since_restore: 22500
  timesteps_this_iter: 225
  timesteps_total: 22500
  training_iteration: 100
  trial_id: 430d5224
  
== Status ==
Memory usage on this node: 11.9/15.4 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/1.56 GiB heap, 0.0/0.1 GiB objects
Result logdir: /home/sitota/ray_results/fleet_control
Number of trials: 1 (1 TERMINATED)
+---------------------------------+------------+-------+--------+------------------+-------------+----------+
| Trial name                      | status     | loc   |   iter |   total time (s) |   timesteps |   reward |
|---------------------------------+------------+-------+--------+------------------+-------------+----------|
| PPO_FleetControlEnv-v0_430d5224 | TERMINATED |       |    100 |          168.077 |       22500 |  1.16621 |
+---------------------------------+------------+-------+--------+------------------+-------------+----------+


[2m[36m(pid=291595)[0m ./emissions_output/fleet_control_20250409-1225411744215941.117769-0_emission.csv ./emissions_output
